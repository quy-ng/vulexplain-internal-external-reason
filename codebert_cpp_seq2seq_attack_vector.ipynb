{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=codebert_attack_vector\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=codebert_attack_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from project_dataset import load_dataset\n",
    "from code2nl.model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_name = \"neulab/codebert-cpp\"\n",
    "    num_proc = 4\n",
    "    batch_size = 5\n",
    "    max_source_length = 512  \n",
    "    max_target_length = 146 \n",
    "    data_cols = [\"CVE ID\", \"explain\", \"func_before\"]\n",
    "    save_dir = 'tf_board'\n",
    "    epochs = 100\n",
    "    grad_acc_steps = 4\n",
    "    lr = 5e-5\n",
    "    log_freq = 10\n",
    "    local_rank = -1\n",
    "    deepspeed = None\n",
    "    fp16 = False\n",
    "    lr_warmup_steps = 200\n",
    "    weight_decay = 0.05\n",
    "    task = \"attack_vector\"\n",
    "    prefix = 'neulab'\n",
    "    do_lower_case = False\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(args.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 4858\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 540\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 1350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds['train']\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "df_val = ds['validation']\n",
    "df_val = df_val.to_pandas()\n",
    "\n",
    "df_test = ds['test']\n",
    "df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVE ID</th>\n",
       "      <th>explain</th>\n",
       "      <th>func_before</th>\n",
       "      <th>processed_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-2013-4483</td>\n",
       "      <td>reference counter might not be adjusted properly</td>\n",
       "      <td>static int semctl_down(struct ipc_namespace *n...</td>\n",
       "      <td>static int semctl_down(struct ipc_namespace *n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-2017-13009</td>\n",
       "      <td>sending a specially crafted request</td>\n",
       "      <td>mobility_print(netdissect_options *ndo,  const...</td>\n",
       "      <td>mobility_print(netdissect_options *ndo, const ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-2016-3839</td>\n",
       "      <td>via a crafted application that sends a signal ...</td>\n",
       "      <td>void close_uinput (void)   {  BTIF_TRACE_DEBUG...</td>\n",
       "      <td>void close_uinput(void) {\\n  BTIF_TRACE_DEBUG(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CVE ID                                            explain  \\\n",
       "0   CVE-2013-4483   reference counter might not be adjusted properly   \n",
       "1  CVE-2017-13009                sending a specially crafted request   \n",
       "2   CVE-2016-3839  via a crafted application that sends a signal ...   \n",
       "\n",
       "                                         func_before  \\\n",
       "0  static int semctl_down(struct ipc_namespace *n...   \n",
       "1  mobility_print(netdissect_options *ndo,  const...   \n",
       "2  void close_uinput (void)   {  BTIF_TRACE_DEBUG...   \n",
       "\n",
       "                                      processed_func  \n",
       "0  static int semctl_down(struct ipc_namespace *n...  \n",
       "1  mobility_print(netdissect_options *ndo, const ...  \n",
       "2  void close_uinput(void) {\\n  BTIF_TRACE_DEBUG(...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "os.makedirs(f'tmp_data/{args.task}', exist_ok=True)\n",
    "os.makedirs(f'{args.save_dir}/{args.prefix}_{args.task}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_train['code_tokens'] = df_train.func_before.apply(lambda x: x.split())\n",
    "df_train['docstring_tokens'] = df_train.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/train.jsonl','w') as f:\n",
    "    for _, row in df_train.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_val['code_tokens'] = df_val.func_before.apply(lambda x: x.split())\n",
    "df_val['docstring_tokens'] = df_val.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/valid.jsonl','w') as f:\n",
    "    for _, row in df_val.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_test['code_tokens'] = df_test.func_before.apply(lambda x: x.split())\n",
    "df_test['docstring_tokens'] = df_test.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/test.jsonl','w') as f:\n",
    "    for _, row in df_test.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2023 00:35:34 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='neulab/codebert-cpp', output_dir='tf_board/neulab_attack_vector', load_model_path=None, train_filename='tmp_data/attack_vector/train.jsonl', dev_filename='tmp_data/attack_vector/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=146, do_train=True, do_eval=True, do_test=False, do_lower_case=True, no_cuda=False, train_batch_size=50, eval_batch_size=50, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/27/2023 00:35:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "Some weights of the model checkpoint at neulab/codebert-cpp were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-cpp and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   *** Example ***\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   idx: 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_int', '_sem', 'ctl', '_', 'down', '(', 'struct', '_ip', 'c', '_', 'names', 'pace', '_*', 'ns', ',', '_int', '_sem', 'id', ',', '_int', '_cmd', ',', '_int', '_version', ',', '_void', '___', 'user', '_*', 'p', ')', '_{', '_struct', '_sem', '_', 'array', '_*', 's', 'ma', ';', '_int', '_err', ';', '_struct', '_sem', 'id', '64', '_', 'ds', '_sem', 'id', '64', ';', '_struct', '_k', 'ern', '_', 'ip', 'c', '_', 'perm', '_*', 'ip', 'cp', ';', '_if', '(', 'cmd', '_==', '_I', 'PC', '_', 'SET', ')', '_{', '_if', '_(', 'copy', '_', 'se', 'mid', '_', 'from', '_', 'user', '(&', 'se', 'mid', '64', ',', '_p', ',', '_version', '))', '_return', '_-', 'E', 'FAULT', ';', '_}', '_ip', 'cp', '_=', '_ip', 'c', 'ctl', '_', 'pre', '_', 'down', '_', 'n', 'ol', 'ock', '(', 'ns', ',', '_&', 'sem', '_', 'ids', '(', 'ns', '),', '_sem', 'id', ',', '_cmd', ',', '_&', 'se', 'mid', '64', '.', 'sem', '_', 'perm', ',', '_0', ');', '_if', '_(', 'IS', '_', 'ER', 'R', '(', 'ip', 'cp', '))', '_return', '_P', 'TR', '_', 'ER', 'R', '(', 'ip', 'cp', ');', '_sm', 'a', '_=', '_container', '_', 'of', '(', 'ip', 'cp', ',', '_struct', '_sem', '_', 'array', ',', '_sem', '_', 'perm', ');', '_err', '_=', '_security', '_', 'sem', '_', 'sem', 'ctl', '(', 's', 'ma', ',', '_cmd', ');', '_if', '_(', 'err', ')', '_{', '_r', 'cu', '_', 'read', '_', 'un', 'lock', '();', '_goto', '_out', '_', 'un', 'lock', ';', '_}', '_switch', '(', 'cmd', '){', '_case', '_I', 'PC', '_', 'RM', 'ID', ':', '_ip', 'c', '_', 'lock', '_', 'object', '(&', 's', 'ma', '->', 'sem', '_', 'perm', ');', '_fre', 'ear', 'y', '(', 'ns', ',', '_ip', 'cp', ');', '_goto', '_out', '_', 'up', ';', '_case', '_I', 'PC', '_', 'SET', ':', '_ip', 'c', '_', 'lock', '_', 'object', '(&', 's', 'ma', '->', 'sem', '_', 'perm', ');', '_err', '_=', '_ip', 'c', '_', 'update', '_', 'perm', '(&', 'se', 'mid', '64', '.', 'sem', '_', 'perm', ',', '_ip', 'cp', ');', '_if', '_(', 'err', ')', '_goto', '_out', '_', 'un', 'lock', ';', '_sm', 'a', '->', 'sem', '_', 'ct', 'ime', '_=', '_get', '_', 'seconds', '();', '_break', ';', '_default', ':', '_r', 'cu', '_', 'read', '_', 'un', 'lock', '();', '_err', '_=', '_-', 'E', 'IN', 'VAL', ';', '_goto', '_out', '_', 'up', ';', '_}', '_out', '_', 'un', 'lock', ':', '_sem', '_', 'un', 'lock', '(', 's', 'ma', ');', '_out', '_', 'up', ':', '_up', '_', 'write', '(&', 'sem', '_', 'ids', '(', 'ns', ').', 'rw', '_', 'mut', 'ex', ');', '_return', '_err', ';', '_}', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_ids: 0 42653 6979 9031 47074 1215 3955 1640 25384 36180 438 1215 37815 18851 1009 6852 6 6979 9031 808 6 6979 49099 6 6979 1732 6 13842 27148 12105 1009 642 43 25522 29916 9031 1215 30766 1009 29 1916 131 6979 22379 131 29916 9031 808 4027 1215 11622 9031 808 4027 131 29916 449 3281 1215 1588 438 1215 43983 1009 1588 30216 131 114 1640 48211 45994 38 4794 1215 45099 43 25522 114 36 44273 1215 1090 16079 1215 7761 1215 12105 49763 1090 16079 4027 6 181 6 1732 35122 671 111 717 47697 131 35524 36180 30216 5457 36180 438 47074 1215 5234 1215 3955 1215 282 1168 3343 1640 6852 6 359 26976 1215 7823 1640 6852 238 9031 808 6 49099 6 359 1090 16079 4027 4 26976 1215 43983 6 321 4397 114 36 1729 1215 2076 500 1640 1588 30216 35122 671 221 6997 1215 2076 500 1640 1588 30216 4397 5278 102 5457 11255 1215 1116 1640 1588 30216 6 29916 9031 1215 30766 6 9031 1215 43983 4397 22379 5457 573 1215 26976 1215 26976 47074 1640 29 1916 6 49099 4397 114 36 14385 43 25522 910 16312 1215 12745 1215 879 8292 47006 49325 66 1215 879 8292 131 35524 5405 1640 48211 48512 403 38 4794 1215 28580 2688 35 36180 438 1215 8292 1215 40412 49763 29 1916 46613 26976 1215 43983 4397 7619 4352 219 1640 6852 6 36180 30216 4397 49325 66 1215 658 131 403 38 4794 1215 45099 35 36180 438 1215 8292 1215 40412 49763 29 1916 46613 26976 1215 43983 4397 22379 5457 36180 438 1215 45061 1215 43983 49763 1090 16079 4027 4 26976 1215 43983 6 36180 30216 4397 114 36 14385 43 49325 66 1215 879 8292 131 5278 102 46613 26976 1215 3894 4235 5457 120 1215 43968 47006 1108 131 6814 35 910 16312 1215 12745 1215 879 8292 47006 22379 5457 111 717 2444 39766 131 49325 66 1215 658 131 35524 66 1215 879 8292 35 9031 1215 879 8292 1640 29 1916 4397 66 1215 658 35 62 1215 29631 49763 26976 1215 7823 1640 6852 322 43926 1215 26121 3463 4397 671 22379 131 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_tokens: ['<s>', 'reference', '_counter', '_might', '_not', '_be', '_adjusted', '_properly', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_ids: 0 45927 3231 429 45 28 5493 5083 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   *** Example ***\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   idx: 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_tokens: ['<s>', 'mob', 'ility', '_', 'print', '(', 'net', 'dis', 'sect', '_', 'options', '_*', 'nd', 'o', ',', '_const', '_u', '_', 'char', '_*', 'bp', ',', '_const', '_u', '_', 'char', '_*', 'bp', '2', '__', 'U', '_', ')', '_{', '_const', '_struct', '_ip', '6', '_', 'mob', 'ility', '_*', 'm', 'h', ';', '_const', '_u', '_', 'char', '_*', 'ep', ';', '_unsigned', '_m', 'h', 'len', ',', '_h', 'len', ';', '_uint', '8', '_', 't', '_type', ';', '_m', 'h', '_=', '_(', 'const', '_struct', '_ip', '6', '_', 'mob', 'ility', '_*)', 'bp', ';', '_/*', \"_'\", 'ep', \"'\", '_points', '_to', '_the', '_end', '_of', '_available', '_data', '.', '_*/', '_ep', '_=', '_n', 'do', '->', 'nd', 'o', '_', 'snap', 'end', ';', '_if', '_(!', 'ND', '_', 'TT', 'EST', '(', 'm', 'h', '->', 'ip', '6', 'm', '_', 'len', '))', '_{', '_/*', '_*', '_There', \"'s\", '_not', '_enough', '_captured', '_data', '_to', '_include', '_the', '_*', '_mobility', '_header', '_length', '.', '_*', '_*', '_Our', '_caller', '_expects', '_us', '_to', '_return', '_the', '_length', ',', '_however', ',', '_*', '_so', '_return', '_a', '_value', '_that', '_will', '_run', '_to', '_the', '_end', '_of', '_the', '_*', '_captured', '_data', '.', '_*', '_*', '_XXX', '_-', '_\"', 'ip', '6', '_', 'print', '()', '\"', '_doesn', \"'t\", '_do', '_anything', '_with', '_the', '_*', '_returned', '_length', ',', '_however', ',', '_as', '_it', '_breaks', '_out', '_of', '_the', '_*', '_header', '-', 'processing', '_loop', '.', '_*/', '_m', 'h', 'len', '_=', '_ep', '_-', '_b', 'p', ';', '_goto', '_trunc', ';', '_}', '_m', 'h', 'len', '_=', '_(', 'm', 'h', '->', 'ip', '6', 'm', '_', 'len', '_+', '_1', ')', '_<<', '_3', ';', '_/*', '_XXX', '_ip', '6', 'm', '_', 'cks', 'um', '_*/', '_ND', '_', 'T', 'CHECK', '(', 'm', 'h', '->', 'ip', '6', 'm', '_', 'type', ');', '_type', '_=', '_m', 'h', '->', 'ip', '6', 'm', '_', 'type', ';', '_if', '_(', 'type', '_<=', '_IP', '6', 'M', '_', 'MAX', '_&&', '_m', 'h', 'len', '_<', '_ip', '6', 'm', '_', 'h', 'dr', 'len', '[', 'type', '])', '_{', '_ND', '_', 'PR', 'INT', '((', 'nd', 'o', ',', '_\"(', 'header', '_length', '_%', 'u', '_is', '_too', '_small', '_for', '_type', '_%', 'u', ')\",', '_m', 'h', 'len', ',', '_type', '));', '_goto', '_trunc', ';', '_}', '_ND', '_', 'PR', 'INT', '((', 'nd', 'o', ',', '_\"', 'mob', 'ility', ':', '_%', 's', '\",', '_to', 'k', '2', 'str', '(', 'ip', '6', 'm', '_', 'str', ',', '_\"', 'type', '-', '#', '%', 'u', '\",', '_type', '))', ');', '_switch', '_(', 'type', ')', '_{', '_case', '_IP', '6', 'M', '_', 'B', 'IND', 'ING', '_', 'RE', 'QUEST', ':', '_h', 'len', '_=', '_IP', '6', 'M', '_', 'MIN', 'L', 'EN', ';', '_break', ';', '_case', '_IP', '6', 'M', '_', 'HOME', '_', 'T', 'EST', '_', 'IN', 'IT', ':', '_case', '_IP', '6', 'M', '_', 'CAR', 'EO', 'F', '_', 'T', 'EST', '_', 'IN', 'IT', ':', '_h', 'len', '_=', '_IP', '6', 'M', '_', 'MIN', 'L', 'EN', ';', '_if', '_(', 'nd', 'o', '->', 'nd', 'o', '_', 'v', 'flag', ')', '_{', '_ND', '_', 'T', 'CHECK', '2', '(*', 'm', 'h', ',', '_h', 'len', '_+', '_8', ');', '_ND', '_', 'PR', 'INT', '((', 'nd', 'o', ',', '_\"', '_%', 's', '_Init', '_Cookie', '=', '%', '08', 'x', ':', '%', '08', 'x', '\",', '_type', '_==', '_IP', '6', 'M', '_', 'HOME', '_', 'T', 'EST', '_', 'IN', 'IT', '_?', '_\"', 'Home', '\"', '_:', '_\"', 'Care', '-', 'of', '\",', '_EX', 'TR', 'ACT', '_', '32', 'BIT', 'S', '(&', 'bp', '[', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_ids: 0 37608 13005 1215 17265 1640 4135 7779 41147 1215 45012 1009 1187 139 6 10759 1717 1215 24262 1009 20794 6 10759 1717 1215 24262 1009 20794 176 18134 791 1215 43 25522 10759 29916 36180 401 1215 37608 13005 1009 119 298 131 10759 1717 1215 24262 1009 2462 131 39023 475 298 8476 6 1368 8476 131 49315 398 1215 90 1907 131 475 298 5457 36 20836 29916 36180 401 1215 37608 13005 49521 20794 131 48565 128 2462 108 332 7 5 253 9 577 414 4 48404 14887 5457 295 5016 46613 1187 139 1215 43189 1397 131 114 48209 13457 1215 14543 4923 1640 119 298 46613 1588 401 119 1215 8476 35122 25522 48565 1009 345 18 45 615 4705 414 7 680 5 1009 11525 12734 5933 4 1009 1009 1541 17017 3352 201 7 671 5 5933 6 959 6 1009 98 671 10 923 14 40 422 7 5 253 9 5 1009 4705 414 4 1009 1009 34528 111 22 1588 401 1215 17265 43048 113 630 75 109 932 19 5 1009 1835 5933 6 959 6 25 24 6383 66 9 5 1009 12734 12 39221 14018 4 48404 475 298 8476 5457 14887 111 741 642 131 49325 43064 131 35524 475 298 8476 5457 36 119 298 46613 1588 401 119 1215 8476 2055 112 43 48188 155 131 48565 34528 36180 401 119 1215 15291 783 48404 19430 1215 565 48692 1640 119 298 46613 1588 401 119 1215 12528 4397 1907 5457 475 298 46613 1588 401 119 1215 12528 131 114 36 12528 49230 6442 401 448 1215 30187 48200 475 298 8476 28696 36180 401 119 1215 298 10232 8476 10975 12528 45587 25522 19430 1215 4454 17831 48461 1187 139 6 14025 24419 5933 7606 257 16 350 650 13 1907 7606 257 45894 475 298 8476 6 1907 48749 49325 43064 131 35524 19430 1215 4454 17831 48461 1187 139 6 22 37608 13005 35 7606 29 1297 7 330 176 6031 1640 1588 401 119 1215 6031 6 22 12528 12 10431 207 257 1297 1907 35122 4397 5405 36 12528 43 25522 403 6442 401 448 1215 387 13796 1862 1215 4629 46392 35 1368 8476 5457 6442 401 448 1215 24765 574 2796 131 1108 131 403 6442 401 448 1215 47104 1215 565 4923 1215 2444 2068 35 403 6442 401 448 1215 22965 15127 597 1215 565 4923 1215 2444 2068 35 1368 8476 5457 6442 401 448 1215 24765 574 2796 131 114 36 1187 139 46613 1187 139 1215 705 30160 43 25522 19430 1215 565 48692 176 49570 119 298 6 1368 8476 2055 290 4397 19430 1215 4454 17831 48461 1187 139 6 22 7606 29 47023 34662 5214 207 3669 1178 35 207 3669 1178 1297 1907 45994 6442 401 448 1215 47104 1215 565 4923 1215 2444 2068 17487 22 19457 113 4832 22 16431 12 1116 1297 10649 6997 13709 1215 2881 5871 104 49763 20794 10975 2\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_tokens: ['<s>', 's', 'ending', '_a', '_specially', '_crafted', '_request', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_ids: 0 29 4345 10 18041 17626 2069 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   *** Example ***\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   idx: 2\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_tokens: ['<s>', 'void', '_close', '_', 'u', 'input', '_(', 'void', ')', '_{', '_BT', 'IF', '_', 'TR', 'ACE', '_', 'DEBUG', '(\"', '%', 's', '\",', '___', 'FUN', 'CT', 'ION', '__', ');', '_if', '_(', 'u', 'input', '_', 'fd', '_>', '_0', ')', '_{', '_io', 'ctl', '(', 'u', 'input', '_', 'fd', ',', '_UI', '_', 'DEV', '_', 'DES', 'TR', 'OY', ');', '_close', '(', 'u', 'input', '_', 'fd', ');', '_u', 'input', '_', 'fd', '_=', '_-', '1', ';', '_}', '_}', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_ids: 0 47908 593 1215 257 46797 36 47908 43 25522 12482 7025 1215 6997 15949 1215 49837 46469 207 29 1297 27148 45354 7164 7744 30529 4397 114 36 257 46797 1215 37379 8061 321 43 25522 46155 47074 1640 257 46797 1215 37379 6 27182 1215 47233 1215 40429 6997 20664 4397 593 1640 257 46797 1215 37379 4397 1717 46797 1215 37379 5457 111 134 131 35524 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_tokens: ['<s>', 'via', '_a', '_crafted', '_application', '_that', '_sends', '_a', '_signal', '_to', '_a', '_Bluetooth', '_process', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_ids: 0 11409 10 17626 2502 14 11210 10 6029 7 10 13217 609 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   *** Example ***\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   idx: 3\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_tokens: ['<s>', 'base', '::', 'Process', 'Handle', '_Start', 'Process', 'With', 'Access', '(', 'Command', 'Line', '*', '_cmd', '_', 'line', ',', '_const', '_File', 'Path', '&', '_exposed', '_', 'dir', ')', '_{', '_const', '_Command', 'Line', '&', '_browser', '_', 'command', '_', 'line', '_=', '_*', 'Command', 'Line', '::', 'For', 'Current', 'Process', '();', '_content', '::', 'Process', 'Type', '_type', ';', '_std', '::', 'string', '_type', '_', 'str', '_=', '_cmd', '_', 'line', '->', 'Get', 'Switch', 'Value', 'ASC', 'II', '(', 'sw', 'itches', '::', 'k', 'Process', 'Type', ');', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'R', 'end', 'erer', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'R', 'END', 'ER', 'ER', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'Plugin', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'PL', 'UG', 'IN', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'Work', 'er', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'WORK', 'ER', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'Na', 'Cl', 'Loader', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'N', 'AC', 'L', '_', 'LOAD', 'ER', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'Ut', 'ility', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'UT', 'IL', 'ITY', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'Na', 'Cl', 'Bro', 'ker', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'N', 'AC', 'L', '_', 'BR', 'OK', 'ER', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'G', 'pu', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'GPU', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'P', 'p', 'api', 'Plugin', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'PP', 'API', '_', 'PL', 'UG', 'IN', ';', '_}', '_else', '_if', '_(', 'type', '_', 'str', '_==', '_switches', '::', 'k', 'P', 'p', 'api', 'Bro', 'ker', 'Process', ')', '_{', '_type', '_=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'PP', 'API', '_', 'BR', 'OK', 'ER', ';', '_}', '_else', '_{', '_NOT', 'RE', 'ACH', 'ED', '();', '_return', '_0', ';', '_}', '_TR', 'ACE', '_', 'EV', 'ENT', '_', 'B', 'EGIN', '_', 'ET', 'W', '(\"', 'Start', 'Process', 'With', 'Access', '\",', '_0', ',', '_type', '_', 'str', ');', '_bool', '_in', '_', 'sand', 'box', '_=', '_(', 'type', '_!=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'N', 'AC', 'L', '_', 'BR', 'OK', 'ER', ')', '_&&', '_(', 'type', '_!=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'PL', 'UG', 'IN', ')', '_&&', '_(', 'type', '_!=', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'PP', 'API', '_', 'BR', 'OK', 'ER', ');', '_if', '_((', 'type', '_==', '_content', '::', 'PR', 'OC', 'ESS', '_', 'TYPE', '_', 'GPU', ')', '_&&', '_(', 'cmd', '_', 'line', '->', 'Has', 'Switch', '(', 'sw', 'itches', '::', 'k', 'Disable', 'G', 'pu', 'Sand', 'box', ')))', '_{', '_in', '_', 'sand', 'box', '_=', '_false', ';', '_DV', 'LOG', '(', '1', ')', '_<<', '_\"', 'GPU', '_sandbox', '_is', '_disabled', '\";', '_}', '_if', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_ids: 0 11070 38304 46202 48678 2776 46202 3908 35505 1640 46785 18997 3226 49099 1215 1902 6 10759 8655 42119 947 4924 1215 41292 43 25522 10759 9539 18997 947 11407 1215 41483 1215 1902 5457 1009 46785 18997 38304 2709 42124 46202 47006 1383 38304 46202 40118 1907 131 49008 38304 20951 1907 1215 6031 5457 49099 1215 1902 46613 14181 45112 33977 40230 11194 1640 4184 30312 38304 330 46202 40118 4397 114 36 12528 1215 6031 45994 21737 38304 330 500 1397 7160 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 500 9309 2076 2076 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 49577 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 7205 13644 2444 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 21461 254 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 45213 2076 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 30612 11428 49621 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 487 2562 574 1215 27822 2076 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 41967 13005 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 6972 3063 8662 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 30612 11428 26519 5029 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 487 2562 574 1215 7202 9335 2076 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 534 30738 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 44753 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 510 642 30602 49577 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 5756 40104 1215 7205 13644 2444 131 35524 1493 114 36 12528 1215 6031 45994 21737 38304 330 510 642 30602 26519 5029 46202 43 25522 1907 5457 1383 38304 4454 4571 12147 1215 48710 1215 5756 40104 1215 7202 9335 2076 131 35524 1493 25522 8127 4629 11083 1691 47006 671 321 131 35524 5758 15949 1215 19896 5382 1215 387 39764 1215 3935 771 46469 33724 46202 3908 35505 1297 321 6 1907 1215 6031 4397 49460 11 1215 39009 8304 5457 36 12528 49333 1383 38304 4454 4571 12147 1215 48710 1215 487 2562 574 1215 7202 9335 2076 43 48200 36 12528 49333 1383 38304 4454 4571 12147 1215 48710 1215 7205 13644 2444 43 48200 36 12528 49333 1383 38304 4454 4571 12147 1215 48710 1215 5756 40104 1215 7202 9335 2076 4397 114 41006 12528 45994 1383 38304 4454 4571 12147 1215 48710 1215 44753 43 48200 36 48211 1215 1902 46613 35634 45112 1640 4184 30312 38304 330 49392 534 30738 40213 8304 47619 25522 11 1215 39009 8304 5457 3950 131 32586 45403 1640 134 43 48188 22 44753 43278 16 6242 25718 35524 114 2\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_tokens: ['<s>', 'via', '_unspecified', '_vectors', '_.', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_ids: 0 11409 20022 44493 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   *** Example ***\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   idx: 4\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_v', '8', '::', 'Handle', '<', 'v', '8', '::', 'Value', '>', '_id', 'b', 'Key', 'Callback', '(', 'const', '_v', '8', '::', 'Arg', 'uments', '&', '_args', ')', '_{', '_INC', '_', 'ST', 'ATS', '(\"', 'DOM', '.', 'Test', 'Obj', '.', 'id', 'b', 'Key', '\");', '_if', '_(', 'args', '.', 'Length', '()', '_<', '_1', ')', '_return', '_V', '8', 'Proxy', '::', 'throw', 'Not', 'Enough', 'Arg', 'uments', 'Error', '();', '_Test', 'Obj', '*', '_imp', '_=', '_V', '8', 'Test', 'Obj', '::', 'to', 'Native', '(', 'args', '.', 'H', 'older', '());', '_EX', 'CEPT', 'ION', '_', 'BL', 'OCK', '(', 'Ref', 'Ptr', '<', 'ID', 'B', 'Key', '>,', '_key', ',', '_create', 'ID', 'B', 'Key', 'From', 'Value', '(', 'M', 'AY', 'BE', '_', 'M', 'ISS', 'ING', '_', 'PAR', 'AM', 'ET', 'ER', '(', 'args', ',', '_0', ',', '_Default', 'Is', 'Und', 'efined', '))', ');', '_imp', '->', 'id', 'b', 'Key', '(', 'key', '.', 'get', '());', '_return', '_v', '8', '::', 'Handle', '<', 'v', '8', '::', 'Value', '>', '();', '_}', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_ids: 0 42653 748 398 38304 48678 41552 705 398 38304 33977 15698 13561 428 28152 49706 1640 20836 748 398 38304 45621 30179 947 49503 43 25522 18012 1215 4014 26063 46469 45092 4 34603 49062 4 808 428 28152 45751 114 36 48204 4 48739 43048 28696 112 43 671 468 398 49115 38304 26003 7199 41844 45621 30179 30192 47006 4500 49062 3226 4023 5457 468 398 34603 49062 38304 560 45339 1640 48204 4 725 33780 49291 10649 45383 7744 1215 7976 13181 1640 31842 49835 41552 2688 387 28152 48077 762 6 1045 2688 387 28152 7605 33977 1640 448 2547 8827 1215 448 17588 1862 1215 14280 2620 3935 2076 1640 48204 6 321 6 35364 6209 42061 38716 35122 4397 4023 46613 808 428 28152 1640 5282 4 6460 49291 671 748 398 38304 48678 41552 705 398 38304 33977 15698 47006 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_tokens: ['<s>', 'via', '_a', '_crafted', '_extension', '_.', '</s>']\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_ids: 0 11409 10 17626 5064 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/27/2023 00:35:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "07/27/2023 00:35:47 - INFO - __main__ -   ***** Running training *****\n",
      "07/27/2023 00:35:47 - INFO - __main__ -     Num examples = 4858\n",
      "07/27/2023 00:35:47 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:35:47 - INFO - __main__ -     Num epoch = 100\n",
      "  0%|                                                    | 0/98 [00:00<?, ?it/s]/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 0 loss 8.6744: 100%|██████████████████████| 98/98 [01:21<00:00,  1.20it/s]\n",
      "07/27/2023 00:37:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:37:10 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:37:10 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:37:13 - INFO - __main__ -     eval_ppl = 272.39293\n",
      "07/27/2023 00:37:13 - INFO - __main__ -     global_step = 99\n",
      "07/27/2023 00:37:13 - INFO - __main__ -     train_loss = 8.6744\n",
      "07/27/2023 00:37:13 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:37:14 - INFO - __main__ -     Best ppl:272.39293\n",
      "07/27/2023 00:37:14 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:37:33 - INFO - __main__ -     bleu-4 = 3.87 \n",
      "07/27/2023 00:37:33 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:37:33 - INFO - __main__ -     Best bleu:3.87\n",
      "07/27/2023 00:37:33 - INFO - __main__ -     ********************\n",
      "epoch 1 loss 4.2958: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:38:53 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:38:53 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:38:53 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:38:57 - INFO - __main__ -     eval_ppl = 33.59034\n",
      "07/27/2023 00:38:57 - INFO - __main__ -     global_step = 197\n",
      "07/27/2023 00:38:57 - INFO - __main__ -     train_loss = 4.2958\n",
      "07/27/2023 00:38:57 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:38:59 - INFO - __main__ -     Best ppl:33.59034\n",
      "07/27/2023 00:38:59 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:39:31 - INFO - __main__ -     bleu-4 = 33.07 \n",
      "07/27/2023 00:39:31 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:39:31 - INFO - __main__ -     Best bleu:33.07\n",
      "07/27/2023 00:39:31 - INFO - __main__ -     ********************\n",
      "epoch 2 loss 3.1638: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:40:53 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:40:53 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:40:53 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:40:56 - INFO - __main__ -     eval_ppl = 18.73426\n",
      "07/27/2023 00:40:56 - INFO - __main__ -     global_step = 295\n",
      "07/27/2023 00:40:56 - INFO - __main__ -     train_loss = 3.1638\n",
      "07/27/2023 00:40:56 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:40:58 - INFO - __main__ -     Best ppl:18.73426\n",
      "07/27/2023 00:40:58 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:41:29 - INFO - __main__ -     bleu-4 = 36.98 \n",
      "07/27/2023 00:41:29 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:41:29 - INFO - __main__ -     Best bleu:36.98\n",
      "07/27/2023 00:41:29 - INFO - __main__ -     ********************\n",
      "epoch 3 loss 2.6351: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:42:51 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:42:51 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:42:51 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:42:54 - INFO - __main__ -     eval_ppl = 11.79189\n",
      "07/27/2023 00:42:54 - INFO - __main__ -     global_step = 393\n",
      "07/27/2023 00:42:54 - INFO - __main__ -     train_loss = 2.6351\n",
      "07/27/2023 00:42:54 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:42:56 - INFO - __main__ -     Best ppl:11.79189\n",
      "07/27/2023 00:42:56 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:43:25 - INFO - __main__ -     bleu-4 = 43.64 \n",
      "07/27/2023 00:43:25 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:43:25 - INFO - __main__ -     Best bleu:43.64\n",
      "07/27/2023 00:43:25 - INFO - __main__ -     ********************\n",
      "epoch 4 loss 2.2141: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:44:46 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:44:46 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:44:46 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:44:50 - INFO - __main__ -     eval_ppl = 8.09087\n",
      "07/27/2023 00:44:50 - INFO - __main__ -     global_step = 491\n",
      "07/27/2023 00:44:50 - INFO - __main__ -     train_loss = 2.2141\n",
      "07/27/2023 00:44:50 - INFO - __main__ -     ********************\n",
      "epoch 5 loss 1.8252: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:46:43 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:46:43 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:46:43 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:46:46 - INFO - __main__ -     eval_ppl = 6.02836\n",
      "07/27/2023 00:46:46 - INFO - __main__ -     global_step = 589\n",
      "07/27/2023 00:46:46 - INFO - __main__ -     train_loss = 1.8252\n",
      "07/27/2023 00:46:46 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:46:49 - INFO - __main__ -     Best ppl:6.02836\n",
      "07/27/2023 00:46:49 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:47:17 - INFO - __main__ -     bleu-4 = 45.83 \n",
      "07/27/2023 00:47:17 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:47:17 - INFO - __main__ -     Best bleu:45.83\n",
      "07/27/2023 00:47:17 - INFO - __main__ -     ********************\n",
      "epoch 6 loss 1.5173: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:48:39 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:48:39 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:48:39 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:48:42 - INFO - __main__ -     eval_ppl = 4.80134\n",
      "07/27/2023 00:48:42 - INFO - __main__ -     global_step = 687\n",
      "07/27/2023 00:48:42 - INFO - __main__ -     train_loss = 1.5173\n",
      "07/27/2023 00:48:42 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:48:45 - INFO - __main__ -     Best ppl:4.80134\n",
      "07/27/2023 00:48:45 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:49:14 - INFO - __main__ -     bleu-4 = 51.46 \n",
      "07/27/2023 00:49:14 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:49:14 - INFO - __main__ -     Best bleu:51.46\n",
      "07/27/2023 00:49:14 - INFO - __main__ -     ********************\n",
      "epoch 7 loss 1.2813: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:50:36 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:50:36 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:50:36 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:50:39 - INFO - __main__ -     eval_ppl = 4.03166\n",
      "07/27/2023 00:50:39 - INFO - __main__ -     global_step = 785\n",
      "07/27/2023 00:50:39 - INFO - __main__ -     train_loss = 1.2813\n",
      "07/27/2023 00:50:39 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:50:42 - INFO - __main__ -     Best ppl:4.03166\n",
      "07/27/2023 00:50:42 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:51:12 - INFO - __main__ -     bleu-4 = 53.97 \n",
      "07/27/2023 00:51:12 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:51:12 - INFO - __main__ -     Best bleu:53.97\n",
      "07/27/2023 00:51:12 - INFO - __main__ -     ********************\n",
      "epoch 8 loss 1.0666: 100%|██████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:52:33 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:52:33 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:52:33 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:52:37 - INFO - __main__ -     eval_ppl = 3.66994\n",
      "07/27/2023 00:52:37 - INFO - __main__ -     global_step = 883\n",
      "07/27/2023 00:52:37 - INFO - __main__ -     train_loss = 1.0666\n",
      "07/27/2023 00:52:37 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:52:39 - INFO - __main__ -     Best ppl:3.66994\n",
      "07/27/2023 00:52:39 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:53:07 - INFO - __main__ -     bleu-4 = 55.33 \n",
      "07/27/2023 00:53:07 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:53:07 - INFO - __main__ -     Best bleu:55.33\n",
      "07/27/2023 00:53:07 - INFO - __main__ -     ********************\n",
      "epoch 9 loss 0.8815: 100%|██████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 00:54:30 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:54:30 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:54:30 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:54:33 - INFO - __main__ -     eval_ppl = 3.32447\n",
      "07/27/2023 00:54:33 - INFO - __main__ -     global_step = 981\n",
      "07/27/2023 00:54:33 - INFO - __main__ -     train_loss = 0.8815\n",
      "07/27/2023 00:54:33 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:54:35 - INFO - __main__ -     Best ppl:3.32447\n",
      "07/27/2023 00:54:35 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:55:04 - INFO - __main__ -     bleu-4 = 60.88 \n",
      "07/27/2023 00:55:04 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:55:04 - INFO - __main__ -     Best bleu:60.88\n",
      "07/27/2023 00:55:04 - INFO - __main__ -     ********************\n",
      "epoch 10 loss 0.7232: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:56:26 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:56:26 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:56:26 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:56:29 - INFO - __main__ -     eval_ppl = 3.04989\n",
      "07/27/2023 00:56:29 - INFO - __main__ -     global_step = 1079\n",
      "07/27/2023 00:56:29 - INFO - __main__ -     train_loss = 0.7232\n",
      "07/27/2023 00:56:29 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:56:32 - INFO - __main__ -     Best ppl:3.04989\n",
      "07/27/2023 00:56:32 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:57:03 - INFO - __main__ -     bleu-4 = 63.01 \n",
      "07/27/2023 00:57:03 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:57:03 - INFO - __main__ -     Best bleu:63.01\n",
      "07/27/2023 00:57:03 - INFO - __main__ -     ********************\n",
      "epoch 11 loss 0.5904: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 00:58:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 00:58:25 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 00:58:25 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 00:58:28 - INFO - __main__ -     eval_ppl = 2.87945\n",
      "07/27/2023 00:58:28 - INFO - __main__ -     global_step = 1177\n",
      "07/27/2023 00:58:28 - INFO - __main__ -     train_loss = 0.5904\n",
      "07/27/2023 00:58:28 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:58:30 - INFO - __main__ -     Best ppl:2.87945\n",
      "07/27/2023 00:58:30 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 00:59:02 - INFO - __main__ -     bleu-4 = 65.67 \n",
      "07/27/2023 00:59:02 - INFO - __main__ -     ********************\n",
      "07/27/2023 00:59:02 - INFO - __main__ -     Best bleu:65.67\n",
      "07/27/2023 00:59:02 - INFO - __main__ -     ********************\n",
      "epoch 12 loss 0.4701: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:00:23 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:00:23 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:00:23 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:00:27 - INFO - __main__ -     eval_ppl = 2.83028\n",
      "07/27/2023 01:00:27 - INFO - __main__ -     global_step = 1275\n",
      "07/27/2023 01:00:27 - INFO - __main__ -     train_loss = 0.4701\n",
      "07/27/2023 01:00:27 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:00:29 - INFO - __main__ -     Best ppl:2.83028\n",
      "07/27/2023 01:00:29 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:01:00 - INFO - __main__ -     bleu-4 = 65.75 \n",
      "07/27/2023 01:01:00 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:01:00 - INFO - __main__ -     Best bleu:65.75\n",
      "07/27/2023 01:01:00 - INFO - __main__ -     ********************\n",
      "epoch 13 loss 0.3813: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:02:22 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:02:22 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:02:22 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:02:25 - INFO - __main__ -     eval_ppl = 2.73708\n",
      "07/27/2023 01:02:25 - INFO - __main__ -     global_step = 1373\n",
      "07/27/2023 01:02:25 - INFO - __main__ -     train_loss = 0.3813\n",
      "07/27/2023 01:02:25 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:02:27 - INFO - __main__ -     Best ppl:2.73708\n",
      "07/27/2023 01:02:27 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:02:58 - INFO - __main__ -     bleu-4 = 66.37 \n",
      "07/27/2023 01:02:58 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:02:58 - INFO - __main__ -     Best bleu:66.37\n",
      "07/27/2023 01:02:58 - INFO - __main__ -     ********************\n",
      "epoch 14 loss 0.3036: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:04:20 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:04:20 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:04:20 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:04:24 - INFO - __main__ -     eval_ppl = 2.67257\n",
      "07/27/2023 01:04:24 - INFO - __main__ -     global_step = 1471\n",
      "07/27/2023 01:04:24 - INFO - __main__ -     train_loss = 0.3036\n",
      "07/27/2023 01:04:24 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:04:26 - INFO - __main__ -     Best ppl:2.67257\n",
      "07/27/2023 01:04:26 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:04:57 - INFO - __main__ -     bleu-4 = 67.44 \n",
      "07/27/2023 01:04:57 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:04:57 - INFO - __main__ -     Best bleu:67.44\n",
      "07/27/2023 01:04:57 - INFO - __main__ -     ********************\n",
      "epoch 15 loss 0.2463: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:06:19 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:06:19 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:06:19 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:06:23 - INFO - __main__ -     eval_ppl = 2.65604\n",
      "07/27/2023 01:06:23 - INFO - __main__ -     global_step = 1569\n",
      "07/27/2023 01:06:23 - INFO - __main__ -     train_loss = 0.2463\n",
      "07/27/2023 01:06:23 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:06:25 - INFO - __main__ -     Best ppl:2.65604\n",
      "07/27/2023 01:06:25 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:06:57 - INFO - __main__ -     bleu-4 = 68.34 \n",
      "07/27/2023 01:06:57 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:06:57 - INFO - __main__ -     Best bleu:68.34\n",
      "07/27/2023 01:06:57 - INFO - __main__ -     ********************\n",
      "epoch 16 loss 0.2026: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:08:19 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:08:19 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:08:19 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:08:22 - INFO - __main__ -     eval_ppl = 2.645\n",
      "07/27/2023 01:08:22 - INFO - __main__ -     global_step = 1667\n",
      "07/27/2023 01:08:22 - INFO - __main__ -     train_loss = 0.2026\n",
      "07/27/2023 01:08:22 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:08:24 - INFO - __main__ -     Best ppl:2.645\n",
      "07/27/2023 01:08:24 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:08:56 - INFO - __main__ -     bleu-4 = 68.71 \n",
      "07/27/2023 01:08:56 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:08:56 - INFO - __main__ -     Best bleu:68.71\n",
      "07/27/2023 01:08:56 - INFO - __main__ -     ********************\n",
      "epoch 17 loss 0.1664: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:10:18 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:10:18 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:10:18 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:10:21 - INFO - __main__ -     eval_ppl = 2.58967\n",
      "07/27/2023 01:10:21 - INFO - __main__ -     global_step = 1765\n",
      "07/27/2023 01:10:21 - INFO - __main__ -     train_loss = 0.1664\n",
      "07/27/2023 01:10:21 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:10:23 - INFO - __main__ -     Best ppl:2.58967\n",
      "07/27/2023 01:10:23 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:10:55 - INFO - __main__ -     bleu-4 = 68.86 \n",
      "07/27/2023 01:10:55 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:10:55 - INFO - __main__ -     Best bleu:68.86\n",
      "07/27/2023 01:10:55 - INFO - __main__ -     ********************\n",
      "epoch 18 loss 0.1309: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:12:17 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:12:17 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:12:17 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:12:20 - INFO - __main__ -     eval_ppl = 2.5878\n",
      "07/27/2023 01:12:20 - INFO - __main__ -     global_step = 1863\n",
      "07/27/2023 01:12:20 - INFO - __main__ -     train_loss = 0.1309\n",
      "07/27/2023 01:12:20 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:12:22 - INFO - __main__ -     Best ppl:2.5878\n",
      "07/27/2023 01:12:22 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:12:55 - INFO - __main__ -     bleu-4 = 68.89 \n",
      "07/27/2023 01:12:55 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:12:55 - INFO - __main__ -     Best bleu:68.89\n",
      "07/27/2023 01:12:55 - INFO - __main__ -     ********************\n",
      "epoch 19 loss 0.1087: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:14:16 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:14:16 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:14:16 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:14:20 - INFO - __main__ -     eval_ppl = 2.63305\n",
      "07/27/2023 01:14:20 - INFO - __main__ -     global_step = 1961\n",
      "07/27/2023 01:14:20 - INFO - __main__ -     train_loss = 0.1087\n",
      "07/27/2023 01:14:20 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:14:51 - INFO - __main__ -     bleu-4 = 68.64 \n",
      "07/27/2023 01:14:51 - INFO - __main__ -     ********************\n",
      "epoch 20 loss 0.0882:  82%|█████████████████▏   | 80/98 [01:05<00:14,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 loss 0.0881: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:16:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:16:10 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:16:10 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:16:14 - INFO - __main__ -     eval_ppl = 2.6222\n",
      "07/27/2023 01:16:14 - INFO - __main__ -     global_step = 2059\n",
      "07/27/2023 01:16:14 - INFO - __main__ -     train_loss = 0.0881\n",
      "07/27/2023 01:16:14 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:16:44 - INFO - __main__ -     bleu-4 = 69.09 \n",
      "07/27/2023 01:16:44 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:16:44 - INFO - __main__ -     Best bleu:69.09\n",
      "07/27/2023 01:16:44 - INFO - __main__ -     ********************\n",
      "epoch 21 loss 0.0723: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:18:07 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:18:07 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:18:07 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:18:10 - INFO - __main__ -     eval_ppl = 2.65095\n",
      "07/27/2023 01:18:10 - INFO - __main__ -     global_step = 2157\n",
      "07/27/2023 01:18:10 - INFO - __main__ -     train_loss = 0.0723\n",
      "07/27/2023 01:18:10 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:18:41 - INFO - __main__ -     bleu-4 = 70.49 \n",
      "07/27/2023 01:18:41 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:18:41 - INFO - __main__ -     Best bleu:70.49\n",
      "07/27/2023 01:18:41 - INFO - __main__ -     ********************\n",
      "epoch 22 loss 0.0637: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:20:02 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:20:02 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:20:02 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:20:06 - INFO - __main__ -     eval_ppl = 2.59073\n",
      "07/27/2023 01:20:06 - INFO - __main__ -     global_step = 2255\n",
      "07/27/2023 01:20:06 - INFO - __main__ -     train_loss = 0.0637\n",
      "07/27/2023 01:20:06 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:20:38 - INFO - __main__ -     bleu-4 = 71.96 \n",
      "07/27/2023 01:20:38 - INFO - __main__ -     ********************\n",
      "07/27/2023 01:20:38 - INFO - __main__ -     Best bleu:71.96\n",
      "07/27/2023 01:20:38 - INFO - __main__ -     ********************\n",
      "epoch 23 loss 0.0529: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:22:00 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:22:00 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:22:00 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:22:03 - INFO - __main__ -     eval_ppl = 2.62323\n",
      "07/27/2023 01:22:03 - INFO - __main__ -     global_step = 2353\n",
      "07/27/2023 01:22:03 - INFO - __main__ -     train_loss = 0.0529\n",
      "07/27/2023 01:22:03 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:22:35 - INFO - __main__ -     bleu-4 = 70.64 \n",
      "07/27/2023 01:22:35 - INFO - __main__ -     ********************\n",
      "epoch 25 loss 0.0408: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:25:50 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:25:50 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:25:50 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:25:53 - INFO - __main__ -     eval_ppl = 2.62091\n",
      "07/27/2023 01:25:53 - INFO - __main__ -     global_step = 2549\n",
      "07/27/2023 01:25:53 - INFO - __main__ -     train_loss = 0.0408\n",
      "07/27/2023 01:25:53 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:26:25 - INFO - __main__ -     bleu-4 = 71.45 \n",
      "07/27/2023 01:26:25 - INFO - __main__ -     ********************\n",
      "epoch 26 loss 0.0369: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:27:45 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:27:45 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:27:45 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:27:49 - INFO - __main__ -     eval_ppl = 2.62519\n",
      "07/27/2023 01:27:49 - INFO - __main__ -     global_step = 2647\n",
      "07/27/2023 01:27:49 - INFO - __main__ -     train_loss = 0.0369\n",
      "07/27/2023 01:27:49 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:28:20 - INFO - __main__ -     bleu-4 = 70.6 \n",
      "07/27/2023 01:28:20 - INFO - __main__ -     ********************\n",
      "epoch 27 loss 0.034: 100%|██████████████████████| 98/98 [01:19<00:00,  1.24it/s]\n",
      "07/27/2023 01:29:39 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:29:39 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:29:39 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:29:43 - INFO - __main__ -     eval_ppl = 2.69026\n",
      "07/27/2023 01:29:43 - INFO - __main__ -     global_step = 2745\n",
      "07/27/2023 01:29:43 - INFO - __main__ -     train_loss = 0.034\n",
      "07/27/2023 01:29:43 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:30:15 - INFO - __main__ -     bleu-4 = 71.17 \n",
      "07/27/2023 01:30:15 - INFO - __main__ -     ********************\n",
      "epoch 28 loss 0.0339: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:31:34 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:31:34 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:31:34 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:31:38 - INFO - __main__ -     eval_ppl = 2.63298\n",
      "07/27/2023 01:31:38 - INFO - __main__ -     global_step = 2843\n",
      "07/27/2023 01:31:38 - INFO - __main__ -     train_loss = 0.0339\n",
      "07/27/2023 01:31:38 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:32:09 - INFO - __main__ -     bleu-4 = 70.83 \n",
      "07/27/2023 01:32:09 - INFO - __main__ -     ********************\n",
      "epoch 29 loss 0.0285: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:33:28 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:33:28 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:33:28 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:33:32 - INFO - __main__ -     eval_ppl = 2.67713\n",
      "07/27/2023 01:33:32 - INFO - __main__ -     global_step = 2941\n",
      "07/27/2023 01:33:32 - INFO - __main__ -     train_loss = 0.0285\n",
      "07/27/2023 01:33:32 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:34:04 - INFO - __main__ -     bleu-4 = 71.15 \n",
      "07/27/2023 01:34:04 - INFO - __main__ -     ********************\n",
      "epoch 30 loss 0.0246: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:35:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:35:25 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:35:25 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:35:28 - INFO - __main__ -     eval_ppl = 2.67863\n",
      "07/27/2023 01:35:28 - INFO - __main__ -     global_step = 3039\n",
      "07/27/2023 01:35:28 - INFO - __main__ -     train_loss = 0.0246\n",
      "07/27/2023 01:35:28 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:36:00 - INFO - __main__ -     bleu-4 = 69.29 \n",
      "07/27/2023 01:36:00 - INFO - __main__ -     ********************\n",
      "epoch 31 loss 0.0219: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:37:20 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:37:20 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:37:20 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:37:23 - INFO - __main__ -     eval_ppl = 2.66326\n",
      "07/27/2023 01:37:23 - INFO - __main__ -     global_step = 3137\n",
      "07/27/2023 01:37:23 - INFO - __main__ -     train_loss = 0.0219\n",
      "07/27/2023 01:37:23 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:37:55 - INFO - __main__ -     bleu-4 = 70.35 \n",
      "07/27/2023 01:37:55 - INFO - __main__ -     ********************\n",
      "epoch 32 loss 0.0211: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:39:15 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:39:15 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:39:15 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:39:19 - INFO - __main__ -     eval_ppl = 2.70933\n",
      "07/27/2023 01:39:19 - INFO - __main__ -     global_step = 3235\n",
      "07/27/2023 01:39:19 - INFO - __main__ -     train_loss = 0.0211\n",
      "07/27/2023 01:39:19 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:39:50 - INFO - __main__ -     bleu-4 = 71.02 \n",
      "07/27/2023 01:39:50 - INFO - __main__ -     ********************\n",
      "epoch 33 loss 0.0201: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:41:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:41:10 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:41:10 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:41:13 - INFO - __main__ -     eval_ppl = 2.67253\n",
      "07/27/2023 01:41:13 - INFO - __main__ -     global_step = 3333\n",
      "07/27/2023 01:41:13 - INFO - __main__ -     train_loss = 0.0201\n",
      "07/27/2023 01:41:13 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:41:45 - INFO - __main__ -     bleu-4 = 70.64 \n",
      "07/27/2023 01:41:45 - INFO - __main__ -     ********************\n",
      "epoch 34 loss 0.0192: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:43:05 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:43:05 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:43:05 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:43:08 - INFO - __main__ -     eval_ppl = 2.68448\n",
      "07/27/2023 01:43:08 - INFO - __main__ -     global_step = 3431\n",
      "07/27/2023 01:43:08 - INFO - __main__ -     train_loss = 0.0192\n",
      "07/27/2023 01:43:08 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:43:39 - INFO - __main__ -     bleu-4 = 71.86 \n",
      "07/27/2023 01:43:39 - INFO - __main__ -     ********************\n",
      "epoch 35 loss 0.0198: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:44:59 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:44:59 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:44:59 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:45:02 - INFO - __main__ -     eval_ppl = 2.73405\n",
      "07/27/2023 01:45:02 - INFO - __main__ -     global_step = 3529\n",
      "07/27/2023 01:45:02 - INFO - __main__ -     train_loss = 0.0198\n",
      "07/27/2023 01:45:02 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:45:33 - INFO - __main__ -     bleu-4 = 70.14 \n",
      "07/27/2023 01:45:33 - INFO - __main__ -     ********************\n",
      "epoch 36 loss 0.0163: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:46:54 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:46:54 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:46:54 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:46:57 - INFO - __main__ -     eval_ppl = 2.75122\n",
      "07/27/2023 01:46:57 - INFO - __main__ -     global_step = 3627\n",
      "07/27/2023 01:46:57 - INFO - __main__ -     train_loss = 0.0163\n",
      "07/27/2023 01:46:57 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:47:29 - INFO - __main__ -     bleu-4 = 71.21 \n",
      "07/27/2023 01:47:29 - INFO - __main__ -     ********************\n",
      "epoch 37 loss 0.0166: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 01:48:49 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:48:49 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:48:49 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:48:52 - INFO - __main__ -     eval_ppl = 2.74968\n",
      "07/27/2023 01:48:52 - INFO - __main__ -     global_step = 3725\n",
      "07/27/2023 01:48:52 - INFO - __main__ -     train_loss = 0.0166\n",
      "07/27/2023 01:48:52 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:49:24 - INFO - __main__ -     bleu-4 = 70.98 \n",
      "07/27/2023 01:49:24 - INFO - __main__ -     ********************\n",
      "epoch 38 loss 0.0154: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:50:44 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:50:44 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:50:44 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:50:47 - INFO - __main__ -     eval_ppl = 2.72522\n",
      "07/27/2023 01:50:47 - INFO - __main__ -     global_step = 3823\n",
      "07/27/2023 01:50:47 - INFO - __main__ -     train_loss = 0.0154\n",
      "07/27/2023 01:50:47 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:51:18 - INFO - __main__ -     bleu-4 = 70.15 \n",
      "07/27/2023 01:51:18 - INFO - __main__ -     ********************\n",
      "epoch 39 loss 0.0145: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 01:52:38 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 01:52:38 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 01:52:38 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 01:52:41 - INFO - __main__ -     eval_ppl = 2.767\n",
      "07/27/2023 01:52:41 - INFO - __main__ -     global_step = 3921\n",
      "07/27/2023 01:52:41 - INFO - __main__ -     train_loss = 0.0145\n",
      "07/27/2023 01:52:41 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 01:53:13 - INFO - __main__ -     bleu-4 = 69.79 \n",
      "07/27/2023 01:53:13 - INFO - __main__ -     ********************\n",
      "epoch 40 loss 0.012:  55%|████████████          | 54/98 [00:44<00:35,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79 loss 0.004: 100%|██████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:09:16 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:09:16 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:09:16 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:09:19 - INFO - __main__ -     eval_ppl = 2.91081\n",
      "07/27/2023 03:09:19 - INFO - __main__ -     global_step = 7841\n",
      "07/27/2023 03:09:19 - INFO - __main__ -     train_loss = 0.004\n",
      "07/27/2023 03:09:19 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:09:52 - INFO - __main__ -     bleu-4 = 71.76 \n",
      "07/27/2023 03:09:52 - INFO - __main__ -     ********************\n",
      "epoch 80 loss 0.0045: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:11:12 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:11:12 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:11:12 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:11:15 - INFO - __main__ -     eval_ppl = 2.89799\n",
      "07/27/2023 03:11:15 - INFO - __main__ -     global_step = 7939\n",
      "07/27/2023 03:11:15 - INFO - __main__ -     train_loss = 0.0045\n",
      "07/27/2023 03:11:15 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:11:47 - INFO - __main__ -     bleu-4 = 71.23 \n",
      "07/27/2023 03:11:47 - INFO - __main__ -     ********************\n",
      "epoch 81 loss 0.0045: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:13:07 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:13:07 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:13:07 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:13:10 - INFO - __main__ -     eval_ppl = 2.93916\n",
      "07/27/2023 03:13:10 - INFO - __main__ -     global_step = 8037\n",
      "07/27/2023 03:13:10 - INFO - __main__ -     train_loss = 0.0045\n",
      "07/27/2023 03:13:10 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:13:42 - INFO - __main__ -     bleu-4 = 71.14 \n",
      "07/27/2023 03:13:42 - INFO - __main__ -     ********************\n",
      "epoch 82 loss 0.0041: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:15:02 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:15:02 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:15:02 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:15:06 - INFO - __main__ -     eval_ppl = 2.91871\n",
      "07/27/2023 03:15:06 - INFO - __main__ -     global_step = 8135\n",
      "07/27/2023 03:15:06 - INFO - __main__ -     train_loss = 0.0041\n",
      "07/27/2023 03:15:06 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:15:37 - INFO - __main__ -     bleu-4 = 71.17 \n",
      "07/27/2023 03:15:37 - INFO - __main__ -     ********************\n",
      "epoch 83 loss 0.0038: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:16:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:16:57 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:16:57 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:17:00 - INFO - __main__ -     eval_ppl = 2.93249\n",
      "07/27/2023 03:17:00 - INFO - __main__ -     global_step = 8233\n",
      "07/27/2023 03:17:00 - INFO - __main__ -     train_loss = 0.0038\n",
      "07/27/2023 03:17:00 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:17:32 - INFO - __main__ -     bleu-4 = 70.11 \n",
      "07/27/2023 03:17:32 - INFO - __main__ -     ********************\n",
      "epoch 84 loss 0.0041: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:18:51 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:18:51 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:18:51 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:18:55 - INFO - __main__ -     eval_ppl = 2.90641\n",
      "07/27/2023 03:18:55 - INFO - __main__ -     global_step = 8331\n",
      "07/27/2023 03:18:55 - INFO - __main__ -     train_loss = 0.0041\n",
      "07/27/2023 03:18:55 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:19:26 - INFO - __main__ -     bleu-4 = 71.57 \n",
      "07/27/2023 03:19:26 - INFO - __main__ -     ********************\n",
      "epoch 85 loss 0.0036: 100%|█████████████████████| 98/98 [01:19<00:00,  1.24it/s]\n",
      "07/27/2023 03:20:45 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:20:45 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:20:45 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:20:49 - INFO - __main__ -     eval_ppl = 2.89372\n",
      "07/27/2023 03:20:49 - INFO - __main__ -     global_step = 8429\n",
      "07/27/2023 03:20:49 - INFO - __main__ -     train_loss = 0.0036\n",
      "07/27/2023 03:20:49 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:21:20 - INFO - __main__ -     bleu-4 = 71.39 \n",
      "07/27/2023 03:21:20 - INFO - __main__ -     ********************\n",
      "epoch 87 loss 0.0036: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:24:34 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:24:34 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:24:34 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:24:37 - INFO - __main__ -     eval_ppl = 2.91187\n",
      "07/27/2023 03:24:37 - INFO - __main__ -     global_step = 8625\n",
      "07/27/2023 03:24:37 - INFO - __main__ -     train_loss = 0.0036\n",
      "07/27/2023 03:24:37 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:25:09 - INFO - __main__ -     bleu-4 = 72.42 \n",
      "07/27/2023 03:25:09 - INFO - __main__ -     ********************\n",
      "07/27/2023 03:25:09 - INFO - __main__ -     Best bleu:72.42\n",
      "07/27/2023 03:25:09 - INFO - __main__ -     ********************\n",
      "epoch 88 loss 0.0038: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:26:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:26:31 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:26:31 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:26:34 - INFO - __main__ -     eval_ppl = 2.91855\n",
      "07/27/2023 03:26:34 - INFO - __main__ -     global_step = 8723\n",
      "07/27/2023 03:26:34 - INFO - __main__ -     train_loss = 0.0038\n",
      "07/27/2023 03:26:34 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:27:06 - INFO - __main__ -     bleu-4 = 71.32 \n",
      "07/27/2023 03:27:06 - INFO - __main__ -     ********************\n",
      "epoch 89 loss 0.0035: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:28:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:28:25 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:28:25 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:28:29 - INFO - __main__ -     eval_ppl = 2.92453\n",
      "07/27/2023 03:28:29 - INFO - __main__ -     global_step = 8821\n",
      "07/27/2023 03:28:29 - INFO - __main__ -     train_loss = 0.0035\n",
      "07/27/2023 03:28:29 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:29:01 - INFO - __main__ -     bleu-4 = 71.43 \n",
      "07/27/2023 03:29:01 - INFO - __main__ -     ********************\n",
      "epoch 90 loss 0.0035: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:30:20 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:30:20 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:30:20 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:30:24 - INFO - __main__ -     eval_ppl = 2.92093\n",
      "07/27/2023 03:30:24 - INFO - __main__ -     global_step = 8919\n",
      "07/27/2023 03:30:24 - INFO - __main__ -     train_loss = 0.0035\n",
      "07/27/2023 03:30:24 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:30:55 - INFO - __main__ -     bleu-4 = 71.48 \n",
      "07/27/2023 03:30:55 - INFO - __main__ -     ********************\n",
      "epoch 91 loss 0.0034: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:32:15 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:32:15 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:32:15 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:32:19 - INFO - __main__ -     eval_ppl = 2.91636\n",
      "07/27/2023 03:32:19 - INFO - __main__ -     global_step = 9017\n",
      "07/27/2023 03:32:19 - INFO - __main__ -     train_loss = 0.0034\n",
      "07/27/2023 03:32:19 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:32:50 - INFO - __main__ -     bleu-4 = 71.7 \n",
      "07/27/2023 03:32:50 - INFO - __main__ -     ********************\n",
      "epoch 92 loss 0.0036: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:34:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:34:10 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:34:10 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:34:14 - INFO - __main__ -     eval_ppl = 2.90979\n",
      "07/27/2023 03:34:14 - INFO - __main__ -     global_step = 9115\n",
      "07/27/2023 03:34:14 - INFO - __main__ -     train_loss = 0.0036\n",
      "07/27/2023 03:34:14 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:34:46 - INFO - __main__ -     bleu-4 = 71.24 \n",
      "07/27/2023 03:34:46 - INFO - __main__ -     ********************\n",
      "epoch 93 loss 0.0034: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:36:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:36:06 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:36:06 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:36:09 - INFO - __main__ -     eval_ppl = 2.91808\n",
      "07/27/2023 03:36:09 - INFO - __main__ -     global_step = 9213\n",
      "07/27/2023 03:36:09 - INFO - __main__ -     train_loss = 0.0034\n",
      "07/27/2023 03:36:09 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:36:41 - INFO - __main__ -     bleu-4 = 71.74 \n",
      "07/27/2023 03:36:41 - INFO - __main__ -     ********************\n",
      "epoch 94 loss 0.0031: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:38:01 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:38:01 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:38:01 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:38:04 - INFO - __main__ -     eval_ppl = 2.93053\n",
      "07/27/2023 03:38:04 - INFO - __main__ -     global_step = 9311\n",
      "07/27/2023 03:38:04 - INFO - __main__ -     train_loss = 0.0031\n",
      "07/27/2023 03:38:04 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:38:37 - INFO - __main__ -     bleu-4 = 71.59 \n",
      "07/27/2023 03:38:37 - INFO - __main__ -     ********************\n",
      "epoch 95 loss 0.0031: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:39:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:39:57 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:39:57 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:40:00 - INFO - __main__ -     eval_ppl = 2.92583\n",
      "07/27/2023 03:40:00 - INFO - __main__ -     global_step = 9409\n",
      "07/27/2023 03:40:00 - INFO - __main__ -     train_loss = 0.0031\n",
      "07/27/2023 03:40:00 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:40:33 - INFO - __main__ -     bleu-4 = 72.05 \n",
      "07/27/2023 03:40:33 - INFO - __main__ -     ********************\n",
      "epoch 96 loss 0.003: 100%|██████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:41:53 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:41:53 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:41:53 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:41:56 - INFO - __main__ -     eval_ppl = 2.92927\n",
      "07/27/2023 03:41:56 - INFO - __main__ -     global_step = 9507\n",
      "07/27/2023 03:41:56 - INFO - __main__ -     train_loss = 0.003\n",
      "07/27/2023 03:41:56 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:42:28 - INFO - __main__ -     bleu-4 = 71.95 \n",
      "07/27/2023 03:42:28 - INFO - __main__ -     ********************\n",
      "epoch 97 loss 0.0029: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:43:48 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:43:48 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:43:48 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:43:51 - INFO - __main__ -     eval_ppl = 2.93462\n",
      "07/27/2023 03:43:51 - INFO - __main__ -     global_step = 9605\n",
      "07/27/2023 03:43:51 - INFO - __main__ -     train_loss = 0.0029\n",
      "07/27/2023 03:43:51 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:44:24 - INFO - __main__ -     bleu-4 = 71.41 \n",
      "07/27/2023 03:44:24 - INFO - __main__ -     ********************\n",
      "epoch 98 loss 0.0028: 100%|█████████████████████| 98/98 [01:20<00:00,  1.22it/s]\n",
      "07/27/2023 03:45:44 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:45:44 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:45:44 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:45:48 - INFO - __main__ -     eval_ppl = 2.92877\n",
      "07/27/2023 03:45:48 - INFO - __main__ -     global_step = 9703\n",
      "07/27/2023 03:45:48 - INFO - __main__ -     train_loss = 0.0028\n",
      "07/27/2023 03:45:48 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:46:19 - INFO - __main__ -     bleu-4 = 71.9 \n",
      "07/27/2023 03:46:19 - INFO - __main__ -     ********************\n",
      "epoch 99 loss 0.0028: 100%|█████████████████████| 98/98 [01:19<00:00,  1.23it/s]\n",
      "07/27/2023 03:47:39 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/27/2023 03:47:39 - INFO - __main__ -     Num examples = 540\n",
      "07/27/2023 03:47:39 - INFO - __main__ -     Batch size = 50\n",
      "07/27/2023 03:47:42 - INFO - __main__ -     eval_ppl = 2.92849\n",
      "07/27/2023 03:47:42 - INFO - __main__ -     global_step = 9801\n",
      "07/27/2023 03:47:42 - INFO - __main__ -     train_loss = 0.0028\n",
      "07/27/2023 03:47:42 - INFO - __main__ -     ********************\n",
      "Total: 540\n",
      "07/27/2023 03:48:15 - INFO - __main__ -     bleu-4 = 71.64 \n",
      "07/27/2023 03:48:15 - INFO - __main__ -     ********************\n"
     ]
    }
   ],
   "source": [
    "lr = 5e-5\n",
    "batch_size = 50 # change depending on the GPU Colab gives you\n",
    "beam_size = 10\n",
    "source_length = args.max_source_length\n",
    "target_length = args.max_target_length\n",
    "data_dir = 'tmp_data'\n",
    "output_dir = f'{args.save_dir}/{args.prefix}_{args.task}'\n",
    "train_file = f'{data_dir}/{args.task}/train.jsonl'\n",
    "dev_file = f'{data_dir}/{args.task}/valid.jsonl'\n",
    "epochs = args.epochs \n",
    "pretrained_model = args.model_name\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_lower_case \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path {pretrained_model} \\\n",
    "    --train_filename {train_file} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --train_batch_size {batch_size} \\\n",
    "    --eval_batch_size {batch_size} \\\n",
    "    --learning_rate {lr} \\\n",
    "    --num_train_epochs {epochs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2023 03:48:18 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='tf_board/neulab_attack_vector', load_model_path='tf_board/neulab_attack_vector/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename='tmp_data/attack_vector/valid.jsonl', test_filename='tmp_data/attack_vector/test.jsonl', config_name='', tokenizer_name='', max_source_length=512, max_target_length=146, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/27/2023 03:48:18 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "07/27/2023 03:48:19 - INFO - __main__ -   reload model from tf_board/neulab_attack_vector/checkpoint-best-bleu/pytorch_model.bin\n",
      "07/27/2023 03:48:21 - INFO - __main__ -   Test file: tmp_data/attack_vector/valid.jsonl\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:31<00:00,  3.51s/it]\n",
      "Total: 540\n",
      "07/27/2023 03:48:54 - INFO - __main__ -     bleu-4 = 72.42 \n",
      "07/27/2023 03:48:54 - INFO - __main__ -     ********************\n",
      "07/27/2023 03:48:54 - INFO - __main__ -   Test file: tmp_data/attack_vector/test.jsonl\n",
      "100%|███████████████████████████████████████████| 22/22 [01:11<00:00,  3.26s/it]\n",
      "Total: 1350\n",
      "07/27/2023 03:50:08 - INFO - __main__ -     bleu-4 = 72.6 \n",
      "07/27/2023 03:50:08 - INFO - __main__ -     ********************\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "dev_file= f'{data_dir}/{args.task}/valid.jsonl'\n",
    "test_file=f\"{data_dir}/{args.task}/test.jsonl\"\n",
    "test_model=f\"{output_dir}/checkpoint-best-bleu/pytorch_model.bin\" #checkpoint for test\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_test \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path microsoft/codebert-base \\\n",
    "    --load_model_path {test_model} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --test_filename {test_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --eval_batch_size {batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name, do_lower_case=args.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neulab/codebert-cpp were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-cpp and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "config = RobertaConfig.from_pretrained(pretrained_model)\n",
    "encoder = RobertaModel.from_pretrained(pretrained_model, config = config)    \n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(encoder = encoder,decoder = decoder,config=config,\n",
    "                beam_size=beam_size,max_length=target_length,\n",
    "                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n",
    "model.load_state_dict(torch.load(Path(output_dir)/\"checkpoint-best-bleu/pytorch_model.bin\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static int aes_gcm_ctrl(EVP_CIPHER_CTX *c, int type, int arg, void *ptr) {  EVP_AES_GCM_CTX *gctx = EVP_C_DATA(EVP_AES_GCM_CTX,c);  switch (type) {  case EVP_CTRL_INIT:  gctx->key_set = 0;  gctx->iv_set = 0;  gctx->ivlen = EVP_CIPHER_CTX_iv_length(c);  gctx->iv = EVP_CIPHER_CTX_iv_noconst(c);  gctx->taglen = -1;  gctx->iv_gen = 0;  gctx->tls_aad_len = -1;  return 1;   case EVP_CTRL_AEAD_SET_IVLEN:  if (arg <= 0)  return 0;  /* Allocate memory for IV if needed */  if ((arg > EVP_MAX_IV_LENGTH) && (arg > gctx->ivlen)) {  if (gctx->iv != EVP_CIPHER_CTX_iv_noconst(c))  OPENSSL_free(gctx->iv);  gctx->iv = OPENSSL_malloc(arg);  if (gctx->iv == NULL)  return 0;  }  gctx->ivlen = arg;  return 1;   case EVP_CTRL_AEAD_SET_TAG:  if (arg <= 0 || arg > 16 || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->taglen = arg;  return 1;   case EVP_CTRL_AEAD_GET_TAG:  if (arg <= 0 || arg > 16 || !EVP_CIPHER_CTX_encrypting(c)  || gctx->taglen < 0)  return 0;  memcpy(ptr, EVP_CIPHER_CTX_buf_noconst(c), arg);  return 1;   case EVP_CTRL_GCM_SET_IV_FIXED:  /* Special case: -1 length restores whole IV */  if (arg == -1) {  memcpy(gctx->iv, ptr, gctx->ivlen);  gctx->iv_gen = 1;  return 1;  }  /*  * Fixed field must be at least 4 bytes and invocation field at least  * 8.  */  if ((arg < 4) || (gctx->ivlen - arg) < 8)  return 0;  if (arg)  memcpy(gctx->iv, ptr, arg);  if (EVP_CIPHER_CTX_encrypting(c)  && RAND_bytes(gctx->iv + arg, gctx->ivlen - arg) <= 0)  return 0;  gctx->iv_gen = 1;  return 1;   case EVP_CTRL_GCM_IV_GEN:  if (gctx->iv_gen == 0 || gctx->key_set == 0)  return 0;  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  if (arg <= 0 || arg > gctx->ivlen)  arg = gctx->ivlen;  memcpy(ptr, gctx->iv + gctx->ivlen - arg, arg);  /*  * Invocation field will be at least 8 bytes in size and so no need  * to check wrap around or increment more than last 8 bytes.  */  ctr64_inc(gctx->iv + gctx->ivlen - 8);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_GCM_SET_IV_INV:  if (gctx->iv_gen == 0 || gctx->key_set == 0  || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(gctx->iv + gctx->ivlen - arg, ptr, arg);  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_AEAD_TLS1_AAD:  /* Save the AAD for later use */  if (arg != EVP_AEAD_TLS1_AAD_LEN)  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->tls_aad_len = arg;  {  unsigned int len =  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] << 8  | EVP_CIPHER_CTX_buf_noconst(c)[arg - 1];  /* Correct length for explicit IV */  len -= EVP_GCM_TLS_EXPLICIT_IV_LEN;  /* If decrypting correct for tag too */  if (!EVP_CIPHER_CTX_encrypting(c))  len -= EVP_GCM_TLS_TAG_LEN;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] = len >> 8;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 1] = len & 0xff;  }  /* Extra padding: tag appended to record */  return EVP_GCM_TLS_TAG_LEN;   case EVP_CTRL_COPY:  {  EVP_CIPHER_CTX *out = ptr;  EVP_AES_GCM_CTX *gctx_out = EVP_C_DATA(EVP_AES_GCM_CTX,out);  if (gctx->gcm.key) {  if (gctx->gcm.key != &gctx->ks)  return 0;  gctx_out->gcm.key = &gctx_out->ks;  }  if (gctx->iv == EVP_CIPHER_CTX_iv_noconst(c))  gctx_out->iv = EVP_CIPHER_CTX_iv_noconst(out);  else {  gctx_out->iv = OPENSSL_malloc(gctx->ivlen);  if (gctx_out->iv == NULL)  return 0;  memcpy(gctx_out->iv, gctx->iv, gctx->ivlen);  }  return 1;  }   default:  return -1;   } } \n",
      "Original Comment: sending specially-crafted data\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "TEXT_TO_SUMMARIZE = df_test.func_before.values[idx]\n",
    "print('Code:', TEXT_TO_SUMMARIZE)\n",
    "print('Original Comment:', df_val.explain.values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from code2nl.run import convert_examples_to_features, Example\n",
    "\n",
    "def get_preds(df: pd.DataFrame):\n",
    "    ps = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        examples = [\n",
    "            Example(idx, source = row.func_before, target = row.explain)\n",
    "        ]\n",
    "        eval_features = convert_examples_to_features(\n",
    "            examples, tokenizer, args, stage='test'\n",
    "        )\n",
    "        source_ids = torch.tensor(eval_features[0].source_ids, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "        source_mask = torch.tensor(eval_features[0].source_mask, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(source_ids = source_ids, source_mask = source_mask)  \n",
    "            for pred in preds:\n",
    "                t = pred[0].cpu().numpy()\n",
    "                t = list(t)\n",
    "                if 0 in t:\n",
    "                    t = t[:t.index(0)]\n",
    "                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                ps.append(text)\n",
    "    \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0048902034759521484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 47,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1350,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe41270fcbd492482adf294625e5de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 512). Running this sequence through the model will result in indexing errors\n",
      "07/27/2023 04:35:32 - INFO - absl -   Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.7591651925483067,\n",
       " 'rouge2': 0.7005250615956675,\n",
       " 'rougeL': 0.7577446031994383,\n",
       " 'rougeLsum': 0.7568914274597773}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = df_test.reset_index()\n",
    "preds = get_preds(df_test)\n",
    "references = []\n",
    "for idx, row in df_test.iterrows():\n",
    "    # print('Code:', row.func_before)\n",
    "    # print('Original Comment:', row.explain)\n",
    "    # print('Generated Comment:', preds[idx])\n",
    "    # print('='*40)\n",
    "    references.append(row.explain)\n",
    "\n",
    "results = rouge.compute(predictions=preds, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static int aes_gcm_ctrl(EVP_CIPHER_CTX *c, int type, int arg, void *ptr) {  EVP_AES_GCM_CTX *gctx = EVP_C_DATA(EVP_AES_GCM_CTX,c);  switch (type) {  case EVP_CTRL_INIT:  gctx->key_set = 0;  gctx->iv_set = 0;  gctx->ivlen = EVP_CIPHER_CTX_iv_length(c);  gctx->iv = EVP_CIPHER_CTX_iv_noconst(c);  gctx->taglen = -1;  gctx->iv_gen = 0;  gctx->tls_aad_len = -1;  return 1;   case EVP_CTRL_AEAD_SET_IVLEN:  if (arg <= 0)  return 0;  /* Allocate memory for IV if needed */  if ((arg > EVP_MAX_IV_LENGTH) && (arg > gctx->ivlen)) {  if (gctx->iv != EVP_CIPHER_CTX_iv_noconst(c))  OPENSSL_free(gctx->iv);  gctx->iv = OPENSSL_malloc(arg);  if (gctx->iv == NULL)  return 0;  }  gctx->ivlen = arg;  return 1;   case EVP_CTRL_AEAD_SET_TAG:  if (arg <= 0 || arg > 16 || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->taglen = arg;  return 1;   case EVP_CTRL_AEAD_GET_TAG:  if (arg <= 0 || arg > 16 || !EVP_CIPHER_CTX_encrypting(c)  || gctx->taglen < 0)  return 0;  memcpy(ptr, EVP_CIPHER_CTX_buf_noconst(c), arg);  return 1;   case EVP_CTRL_GCM_SET_IV_FIXED:  /* Special case: -1 length restores whole IV */  if (arg == -1) {  memcpy(gctx->iv, ptr, gctx->ivlen);  gctx->iv_gen = 1;  return 1;  }  /*  * Fixed field must be at least 4 bytes and invocation field at least  * 8.  */  if ((arg < 4) || (gctx->ivlen - arg) < 8)  return 0;  if (arg)  memcpy(gctx->iv, ptr, arg);  if (EVP_CIPHER_CTX_encrypting(c)  && RAND_bytes(gctx->iv + arg, gctx->ivlen - arg) <= 0)  return 0;  gctx->iv_gen = 1;  return 1;   case EVP_CTRL_GCM_IV_GEN:  if (gctx->iv_gen == 0 || gctx->key_set == 0)  return 0;  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  if (arg <= 0 || arg > gctx->ivlen)  arg = gctx->ivlen;  memcpy(ptr, gctx->iv + gctx->ivlen - arg, arg);  /*  * Invocation field will be at least 8 bytes in size and so no need  * to check wrap around or increment more than last 8 bytes.  */  ctr64_inc(gctx->iv + gctx->ivlen - 8);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_GCM_SET_IV_INV:  if (gctx->iv_gen == 0 || gctx->key_set == 0  || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(gctx->iv + gctx->ivlen - arg, ptr, arg);  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_AEAD_TLS1_AAD:  /* Save the AAD for later use */  if (arg != EVP_AEAD_TLS1_AAD_LEN)  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->tls_aad_len = arg;  {  unsigned int len =  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] << 8  | EVP_CIPHER_CTX_buf_noconst(c)[arg - 1];  /* Correct length for explicit IV */  len -= EVP_GCM_TLS_EXPLICIT_IV_LEN;  /* If decrypting correct for tag too */  if (!EVP_CIPHER_CTX_encrypting(c))  len -= EVP_GCM_TLS_TAG_LEN;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] = len >> 8;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 1] = len & 0xff;  }  /* Extra padding: tag appended to record */  return EVP_GCM_TLS_TAG_LEN;   case EVP_CTRL_COPY:  {  EVP_CIPHER_CTX *out = ptr;  EVP_AES_GCM_CTX *gctx_out = EVP_C_DATA(EVP_AES_GCM_CTX,out);  if (gctx->gcm.key) {  if (gctx->gcm.key != &gctx->ks)  return 0;  gctx_out->gcm.key = &gctx_out->ks;  }  if (gctx->iv == EVP_CIPHER_CTX_iv_noconst(c))  gctx_out->iv = EVP_CIPHER_CTX_iv_noconst(out);  else {  gctx_out->iv = OPENSSL_malloc(gctx->ivlen);  if (gctx_out->iv == NULL)  return 0;  memcpy(gctx_out->iv, gctx->iv, gctx->ivlen);  }  return 1;  }   default:  return -1;   } } \n",
      "Original Comment: sending specially crafted truncated packets\n",
      "Generated Comment: sending specially crafted truncated packets\n",
      "========================================\n",
      "Code: void BluetoothDeviceChromeOS::OnUnregisterAgentError(  const std::string& error_name,  const std::string& error_message) {  LOG(WARNING) << object_path_.value() << \": Failed to unregister agent: \"  << error_name << \": \" << error_message; } \n",
      "Original Comment: via a crafted web site .\n",
      "Generated Comment: via a crafted web site .\n",
      "========================================\n",
      "Code:  static void unregisterBlobURLTask(void* context)  {  OwnPtr<BlobRegistryContext> blobRegistryContext = adoptPtr(static_cast<BlobRegistryContext*>(context));  blobRegistry().unregisterBlobURL(blobRegistryContext->url);  } \n",
      "Original Comment: via unknown vectors .\n",
      "Generated Comment: via unknown vectors .\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_test.head(3).iterrows():\n",
    "    print('Code:', row.func_before)\n",
    "    print('Original Comment:', row.explain)\n",
    "    print('Generated Comment:', preds[idx])\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
