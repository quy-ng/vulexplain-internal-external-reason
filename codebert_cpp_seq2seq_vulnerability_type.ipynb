{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from project_dataset import load_dataset\n",
    "from code2nl.model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_name = \"neulab/codebert-cpp\"\n",
    "    num_proc = 4\n",
    "    batch_size = 50\n",
    "    max_source_length = 512  \n",
    "    max_target_length = 53 \n",
    "    data_cols = [\"CVE ID\", \"explain\", \"func_before\"]\n",
    "    save_dir = 'tf_board'\n",
    "    epochs = 100\n",
    "    grad_acc_steps = 4\n",
    "    lr = 5e-5\n",
    "    log_freq = 10\n",
    "    local_rank = -1\n",
    "    deepspeed = None\n",
    "    fp16 = False\n",
    "    lr_warmup_steps = 200\n",
    "    weight_decay = 0.05\n",
    "    task = \"vulnerability_type\"\n",
    "    prefix = 'neulab'\n",
    "    do_lower_case = False\n",
    "    beam_size = 10\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(args.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 3870\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 431\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 1076\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds['train']\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "df_val = ds['validation']\n",
    "df_val = df_val.to_pandas()\n",
    "\n",
    "df_test = ds['test']\n",
    "df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVE ID</th>\n",
       "      <th>explain</th>\n",
       "      <th>func_before</th>\n",
       "      <th>processed_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-2018-16066</td>\n",
       "      <td>out-of-bounds read</td>\n",
       "      <td>Node::InsertionNotificationRequest SVGStyleEl...</td>\n",
       "      <td>Node::InsertionNotificationRequest SVGStyleEle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-2015-2695</td>\n",
       "      <td>pointer type</td>\n",
       "      <td>spnego_gss_init_sec_context(    OM_uint32 *min...</td>\n",
       "      <td>spnego_gss_init_sec_context(OM_uint32 *minor_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-2011-2861</td>\n",
       "      <td>string read</td>\n",
       "      <td>void RenderThread::Init() {  TRACE_EVENT_BEGIN...</td>\n",
       "      <td>void RenderThread::Init() {\\n  TRACE_EVENT_BEG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CVE ID             explain  \\\n",
       "0  CVE-2018-16066  out-of-bounds read   \n",
       "1   CVE-2015-2695        pointer type   \n",
       "2   CVE-2011-2861         string read   \n",
       "\n",
       "                                         func_before  \\\n",
       "0   Node::InsertionNotificationRequest SVGStyleEl...   \n",
       "1  spnego_gss_init_sec_context(    OM_uint32 *min...   \n",
       "2  void RenderThread::Init() {  TRACE_EVENT_BEGIN...   \n",
       "\n",
       "                                      processed_func  \n",
       "0  Node::InsertionNotificationRequest SVGStyleEle...  \n",
       "1  spnego_gss_init_sec_context(OM_uint32 *minor_s...  \n",
       "2  void RenderThread::Init() {\\n  TRACE_EVENT_BEG...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "os.makedirs(f'tmp_data/{args.task}', exist_ok=True)\n",
    "os.makedirs(f'{args.save_dir}/{args.prefix}_{args.task}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_train['code_tokens'] = df_train.func_before.apply(lambda x: x.split())\n",
    "df_train['docstring_tokens'] = df_train.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/train.jsonl','w') as f:\n",
    "    for _, row in df_train.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_val['code_tokens'] = df_val.func_before.apply(lambda x: x.split())\n",
    "df_val['docstring_tokens'] = df_val.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/valid.jsonl','w') as f:\n",
    "    for _, row in df_val.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_test['code_tokens'] = df_test.func_before.apply(lambda x: x.split())\n",
    "df_test['docstring_tokens'] = df_test.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/test.jsonl','w') as f:\n",
    "    for _, row in df_test.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:33:34 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='neulab/codebert-cpp', output_dir='tf_board/neulab_vulnerability_type', load_model_path=None, train_filename='tmp_data/vulnerability_type/train.jsonl', dev_filename='tmp_data/vulnerability_type/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=53, do_train=True, do_eval=True, do_test=False, do_lower_case=True, no_cuda=False, train_batch_size=50, eval_batch_size=50, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/21/2023 22:33:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "Some weights of the model checkpoint at neulab/codebert-cpp were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-cpp and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   *** Example ***\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   idx: 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_tokens: ['<s>', 'Node', '::', 'Insert', 'ion', 'Not', 'ification', 'Request', '_SV', 'GS', 'ty', 'le', 'Element', '::', 'Insert', 'ed', 'Int', 'o', '(', '_Container', 'Node', '*', '_insertion', '_', 'point', ')', '_{', '_SV', 'GE', 'lement', '::', 'Insert', 'ed', 'Int', 'o', '(', 'insert', 'ion', '_', 'point', ');', '_return', '_k', 'Insert', 'ion', 'Should', 'Call', 'Did', 'Not', 'ify', 'Sub', 'tree', 'Insert', 'ions', ';', '_}', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_ids: 0 48271 38304 48386 1499 7199 5000 45589 22753 10729 2553 459 46331 38304 48386 196 22886 139 1640 37424 48271 3226 43576 1215 2300 43 25522 22753 8800 13767 38304 48386 196 22886 139 1640 43675 1499 1215 2300 4397 671 449 48386 1499 31231 20653 20328 7199 4591 23055 21512 48386 2485 131 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_tokens: ['<s>', 'out', '-', 'of', '-', 'b', 'ounds', '_read', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_ids: 0 995 12 1116 12 428 12363 1166 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   *** Example ***\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   idx: 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_tokens: ['<s>', 'sp', 'ne', 'go', '_', 'g', 'ss', '_', 'init', '_', 'sec', '_', 'context', '(', '_OM', '_', 'uint', '32', '_*', 'min', 'or', '_', 'status', ',', '_g', 'ss', '_', 'c', 'red', '_', 'id', '_', 't', '_claimant', '_', 'c', 'red', '_', 'handle', ',', '_g', 'ss', '_', 'ctx', '_', 'id', '_', 't', '_*', 'context', '_', 'handle', ',', '_g', 'ss', '_', 'name', '_', 't', '_target', '_', 'name', ',', '_g', 'ss', '_', 'O', 'ID', '_mech', '_', 'type', ',', '_OM', '_', 'uint', '32', '_req', '_', 'flags', ',', '_OM', '_', 'uint', '32', '_time', '_', 'req', ',', '_g', 'ss', '_', 'channel', '_', 'bind', 'ings', '_', 't', '_input', '_', 'chan', '_', 'bind', 'ings', ',', '_g', 'ss', '_', 'buffer', '_', 't', '_input', '_', 'token', ',', '_g', 'ss', '_', 'O', 'ID', '_*', 'actual', '_', 'me', 'ch', ',', '_g', 'ss', '_', 'buffer', '_', 't', '_output', '_', 'token', ',', '_OM', '_', 'uint', '32', '_*', 'ret', '_', 'flags', ',', '_OM', '_', 'uint', '32', '_*', 'time', '_', 'rec', ')', '_{', '_send', '_', 'token', '_', 'flag', '_send', '_', 'token', '_=', '_NO', '_', 'TO', 'KEN', '_', 'S', 'END', ';', '_OM', '_', 'uint', '32', '_tmp', 'min', ',', '_ret', ',', '_neg', 'State', ';', '_g', 'ss', '_', 'buffer', '_', 't', '_me', 'cht', 'ok', '_', 'in', ',', '_mech', 'List', 'MIC', '_', 'in', ',', '_mech', 'List', 'MIC', '_', 'out', ';', '_g', 'ss', '_', 'buffer', '_', 'desc', '_me', 'cht', 'ok', '_', 'out', '_=', '_G', 'SS', '_', 'C', '_', 'EMP', 'TY', '_', 'BU', 'FFER', ';', '_sp', 'ne', 'go', '_', 'g', 'ss', '_', 'c', 'red', '_', 'id', '_', 't', '_sp', 'c', 'red', '_=', '_NULL', ';', '_sp', 'ne', 'go', '_', 'g', 'ss', '_', 'ctx', '_', 'id', '_', 't', '_sp', 'ne', 'go', '_', 'ctx', '_=', '_NULL', ';', '_d', 'sys', 'log', '(\"', 'Enter', 'ing', '_init', '_', 'sec', '_', 'context', '\\\\', 'n', '\");', '_me', 'cht', 'ok', '_', 'in', '_=', '_mech', 'List', 'MIC', '_', 'out', '_=', '_mech', 'List', 'MIC', '_', 'in', '_=', '_G', 'SS', '_', 'C', '_', 'NO', '_', 'BU', 'FFER', ';', '_neg', 'State', '_=', '_RE', 'JECT', ';', '_/*', '_*', '_This', '_function', '_works', '_in', '_three', '_steps', ':', '_*', '_*', '_1', '.', '_Perform', '_mechanism', '_negotiation', '.', '_*', '_2', '.', '_Inv', 'oke', '_the', '_negotiated', '_or', '_optimistic', '_mech', \"'s\", '_g', 'ss', '_', 'init', '_', 'sec', '_', 'context', '_*', '_function', '_and', '_examine', '_the', '_results', '.', '_*', '_3', '.', '_Process', '_or', '_generate', '_MIC', 's', '_if', '_necessary', '.', '_*', '_*', '_The', '_three', '_steps', '_share', '_responsibility', '_for', '_determining', '_when', '_the', '_*', '_exchange', '_is', '_complete', '.', '_If', '_the', '_selected', '_mech', '_completed', '_in', '_a', '_previous', '_*', '_call', '_and', '_no', '_MIC', '_exchange', '_is', '_expected', ',', '_then', '_step', '_1', '_will', '_decide', '.', '_If', '_*', '_the', '_selected', '_mech', '_completes', '_in', '_this', '_call', '_and', '_no', '_MIC', '_exchange', '_is', '_*', '_expected', ',', '_then', '_step', '_2', '_will', '_decide', '.', '_If', '_a', '_MIC', '_exchange', '_is', '_expected', ',', '_*', '_then', '_step', '_3', '_will', '_decide', '.', '_If', '_an', '_error', '_occurs', '_in', '_any', '_step', ',', '_the', '_*', '_exchange', '_will', '_be', '_aborted', ',', '_possibly', '_with', '_an', '_error', '_token', '.', '_*', '_*', '_neg', 'State', '_determines', '_the', '_state', '_of', '_the', '_negotiation', ',', '_and', '_is', '_*', '_communicated', '_to', '_the', '_accept', 'or', '_if', '_a', '_continuing', '_token', '_is', '_sent', '.', '_*', '_send', '_', 'token', '_is', '_used', '_to', '_indicate', '_what', '_type', '_of', '_token', ',', '_if', '_any', ',', '_should', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_ids: 0 4182 858 2977 1215 571 7485 1215 25153 1215 8584 1215 46796 1640 23765 1215 47157 2881 1009 4691 368 1215 29552 6 821 7485 1215 438 2050 1215 808 1215 90 42165 1215 438 2050 1215 26628 6 821 7485 1215 49575 1215 808 1215 90 1009 46796 1215 26628 6 821 7485 1215 13650 1215 90 1002 1215 13650 6 821 7485 1215 673 2688 46833 1215 12528 6 23765 1215 47157 2881 48829 1215 46760 6 23765 1215 47157 2881 86 1215 47278 6 821 7485 1215 27681 1215 41744 1033 1215 90 8135 1215 14717 1215 41744 1033 6 821 7485 1215 47438 1215 90 8135 1215 46657 6 821 7485 1215 673 2688 1009 44033 1215 1794 611 6 821 7485 1215 47438 1215 90 4195 1215 46657 6 23765 1215 47157 2881 1009 4903 1215 46760 6 23765 1215 47157 2881 1009 958 1215 13139 43 25522 2142 1215 46657 1215 30160 2142 1215 46657 5457 8228 1215 6390 41138 1215 104 9309 131 23765 1215 47157 2881 49443 4691 6 5494 6 15183 13360 131 821 7485 1215 47438 1215 90 162 8797 1638 1215 179 6 46833 36583 45717 1215 179 6 46833 36583 45717 1215 995 131 821 7485 1215 47438 1215 45091 162 8797 1638 1215 995 5457 272 8108 1215 347 1215 42257 6175 1215 19159 45234 131 2292 858 2977 1215 571 7485 1215 438 2050 1215 808 1215 90 2292 438 2050 5457 48955 131 2292 858 2977 1215 571 7485 1215 49575 1215 808 1215 90 2292 858 2977 1215 49575 5457 48955 131 385 43103 12376 46469 30078 154 45511 1215 8584 1215 46796 37457 282 45751 162 8797 1638 1215 179 5457 46833 36583 45717 1215 995 5457 46833 36583 45717 1215 179 5457 272 8108 1215 347 1215 13449 1215 19159 45234 131 15183 13360 5457 4979 33302 131 48565 1009 152 5043 1364 11 130 2402 35 1009 1009 112 4 24373 9562 14854 4 1009 132 4 9318 5361 5 12518 50 7168 46833 18 821 7485 1215 25153 1215 8584 1215 46796 1009 5043 8 10154 5 775 4 1009 155 4 19149 50 5368 29615 29 114 2139 4 1009 1009 20 130 2402 458 2640 13 13684 77 5 1009 2081 16 1498 4 318 5 3919 46833 2121 11 10 986 1009 486 8 117 29615 2081 16 421 6 172 1149 112 40 2845 4 318 1009 5 3919 46833 25830 11 42 486 8 117 29615 2081 16 1009 421 6 172 1149 132 40 2845 4 318 10 29615 2081 16 421 6 1009 172 1149 155 40 2845 4 318 41 5849 11493 11 143 1149 6 5 1009 2081 40 28 38166 6 3544 19 41 5849 19233 4 1009 1009 15183 13360 23483 5 194 9 5 14854 6 8 16 1009 21498 7 5 3264 368 114 10 3348 19233 16 1051 4 1009 2142 1215 46657 16 341 7 6364 99 1907 9 19233 6 114 143 6 197 2\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_tokens: ['<s>', 'pointer', '_type', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_ids: 0 10475 1907 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   *** Example ***\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   idx: 2\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_tokens: ['<s>', 'void', '_Render', 'Thread', '::', 'Init', '()', '_{', '_TR', 'ACE', '_', 'EV', 'ENT', '_', 'B', 'EGIN', '_', 'ET', 'W', '(\"', 'Render', 'Thread', '::', 'Init', '\",', '_0', ',', '_\"\"', ');', '_#', 'if', '_defined', '(', 'OS', '_', 'MAC', 'OS', 'X', ')', '_Web', 'Kit', '::', 'Web', 'View', '::', 'set', 'Use', 'External', 'Pop', 'up', 'Men', 'us', '(', 'true', ');', '_#', 'endif', '_lazy', '_', 't', 'ls', '.', 'Po', 'inter', '()', '->', 'Set', '(', 'this', ');', '_#', 'if', '_defined', '(', 'OS', '_', 'WIN', ')', '_if', '_(', 'Render', 'Process', 'Impl', '::', 'In', 'Process', 'Plug', 'ins', '())', '_Co', 'Initial', 'ize', '(', '0', ');', '_#', 'endif', '_suspend', '_', 'webkit', '_', 'shared', '_', 'timer', '_', '_=', '_true', ';', '_notify', '_', 'webkit', '_', 'of', '_', 'mod', 'al', '_', 'loop', '_', '_=', '_true', ';', '_plugin', '_', 'ref', 'resh', '_', 'allowed', '_', '_=', '_true', ';', '_widget', '_', 'count', '_', '_=', '_0', ';', '_hidden', '_', 'widget', '_', 'count', '_', '_=', '_0', ';', '_idle', '_', 'not', 'ification', '_', 'delay', '_', 'in', '_', 's', '_', '_=', '_k', 'Initial', 'Id', 'le', 'Handler', 'Del', 'ay', 'S', ';', '_task', '_', 'f', 'actory', '_.', 'reset', '(', 'new', '_Sc', 'oped', 'Run', 'n', 'able', 'Method', 'Factory', '<', 'Render', 'Thread', '>(', 'this', '));', '_app', 'cache', '_', 'dis', 'pat', 'cher', '_.', 'reset', '(', 'new', '_App', 'Cache', 'Dis', 'pat', 'cher', '(', 'this', '));', '_indexed', '_', 'db', '_', 'dis', 'pat', 'cher', '_.', 'reset', '(', 'new', '_Index', 'ed', 'DB', 'Dis', 'pat', 'cher', '());', '_db', '_', 'message', '_', 'filter', '_', '_=', '_new', '_D', 'BM', 'essage', 'Filter', '();', '_Add', 'Filter', '(', 'db', '_', 'message', '_', 'filter', '_.', 'get', '());', '_v', 'c', '_', 'manager', '_', '_=', '_new', '_Video', 'Capture', 'Impl', 'Manager', '();', '_Add', 'Filter', '(', 'vc', '_', 'manager', '_', '->', 'video', '_', 'capt', 'ure', '_', 'message', '_', 'filter', '());', '_audio', '_', 'input', '_', 'message', '_', 'filter', '_', '_=', '_new', '_Audio', 'Input', 'Message', 'Filter', '();', '_Add', 'Filter', '(', 'audio', '_', 'input', '_', 'message', '_', 'filter', '_.', 'get', '());', '_audio', '_', 'message', '_', 'filter', '_', '_=', '_new', '_Audio', 'Message', 'Filter', '();', '_Add', 'Filter', '(', 'audio', '_', 'message', '_', 'filter', '_.', 'get', '());', '_content', '::', 'Get', 'Content', 'Client', '()', '->', 'rend', 'erer', '()', '->', 'Render', 'Thread', 'Start', 'ed', '();', '_TR', 'ACE', '_', 'EV', 'ENT', '_', 'END', '_', 'ET', 'W', '(\"', 'Render', 'Thread', '::', 'Init', '\",', '_0', ',', '_\"\"', ');', '_}', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_ids: 0 47908 46804 47563 38304 49368 43048 25522 5758 15949 1215 19896 5382 1215 387 39764 1215 3935 771 46469 48440 47563 38304 49368 1297 321 6 41039 4397 849 1594 6533 1640 3196 1215 41458 3196 1000 43 6494 29233 38304 27521 22130 38304 8738 34447 47380 30255 658 17762 687 1640 29225 4397 849 49741 22414 1215 90 6634 4 26170 8007 43048 46613 28512 1640 9226 4397 849 1594 6533 1640 3196 1215 28974 43 114 36 48440 46202 48455 38304 1121 46202 48022 1344 49338 944 46187 2072 1640 288 4397 849 49741 13085 1215 49286 1215 42502 1215 36588 1215 5457 1528 131 18981 1215 49286 1215 1116 1215 14377 337 1215 31290 1215 5457 1528 131 43201 1215 13043 23053 1215 34742 1215 5457 1528 131 36859 1215 11432 1215 5457 321 131 7397 1215 48972 1215 11432 1215 5457 321 131 25562 1215 3654 5000 1215 46696 1215 179 1215 29 1215 5457 449 46187 28081 459 49191 21502 857 104 131 3685 1215 506 27670 47426 45703 1640 4651 2741 15911 33177 282 868 47967 47249 41552 48440 47563 49925 9226 48749 1553 47974 1215 7779 11632 5260 47426 45703 1640 4651 3166 48572 26402 11632 5260 1640 9226 48749 43220 1215 33845 1215 7779 11632 5260 47426 45703 1640 4651 4648 196 10842 26402 11632 5260 49291 45655 1215 44773 1215 46617 1215 5457 92 211 13386 49528 47625 47006 4287 47625 1640 33845 1215 44773 1215 46617 47426 6460 49291 748 438 1215 37096 1215 5457 92 5338 48097 48455 44854 47006 4287 47625 1640 36940 1215 37096 1215 46613 14406 1215 18543 2407 1215 44773 1215 46617 49291 6086 1215 46797 1215 44773 1215 46617 1215 5457 92 20555 48214 42394 47625 47006 4287 47625 1640 24846 1215 46797 1215 44773 1215 46617 47426 6460 49291 6086 1215 44773 1215 46617 1215 5457 92 20555 42394 47625 47006 4287 47625 1640 24846 1215 44773 1215 46617 47426 6460 49291 1383 38304 14181 45463 47952 43048 46613 10082 7160 43048 46613 48440 47563 33724 196 47006 5758 15949 1215 19896 5382 1215 9309 1215 3935 771 46469 48440 47563 38304 49368 1297 321 6 41039 4397 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_tokens: ['<s>', 'string', '_read', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_ids: 0 20951 1166 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   *** Example ***\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   idx: 3\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_void', '_copy', 'IP', 'v', '6', 'If', 'Different', '(', 'void', '_*', '_dest', ',', '_const', '_void', '_*', '_src', ')', '_{', '_if', '(', 'dest', '_!=', '_src', ')', '_{', '_mem', 'c', 'py', '(', 'dest', ',', '_src', ',', '_sizeof', '(', 'struct', '_in', '6', '_', 'addr', '));', '_}', '_}', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_ids: 0 42653 13842 5375 3808 705 401 1106 44863 1640 47908 1009 15357 6 10759 13842 1009 47215 43 25522 114 1640 31549 49333 47215 43 25522 26012 438 17163 1640 31549 6 47215 6 49907 1640 25384 11 401 1215 49439 48749 35524 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_tokens: ['<s>', 'pointer', '_de', 'reference', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_ids: 0 10475 263 45927 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   *** Example ***\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   idx: 4\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_tokens: ['<s>', 'xml', 'Par', 'se', 'Pub', 'id', 'L', 'it', 'eral', '(', 'xml', 'Parser', 'C', 'txt', 'Ptr', '_c', 'txt', ')', '_{', '_xml', 'Char', '_*', 'buf', '_=', '_NULL', ';', '_int', '_len', '_=', '_0', ';', '_int', '_size', '_=', '_XML', '_', 'PAR', 'SER', '_', 'BU', 'FFER', '_', 'SIZE', ';', '_xml', 'Char', '_cur', ';', '_xml', 'Char', '_stop', ';', '_int', '_count', '_=', '_0', ';', '_xml', 'Parser', 'Input', 'State', '_old', 'state', '_=', '_c', 'txt', '->', 'in', 'state', ';', '_SH', 'R', 'INK', ';', '_if', '_(', 'RAW', '_==', \"_'\", '\"', \"')\", '_{', '_NEXT', ';', '_stop', '_=', \"_'\", '\"', \"';\", '_}', '_else', '_if', '_(', 'RAW', '_==', \"_'\", '\\\\', \"''\", ')', '_{', '_NEXT', ';', '_stop', '_=', \"_'\", '\\\\', \"'';\", '_}', '_else', '_{', '_xml', 'F', 'atal', 'Er', 'r', '(', 'ct', 'xt', ',', '_XML', '_', 'ER', 'R', '_', 'L', 'IT', 'ERAL', '_', 'NOT', '_', 'ST', 'ART', 'ED', ',', '_NULL', ');', '_return', '(', 'NULL', ');', '_}', '_buf', '_=', '_(', 'xml', 'Char', '_*)', '_xml', 'M', 'alloc', 'At', 'omic', '(', 'size', '_*', '_sizeof', '(', 'xml', 'Char', '));', '_if', '_(', 'buf', '_==', '_NULL', ')', '_{', '_xml', 'Er', 'r', 'Memory', '(', 'ct', 'xt', ',', '_NULL', ');', '_return', '(', 'NULL', ');', '_}', '_c', 'txt', '->', 'in', 'state', '_=', '_XML', '_', 'PAR', 'SER', '_', 'PU', 'BLIC', '_', 'L', 'IT', 'ERAL', ';', '_cur', '_=', '_C', 'UR', ';', '_while', '_((', 'IS', '_', 'PU', 'B', 'ID', 'CHAR', '_', 'CH', '(', 'cur', '))', '_&&', '_(', 'cur', '_!=', '_stop', '))', '_{', '_/*', '_checked', '_*/', '_if', '_(', 'len', '_+', '_1', '_>=', '_size', ')', '_{', '_xml', 'Char', '_*', 'tmp', ';', '_size', '_*', '=', '_2', ';', '_tmp', '_=', '_(', 'xml', 'Char', '_*)', '_xml', 'Re', 'alloc', '(', 'buf', ',', '_size', '_*', '_sizeof', '(', 'xml', 'Char', '));', '_if', '_(', 'tmp', '_==', '_NULL', ')', '_{', '_xml', 'Er', 'r', 'Memory', '(', 'ct', 'xt', ',', '_NULL', ');', '_xml', 'Free', '(', 'buf', ');', '_return', '(', 'NULL', ');', '_}', '_buf', '_=', '_tmp', ';', '_}', '_buf', '[', 'len', '++', ']', '_=', '_cur', ';', '_count', '++;', '_if', '_(', 'count', '_>', '_50', ')', '_{', '_GR', 'OW', ';', '_count', '_=', '_0', ';', '_}', '_NEXT', ';', '_cur', '_=', '_C', 'UR', ';', '_if', '_(', 'cur', '_==', '_0', ')', '_{', '_GR', 'OW', ';', '_SH', 'R', 'INK', ';', '_cur', '_=', '_C', 'UR', ';', '_}', '_}', '_buf', '[', 'len', ']', '_=', '_0', ';', '_if', '_(', 'cur', '_!=', '_stop', ')', '_{', '_xml', 'F', 'atal', 'Er', 'r', '(', 'ct', 'xt', ',', '_XML', '_', 'ER', 'R', '_', 'L', 'IT', 'ERAL', '_', 'NOT', '_', 'FIN', 'ISH', 'ED', ',', '_NULL', ');', '_}', '_else', '_{', '_NEXT', ';', '_}', '_c', 'txt', '->', 'in', 'state', '_=', '_old', 'state', ';', '_return', '(', 'buf', ');', '_}', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_ids: 0 47858 22011 1090 44110 808 574 405 6653 1640 47858 49707 347 46795 49835 740 46795 43 25522 49377 42379 1009 48939 5457 48955 131 6979 25528 5457 321 131 6979 1836 5457 46917 1215 14280 41877 1215 19159 45234 1215 49340 131 49377 42379 5350 131 49377 42379 912 131 6979 3212 5457 321 131 49377 49707 48214 13360 793 4897 5457 740 46795 46613 179 4897 131 4584 500 23617 131 114 36 36880 45994 128 113 27645 25522 10000 131 912 5457 128 113 23500 35524 1493 114 36 36880 45994 128 37457 17809 43 25522 10000 131 912 5457 128 37457 49525 35524 1493 25522 49377 597 14720 28012 338 1640 3894 11483 6 46917 1215 2076 500 1215 574 2068 39243 1215 37049 1215 4014 11328 1691 6 48955 4397 671 1640 49728 4397 35524 49125 5457 36 47858 42379 49521 49377 448 48429 3750 30344 1640 10799 1009 49907 1640 47858 42379 48749 114 36 48939 45994 48955 43 25522 49377 28012 338 47184 1640 3894 11483 6 48955 4397 671 1640 49728 4397 35524 740 46795 46613 179 4897 5457 46917 1215 14280 41877 1215 16821 43743 1215 574 2068 39243 131 5350 5457 230 2492 131 150 41006 1729 1215 16821 387 2688 29146 1215 3764 1640 17742 35122 48200 36 17742 49333 912 35122 25522 48565 7869 48404 114 36 8476 2055 112 49095 1836 43 25522 49377 42379 1009 48743 131 1836 1009 5214 132 131 49443 5457 36 47858 42379 49521 49377 9064 48429 1640 48939 6 1836 1009 49907 1640 47858 42379 48749 114 36 48743 45994 48955 43 25522 49377 28012 338 47184 1640 3894 11483 6 48955 4397 49377 18074 1640 48939 4397 671 1640 49728 4397 35524 49125 5457 49443 131 35524 49125 10975 8476 42964 742 5457 5350 131 3212 49789 114 36 11432 8061 654 43 25522 8837 4581 131 3212 5457 321 131 35524 10000 131 5350 5457 230 2492 131 114 36 17742 45994 321 43 25522 8837 4581 131 4584 500 23617 131 5350 5457 230 2492 131 35524 35524 49125 10975 8476 742 5457 321 131 114 36 17742 49333 912 43 25522 49377 597 14720 28012 338 1640 3894 11483 6 46917 1215 2076 500 1215 574 2068 39243 1215 37049 1215 25623 14849 1691 6 48955 4397 35524 1493 25522 10000 131 35524 740 46795 46613 179 4897 5457 793 4897 131 671 1640 48939 4397 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_tokens: ['<s>', 'out', '-', 'of', '-', 'b', 'ounds', '_read', '</s>']\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_ids: 0 995 12 1116 12 428 12363 1166 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/21/2023 22:33:37 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "07/21/2023 22:33:45 - INFO - __main__ -   ***** Running training *****\n",
      "07/21/2023 22:33:45 - INFO - __main__ -     Num examples = 3870\n",
      "07/21/2023 22:33:45 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:33:45 - INFO - __main__ -     Num epoch = 100\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s]/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 0 loss 8.5715: 100%|██████████████████████| 78/78 [00:59<00:00,  1.31it/s]\n",
      "07/21/2023 22:34:46 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:34:46 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:34:46 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:34:48 - INFO - __main__ -     eval_ppl = 165.93241\n",
      "07/21/2023 22:34:48 - INFO - __main__ -     global_step = 79\n",
      "07/21/2023 22:34:48 - INFO - __main__ -     train_loss = 8.5715\n",
      "07/21/2023 22:34:48 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:34:49 - INFO - __main__ -     Best ppl:165.93241\n",
      "07/21/2023 22:34:49 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:34:59 - INFO - __main__ -     bleu-4 = 8.66 \n",
      "07/21/2023 22:34:59 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:34:59 - INFO - __main__ -     Best bleu:8.66\n",
      "07/21/2023 22:34:59 - INFO - __main__ -     ********************\n",
      "epoch 1 loss 3.9529: 100%|██████████████████████| 78/78 [00:56<00:00,  1.38it/s]\n",
      "07/21/2023 22:35:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:35:57 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:35:57 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:35:59 - INFO - __main__ -     eval_ppl = 7.32911\n",
      "07/21/2023 22:35:59 - INFO - __main__ -     global_step = 157\n",
      "07/21/2023 22:35:59 - INFO - __main__ -     train_loss = 3.9529\n",
      "07/21/2023 22:35:59 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:36:02 - INFO - __main__ -     Best ppl:7.32911\n",
      "07/21/2023 22:36:02 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:36:20 - INFO - __main__ -     bleu-4 = 12.46 \n",
      "07/21/2023 22:36:20 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:36:20 - INFO - __main__ -     Best bleu:12.46\n",
      "07/21/2023 22:36:20 - INFO - __main__ -     ********************\n",
      "epoch 2 loss 1.9522: 100%|██████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:37:19 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:37:19 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:37:19 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:37:22 - INFO - __main__ -     eval_ppl = 3.5219\n",
      "07/21/2023 22:37:22 - INFO - __main__ -     global_step = 235\n",
      "07/21/2023 22:37:22 - INFO - __main__ -     train_loss = 1.9522\n",
      "07/21/2023 22:37:22 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:37:24 - INFO - __main__ -     Best ppl:3.5219\n",
      "07/21/2023 22:37:24 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:37:40 - INFO - __main__ -     bleu-4 = 17.87 \n",
      "07/21/2023 22:37:40 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:37:40 - INFO - __main__ -     Best bleu:17.87\n",
      "07/21/2023 22:37:40 - INFO - __main__ -     ********************\n",
      "epoch 3 loss 1.3233: 100%|██████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 22:38:40 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:38:40 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:38:40 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:38:42 - INFO - __main__ -     eval_ppl = 2.7203\n",
      "07/21/2023 22:38:42 - INFO - __main__ -     global_step = 313\n",
      "07/21/2023 22:38:42 - INFO - __main__ -     train_loss = 1.3233\n",
      "07/21/2023 22:38:42 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:38:45 - INFO - __main__ -     Best ppl:2.7203\n",
      "07/21/2023 22:38:45 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:39:01 - INFO - __main__ -     bleu-4 = 27.15 \n",
      "07/21/2023 22:39:01 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:39:01 - INFO - __main__ -     Best bleu:27.15\n",
      "07/21/2023 22:39:01 - INFO - __main__ -     ********************\n",
      "epoch 4 loss 1.058: 100%|███████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 22:40:01 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:40:01 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:40:01 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:40:03 - INFO - __main__ -     eval_ppl = 2.33487\n",
      "07/21/2023 22:40:03 - INFO - __main__ -     global_step = 391\n",
      "07/21/2023 22:40:03 - INFO - __main__ -     train_loss = 1.058\n",
      "07/21/2023 22:40:03 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:40:05 - INFO - __main__ -     Best ppl:2.33487\n",
      "07/21/2023 22:40:05 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:40:21 - INFO - __main__ -     bleu-4 = 36.51 \n",
      "07/21/2023 22:40:21 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:40:21 - INFO - __main__ -     Best bleu:36.51\n",
      "07/21/2023 22:40:21 - INFO - __main__ -     ********************\n",
      "epoch 5 loss 0.863: 100%|███████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:41:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:41:21 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:41:21 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:41:23 - INFO - __main__ -     eval_ppl = 2.03885\n",
      "07/21/2023 22:41:23 - INFO - __main__ -     global_step = 469\n",
      "07/21/2023 22:41:23 - INFO - __main__ -     train_loss = 0.863\n",
      "07/21/2023 22:41:23 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:41:25 - INFO - __main__ -     Best ppl:2.03885\n",
      "07/21/2023 22:41:25 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:41:41 - INFO - __main__ -     bleu-4 = 43.86 \n",
      "07/21/2023 22:41:41 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:41:41 - INFO - __main__ -     Best bleu:43.86\n",
      "07/21/2023 22:41:41 - INFO - __main__ -     ********************\n",
      "epoch 6 loss 0.6889: 100%|██████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 22:42:41 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:42:41 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:42:41 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:42:43 - INFO - __main__ -     eval_ppl = 1.91538\n",
      "07/21/2023 22:42:43 - INFO - __main__ -     global_step = 547\n",
      "07/21/2023 22:42:43 - INFO - __main__ -     train_loss = 0.6889\n",
      "07/21/2023 22:42:43 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:42:45 - INFO - __main__ -     Best ppl:1.91538\n",
      "07/21/2023 22:42:45 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:43:01 - INFO - __main__ -     bleu-4 = 49.26 \n",
      "07/21/2023 22:43:01 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:43:01 - INFO - __main__ -     Best bleu:49.26\n",
      "07/21/2023 22:43:01 - INFO - __main__ -     ********************\n",
      "epoch 7 loss 0.5399: 100%|██████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:44:00 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:44:00 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:44:00 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:44:03 - INFO - __main__ -     eval_ppl = 1.72845\n",
      "07/21/2023 22:44:03 - INFO - __main__ -     global_step = 625\n",
      "07/21/2023 22:44:03 - INFO - __main__ -     train_loss = 0.5399\n",
      "07/21/2023 22:44:03 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:44:05 - INFO - __main__ -     Best ppl:1.72845\n",
      "07/21/2023 22:44:05 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:44:23 - INFO - __main__ -     bleu-4 = 57.7 \n",
      "07/21/2023 22:44:23 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:44:23 - INFO - __main__ -     Best bleu:57.7\n",
      "07/21/2023 22:44:23 - INFO - __main__ -     ********************\n",
      "epoch 8 loss 0.4074: 100%|██████████████████████| 78/78 [00:56<00:00,  1.38it/s]\n",
      "07/21/2023 22:45:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:45:21 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:45:21 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:45:24 - INFO - __main__ -     eval_ppl = 1.68635\n",
      "07/21/2023 22:45:24 - INFO - __main__ -     global_step = 703\n",
      "07/21/2023 22:45:24 - INFO - __main__ -     train_loss = 0.4074\n",
      "07/21/2023 22:45:24 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:45:26 - INFO - __main__ -     Best ppl:1.68635\n",
      "07/21/2023 22:45:26 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:45:43 - INFO - __main__ -     bleu-4 = 60.63 \n",
      "07/21/2023 22:45:43 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:45:43 - INFO - __main__ -     Best bleu:60.63\n",
      "07/21/2023 22:45:43 - INFO - __main__ -     ********************\n",
      "epoch 9 loss 0.2872: 100%|██████████████████████| 78/78 [00:56<00:00,  1.38it/s]\n",
      "07/21/2023 22:46:42 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:46:42 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:46:42 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:46:44 - INFO - __main__ -     eval_ppl = 1.59895\n",
      "07/21/2023 22:46:44 - INFO - __main__ -     global_step = 781\n",
      "07/21/2023 22:46:44 - INFO - __main__ -     train_loss = 0.2872\n",
      "07/21/2023 22:46:44 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:46:46 - INFO - __main__ -     Best ppl:1.59895\n",
      "07/21/2023 22:46:46 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:47:02 - INFO - __main__ -     bleu-4 = 66.19 \n",
      "07/21/2023 22:47:02 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:47:02 - INFO - __main__ -     Best bleu:66.19\n",
      "07/21/2023 22:47:02 - INFO - __main__ -     ********************\n",
      "epoch 10 loss 0.2005: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 22:48:02 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:48:02 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:48:02 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:48:04 - INFO - __main__ -     eval_ppl = 1.6814\n",
      "07/21/2023 22:48:04 - INFO - __main__ -     global_step = 859\n",
      "07/21/2023 22:48:04 - INFO - __main__ -     train_loss = 0.2005\n",
      "07/21/2023 22:48:04 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:48:19 - INFO - __main__ -     bleu-4 = 64.25 \n",
      "07/21/2023 22:48:19 - INFO - __main__ -     ********************\n",
      "epoch 11 loss 0.1394: 100%|█████████████████████| 78/78 [00:56<00:00,  1.38it/s]\n",
      "07/21/2023 22:49:16 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:49:16 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:49:16 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:49:18 - INFO - __main__ -     eval_ppl = 1.73863\n",
      "07/21/2023 22:49:18 - INFO - __main__ -     global_step = 937\n",
      "07/21/2023 22:49:18 - INFO - __main__ -     train_loss = 0.1394\n",
      "07/21/2023 22:49:18 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:49:35 - INFO - __main__ -     bleu-4 = 63.52 \n",
      "07/21/2023 22:49:35 - INFO - __main__ -     ********************\n",
      "epoch 12 loss 0.1041: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 22:50:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:50:31 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:50:31 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:50:34 - INFO - __main__ -     eval_ppl = 1.68805\n",
      "07/21/2023 22:50:34 - INFO - __main__ -     global_step = 1015\n",
      "07/21/2023 22:50:34 - INFO - __main__ -     train_loss = 0.1041\n",
      "07/21/2023 22:50:34 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:50:50 - INFO - __main__ -     bleu-4 = 68.71 \n",
      "07/21/2023 22:50:50 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:50:50 - INFO - __main__ -     Best bleu:68.71\n",
      "07/21/2023 22:50:50 - INFO - __main__ -     ********************\n",
      "epoch 13 loss 0.0854: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:51:50 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:51:50 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:51:50 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:51:52 - INFO - __main__ -     eval_ppl = 1.71688\n",
      "07/21/2023 22:51:52 - INFO - __main__ -     global_step = 1093\n",
      "07/21/2023 22:51:52 - INFO - __main__ -     train_loss = 0.0854\n",
      "07/21/2023 22:51:52 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:52:08 - INFO - __main__ -     bleu-4 = 65.88 \n",
      "07/21/2023 22:52:08 - INFO - __main__ -     ********************\n",
      "epoch 14 loss 0.0631: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 22:53:05 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:53:05 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:53:05 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:53:07 - INFO - __main__ -     eval_ppl = 1.6775\n",
      "07/21/2023 22:53:07 - INFO - __main__ -     global_step = 1171\n",
      "07/21/2023 22:53:07 - INFO - __main__ -     train_loss = 0.0631\n",
      "07/21/2023 22:53:07 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:53:23 - INFO - __main__ -     bleu-4 = 70.53 \n",
      "07/21/2023 22:53:23 - INFO - __main__ -     ********************\n",
      "07/21/2023 22:53:23 - INFO - __main__ -     Best bleu:70.53\n",
      "07/21/2023 22:53:23 - INFO - __main__ -     ********************\n",
      "epoch 15 loss 0.0456: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:54:23 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:54:23 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:54:23 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:54:25 - INFO - __main__ -     eval_ppl = 1.66663\n",
      "07/21/2023 22:54:25 - INFO - __main__ -     global_step = 1249\n",
      "07/21/2023 22:54:25 - INFO - __main__ -     train_loss = 0.0456\n",
      "07/21/2023 22:54:25 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:54:43 - INFO - __main__ -     bleu-4 = 68.31 \n",
      "07/21/2023 22:54:43 - INFO - __main__ -     ********************\n",
      "epoch 16 loss 0.0387: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 22:55:40 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:55:40 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:55:40 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:55:42 - INFO - __main__ -     eval_ppl = 1.77271\n",
      "07/21/2023 22:55:42 - INFO - __main__ -     global_step = 1327\n",
      "07/21/2023 22:55:42 - INFO - __main__ -     train_loss = 0.0387\n",
      "07/21/2023 22:55:42 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:55:58 - INFO - __main__ -     bleu-4 = 67.45 \n",
      "07/21/2023 22:55:58 - INFO - __main__ -     ********************\n",
      "epoch 17 loss 0.0379: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:56:56 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:56:56 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:56:56 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:56:58 - INFO - __main__ -     eval_ppl = 1.79425\n",
      "07/21/2023 22:56:58 - INFO - __main__ -     global_step = 1405\n",
      "07/21/2023 22:56:58 - INFO - __main__ -     train_loss = 0.0379\n",
      "07/21/2023 22:56:58 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:57:15 - INFO - __main__ -     bleu-4 = 67.86 \n",
      "07/21/2023 22:57:15 - INFO - __main__ -     ********************\n",
      "epoch 18 loss 0.03: 100%|███████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 22:58:12 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:58:12 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:58:12 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:58:14 - INFO - __main__ -     eval_ppl = 1.70513\n",
      "07/21/2023 22:58:14 - INFO - __main__ -     global_step = 1483\n",
      "07/21/2023 22:58:14 - INFO - __main__ -     train_loss = 0.03\n",
      "07/21/2023 22:58:14 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:58:30 - INFO - __main__ -     bleu-4 = 70.5 \n",
      "07/21/2023 22:58:30 - INFO - __main__ -     ********************\n",
      "epoch 19 loss 0.0278: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 22:59:27 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 22:59:27 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 22:59:27 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 22:59:30 - INFO - __main__ -     eval_ppl = 1.74535\n",
      "07/21/2023 22:59:30 - INFO - __main__ -     global_step = 1561\n",
      "07/21/2023 22:59:30 - INFO - __main__ -     train_loss = 0.0278\n",
      "07/21/2023 22:59:30 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 22:59:44 - INFO - __main__ -     bleu-4 = 69.5 \n",
      "07/21/2023 22:59:44 - INFO - __main__ -     ********************\n",
      "epoch 20 loss 0.0269: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:00:42 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:00:42 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:00:42 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:00:44 - INFO - __main__ -     eval_ppl = 1.77692\n",
      "07/21/2023 23:00:44 - INFO - __main__ -     global_step = 1639\n",
      "07/21/2023 23:00:44 - INFO - __main__ -     train_loss = 0.0269\n",
      "07/21/2023 23:00:44 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:01:00 - INFO - __main__ -     bleu-4 = 68.76 \n",
      "07/21/2023 23:01:00 - INFO - __main__ -     ********************\n",
      "epoch 21 loss 0.0245: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:01:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:01:57 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:01:57 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:02:00 - INFO - __main__ -     eval_ppl = 1.81116\n",
      "07/21/2023 23:02:00 - INFO - __main__ -     global_step = 1717\n",
      "07/21/2023 23:02:00 - INFO - __main__ -     train_loss = 0.0245\n",
      "07/21/2023 23:02:00 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:02:18 - INFO - __main__ -     bleu-4 = 67.13 \n",
      "07/21/2023 23:02:18 - INFO - __main__ -     ********************\n",
      "epoch 22 loss 0.0207: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:03:15 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:03:15 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:03:15 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:03:17 - INFO - __main__ -     eval_ppl = 1.77937\n",
      "07/21/2023 23:03:17 - INFO - __main__ -     global_step = 1795\n",
      "07/21/2023 23:03:17 - INFO - __main__ -     train_loss = 0.0207\n",
      "07/21/2023 23:03:17 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:03:34 - INFO - __main__ -     bleu-4 = 68.15 \n",
      "07/21/2023 23:03:34 - INFO - __main__ -     ********************\n",
      "epoch 23 loss 0.0175: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:04:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:04:31 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:04:31 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:04:34 - INFO - __main__ -     eval_ppl = 1.76143\n",
      "07/21/2023 23:04:34 - INFO - __main__ -     global_step = 1873\n",
      "07/21/2023 23:04:34 - INFO - __main__ -     train_loss = 0.0175\n",
      "07/21/2023 23:04:34 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:04:52 - INFO - __main__ -     bleu-4 = 68.87 \n",
      "07/21/2023 23:04:52 - INFO - __main__ -     ********************\n",
      "epoch 24 loss 0.0169: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:05:49 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:05:49 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:05:49 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:05:52 - INFO - __main__ -     eval_ppl = 1.73452\n",
      "07/21/2023 23:05:52 - INFO - __main__ -     global_step = 1951\n",
      "07/21/2023 23:05:52 - INFO - __main__ -     train_loss = 0.0169\n",
      "07/21/2023 23:05:52 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:06:09 - INFO - __main__ -     bleu-4 = 69.42 \n",
      "07/21/2023 23:06:09 - INFO - __main__ -     ********************\n",
      "epoch 25 loss 0.015: 100%|██████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:07:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:07:06 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:07:06 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:07:08 - INFO - __main__ -     eval_ppl = 1.77703\n",
      "07/21/2023 23:07:08 - INFO - __main__ -     global_step = 2029\n",
      "07/21/2023 23:07:08 - INFO - __main__ -     train_loss = 0.015\n",
      "07/21/2023 23:07:08 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:07:26 - INFO - __main__ -     bleu-4 = 70.02 \n",
      "07/21/2023 23:07:26 - INFO - __main__ -     ********************\n",
      "epoch 26 loss 0.0139: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:08:24 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:08:24 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:08:24 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:08:26 - INFO - __main__ -     eval_ppl = 1.78245\n",
      "07/21/2023 23:08:26 - INFO - __main__ -     global_step = 2107\n",
      "07/21/2023 23:08:26 - INFO - __main__ -     train_loss = 0.0139\n",
      "07/21/2023 23:08:26 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:08:42 - INFO - __main__ -     bleu-4 = 69.33 \n",
      "07/21/2023 23:08:42 - INFO - __main__ -     ********************\n",
      "epoch 27 loss 0.0121: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:09:39 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:09:39 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:09:39 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:09:42 - INFO - __main__ -     eval_ppl = 1.7869\n",
      "07/21/2023 23:09:42 - INFO - __main__ -     global_step = 2185\n",
      "07/21/2023 23:09:42 - INFO - __main__ -     train_loss = 0.0121\n",
      "07/21/2023 23:09:42 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:09:57 - INFO - __main__ -     bleu-4 = 69.73 \n",
      "07/21/2023 23:09:57 - INFO - __main__ -     ********************\n",
      "epoch 28 loss 0.0114: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:10:54 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:10:54 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:10:54 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:10:57 - INFO - __main__ -     eval_ppl = 1.76912\n",
      "07/21/2023 23:10:57 - INFO - __main__ -     global_step = 2263\n",
      "07/21/2023 23:10:57 - INFO - __main__ -     train_loss = 0.0114\n",
      "07/21/2023 23:10:57 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:11:13 - INFO - __main__ -     bleu-4 = 70.5 \n",
      "07/21/2023 23:11:13 - INFO - __main__ -     ********************\n",
      "epoch 29 loss 0.0109: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:12:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:12:10 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:12:10 - INFO - __main__ -     Batch size = 50\n",
      "epoch 31 loss 0.012: 100%|██████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:14:42 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:14:42 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:14:42 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:14:44 - INFO - __main__ -     eval_ppl = 1.80445\n",
      "07/21/2023 23:14:44 - INFO - __main__ -     global_step = 2497\n",
      "07/21/2023 23:14:44 - INFO - __main__ -     train_loss = 0.012\n",
      "07/21/2023 23:14:44 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:15:00 - INFO - __main__ -     bleu-4 = 69.7 \n",
      "07/21/2023 23:15:00 - INFO - __main__ -     ********************\n",
      "epoch 32 loss 0.0097: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:15:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:15:57 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:15:57 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:16:00 - INFO - __main__ -     eval_ppl = 1.79405\n",
      "07/21/2023 23:16:00 - INFO - __main__ -     global_step = 2575\n",
      "07/21/2023 23:16:00 - INFO - __main__ -     train_loss = 0.0097\n",
      "07/21/2023 23:16:00 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:16:16 - INFO - __main__ -     bleu-4 = 69.64 \n",
      "07/21/2023 23:16:16 - INFO - __main__ -     ********************\n",
      "epoch 33 loss 0.0104: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:17:12 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:17:12 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:17:12 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:17:15 - INFO - __main__ -     eval_ppl = 1.77772\n",
      "07/21/2023 23:17:15 - INFO - __main__ -     global_step = 2653\n",
      "07/21/2023 23:17:15 - INFO - __main__ -     train_loss = 0.0104\n",
      "07/21/2023 23:17:15 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:17:31 - INFO - __main__ -     bleu-4 = 69.79 \n",
      "07/21/2023 23:17:31 - INFO - __main__ -     ********************\n",
      "epoch 34 loss 0.0096: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:18:28 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:18:28 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:18:28 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:18:31 - INFO - __main__ -     eval_ppl = 1.78976\n",
      "07/21/2023 23:18:31 - INFO - __main__ -     global_step = 2731\n",
      "07/21/2023 23:18:31 - INFO - __main__ -     train_loss = 0.0096\n",
      "07/21/2023 23:18:31 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:18:47 - INFO - __main__ -     bleu-4 = 70.94 \n",
      "07/21/2023 23:18:47 - INFO - __main__ -     ********************\n",
      "epoch 35 loss 0.0087: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:19:44 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:19:44 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:19:44 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:19:47 - INFO - __main__ -     eval_ppl = 1.84523\n",
      "07/21/2023 23:19:47 - INFO - __main__ -     global_step = 2809\n",
      "07/21/2023 23:19:47 - INFO - __main__ -     train_loss = 0.0087\n",
      "07/21/2023 23:19:47 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:20:04 - INFO - __main__ -     bleu-4 = 69.55 \n",
      "07/21/2023 23:20:04 - INFO - __main__ -     ********************\n",
      "epoch 36 loss 0.0088: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:21:01 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:21:01 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:21:01 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:21:03 - INFO - __main__ -     eval_ppl = 1.8279\n",
      "07/21/2023 23:21:03 - INFO - __main__ -     global_step = 2887\n",
      "07/21/2023 23:21:03 - INFO - __main__ -     train_loss = 0.0088\n",
      "07/21/2023 23:21:03 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:21:20 - INFO - __main__ -     bleu-4 = 69.86 \n",
      "07/21/2023 23:21:20 - INFO - __main__ -     ********************\n",
      "epoch 37 loss 0.0081: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:22:17 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:22:17 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:22:17 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:22:20 - INFO - __main__ -     eval_ppl = 1.81913\n",
      "07/21/2023 23:22:20 - INFO - __main__ -     global_step = 2965\n",
      "07/21/2023 23:22:20 - INFO - __main__ -     train_loss = 0.0081\n",
      "07/21/2023 23:22:20 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:22:35 - INFO - __main__ -     bleu-4 = 69.91 \n",
      "07/21/2023 23:22:35 - INFO - __main__ -     ********************\n",
      "epoch 38 loss 0.0086: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:23:32 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:23:32 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:23:32 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:23:35 - INFO - __main__ -     eval_ppl = 1.84688\n",
      "07/21/2023 23:23:35 - INFO - __main__ -     global_step = 3043\n",
      "07/21/2023 23:23:35 - INFO - __main__ -     train_loss = 0.0086\n",
      "07/21/2023 23:23:35 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:23:50 - INFO - __main__ -     bleu-4 = 69.25 \n",
      "07/21/2023 23:23:50 - INFO - __main__ -     ********************\n",
      "epoch 39 loss 0.0077: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:24:47 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:24:47 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:24:47 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:24:49 - INFO - __main__ -     eval_ppl = 1.82045\n",
      "07/21/2023 23:24:49 - INFO - __main__ -     global_step = 3121\n",
      "07/21/2023 23:24:49 - INFO - __main__ -     train_loss = 0.0077\n",
      "07/21/2023 23:24:49 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:25:08 - INFO - __main__ -     bleu-4 = 70.75 \n",
      "07/21/2023 23:25:08 - INFO - __main__ -     ********************\n",
      "epoch 40 loss 0.0085: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:26:05 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:26:05 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:26:05 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:26:07 - INFO - __main__ -     eval_ppl = 1.83868\n",
      "07/21/2023 23:26:07 - INFO - __main__ -     global_step = 3199\n",
      "07/21/2023 23:26:07 - INFO - __main__ -     train_loss = 0.0085\n",
      "07/21/2023 23:26:07 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:26:23 - INFO - __main__ -     bleu-4 = 68.5 \n",
      "07/21/2023 23:26:23 - INFO - __main__ -     ********************\n",
      "epoch 41 loss 0.0079: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:27:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:27:21 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:27:21 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:27:23 - INFO - __main__ -     eval_ppl = 1.8141\n",
      "07/21/2023 23:27:23 - INFO - __main__ -     global_step = 3277\n",
      "07/21/2023 23:27:23 - INFO - __main__ -     train_loss = 0.0079\n",
      "07/21/2023 23:27:23 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:27:39 - INFO - __main__ -     bleu-4 = 70.97 \n",
      "07/21/2023 23:27:39 - INFO - __main__ -     ********************\n",
      "epoch 42 loss 0.0087: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:28:36 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:28:36 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:28:36 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:28:39 - INFO - __main__ -     eval_ppl = 1.83664\n",
      "07/21/2023 23:28:39 - INFO - __main__ -     global_step = 3355\n",
      "07/21/2023 23:28:39 - INFO - __main__ -     train_loss = 0.0087\n",
      "07/21/2023 23:28:39 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:28:54 - INFO - __main__ -     bleu-4 = 70.37 \n",
      "07/21/2023 23:28:54 - INFO - __main__ -     ********************\n",
      "epoch 43 loss 0.0081: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:29:51 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:29:51 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:29:51 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:29:53 - INFO - __main__ -     eval_ppl = 1.81615\n",
      "07/21/2023 23:29:53 - INFO - __main__ -     global_step = 3433\n",
      "07/21/2023 23:29:53 - INFO - __main__ -     train_loss = 0.0081\n",
      "07/21/2023 23:29:53 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:30:09 - INFO - __main__ -     bleu-4 = 69.85 \n",
      "07/21/2023 23:30:09 - INFO - __main__ -     ********************\n",
      "epoch 44 loss 0.0074: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:31:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:31:06 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:31:06 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:31:08 - INFO - __main__ -     eval_ppl = 1.80486\n",
      "07/21/2023 23:31:08 - INFO - __main__ -     global_step = 3511\n",
      "07/21/2023 23:31:08 - INFO - __main__ -     train_loss = 0.0074\n",
      "07/21/2023 23:31:08 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:31:25 - INFO - __main__ -     bleu-4 = 70.5 \n",
      "07/21/2023 23:31:25 - INFO - __main__ -     ********************\n",
      "epoch 45 loss 0.0079: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:32:22 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:32:22 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:32:22 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:32:24 - INFO - __main__ -     eval_ppl = 1.80797\n",
      "07/21/2023 23:32:24 - INFO - __main__ -     global_step = 3589\n",
      "07/21/2023 23:32:24 - INFO - __main__ -     train_loss = 0.0079\n",
      "07/21/2023 23:32:24 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:32:41 - INFO - __main__ -     bleu-4 = 70.67 \n",
      "07/21/2023 23:32:41 - INFO - __main__ -     ********************\n",
      "epoch 46 loss 0.007: 100%|██████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:33:38 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:33:38 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:33:38 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:33:40 - INFO - __main__ -     eval_ppl = 1.81276\n",
      "07/21/2023 23:33:40 - INFO - __main__ -     global_step = 3667\n",
      "07/21/2023 23:33:40 - INFO - __main__ -     train_loss = 0.007\n",
      "07/21/2023 23:33:40 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:33:57 - INFO - __main__ -     bleu-4 = 70.71 \n",
      "07/21/2023 23:33:57 - INFO - __main__ -     ********************\n",
      "epoch 47 loss 0.0062: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:34:54 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:34:54 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:34:54 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:34:56 - INFO - __main__ -     eval_ppl = 1.86212\n",
      "07/21/2023 23:34:56 - INFO - __main__ -     global_step = 3745\n",
      "07/21/2023 23:34:56 - INFO - __main__ -     train_loss = 0.0062\n",
      "07/21/2023 23:34:56 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:35:12 - INFO - __main__ -     bleu-4 = 69.76 \n",
      "07/21/2023 23:35:12 - INFO - __main__ -     ********************\n",
      "epoch 48 loss 0.0068: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:36:08 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:36:08 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:36:08 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:36:11 - INFO - __main__ -     eval_ppl = 1.84447\n",
      "07/21/2023 23:36:11 - INFO - __main__ -     global_step = 3823\n",
      "07/21/2023 23:36:11 - INFO - __main__ -     train_loss = 0.0068\n",
      "07/21/2023 23:36:11 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:36:28 - INFO - __main__ -     bleu-4 = 71.12 \n",
      "07/21/2023 23:36:28 - INFO - __main__ -     ********************\n",
      "epoch 49 loss 0.0064: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:37:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:37:25 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:37:25 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:37:27 - INFO - __main__ -     eval_ppl = 1.87311\n",
      "07/21/2023 23:37:27 - INFO - __main__ -     global_step = 3901\n",
      "07/21/2023 23:37:27 - INFO - __main__ -     train_loss = 0.0064\n",
      "07/21/2023 23:37:27 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:37:43 - INFO - __main__ -     bleu-4 = 69.41 \n",
      "07/21/2023 23:37:43 - INFO - __main__ -     ********************\n",
      "epoch 50 loss 0.0049:   4%|▊                     | 3/78 [00:02<00:57,  1.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52 loss 0.0092: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:41:09 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:41:09 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:41:09 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:41:11 - INFO - __main__ -     eval_ppl = 1.90135\n",
      "07/21/2023 23:41:11 - INFO - __main__ -     global_step = 4135\n",
      "07/21/2023 23:41:11 - INFO - __main__ -     train_loss = 0.0092\n",
      "07/21/2023 23:41:11 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:41:28 - INFO - __main__ -     bleu-4 = 69.86 \n",
      "07/21/2023 23:41:28 - INFO - __main__ -     ********************\n",
      "epoch 53 loss 0.008: 100%|██████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:42:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:42:25 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:42:25 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:42:28 - INFO - __main__ -     eval_ppl = 1.87606\n",
      "07/21/2023 23:42:28 - INFO - __main__ -     global_step = 4213\n",
      "07/21/2023 23:42:28 - INFO - __main__ -     train_loss = 0.008\n",
      "07/21/2023 23:42:28 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:42:45 - INFO - __main__ -     bleu-4 = 68.73 \n",
      "07/21/2023 23:42:45 - INFO - __main__ -     ********************\n",
      "epoch 54 loss 0.0083: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:43:42 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:43:42 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:43:42 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:43:44 - INFO - __main__ -     eval_ppl = 1.92264\n",
      "07/21/2023 23:43:44 - INFO - __main__ -     global_step = 4291\n",
      "07/21/2023 23:43:44 - INFO - __main__ -     train_loss = 0.0083\n",
      "07/21/2023 23:43:44 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:44:00 - INFO - __main__ -     bleu-4 = 69.87 \n",
      "07/21/2023 23:44:00 - INFO - __main__ -     ********************\n",
      "epoch 55 loss 0.0063: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:44:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:44:57 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:44:57 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:44:59 - INFO - __main__ -     eval_ppl = 1.86237\n",
      "07/21/2023 23:44:59 - INFO - __main__ -     global_step = 4369\n",
      "07/21/2023 23:44:59 - INFO - __main__ -     train_loss = 0.0063\n",
      "07/21/2023 23:44:59 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:45:16 - INFO - __main__ -     bleu-4 = 70.93 \n",
      "07/21/2023 23:45:16 - INFO - __main__ -     ********************\n",
      "epoch 56 loss 0.0104: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:46:13 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:46:13 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:46:13 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:46:16 - INFO - __main__ -     eval_ppl = 1.85224\n",
      "07/21/2023 23:46:16 - INFO - __main__ -     global_step = 4447\n",
      "07/21/2023 23:46:16 - INFO - __main__ -     train_loss = 0.0104\n",
      "07/21/2023 23:46:16 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:46:33 - INFO - __main__ -     bleu-4 = 69.56 \n",
      "07/21/2023 23:46:33 - INFO - __main__ -     ********************\n",
      "epoch 57 loss 0.0069: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:47:30 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:47:30 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:47:30 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:47:33 - INFO - __main__ -     eval_ppl = 1.86272\n",
      "07/21/2023 23:47:33 - INFO - __main__ -     global_step = 4525\n",
      "07/21/2023 23:47:33 - INFO - __main__ -     train_loss = 0.0069\n",
      "07/21/2023 23:47:33 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:47:49 - INFO - __main__ -     bleu-4 = 72.38 \n",
      "07/21/2023 23:47:49 - INFO - __main__ -     ********************\n",
      "07/21/2023 23:47:49 - INFO - __main__ -     Best bleu:72.38\n",
      "07/21/2023 23:47:49 - INFO - __main__ -     ********************\n",
      "epoch 58 loss 0.0068: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:48:49 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:48:49 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:48:49 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:48:51 - INFO - __main__ -     eval_ppl = 1.89507\n",
      "07/21/2023 23:48:51 - INFO - __main__ -     global_step = 4603\n",
      "07/21/2023 23:48:51 - INFO - __main__ -     train_loss = 0.0068\n",
      "07/21/2023 23:48:51 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:49:09 - INFO - __main__ -     bleu-4 = 68.44 \n",
      "07/21/2023 23:49:09 - INFO - __main__ -     ********************\n",
      "epoch 59 loss 0.008: 100%|██████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:50:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:50:06 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:50:06 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:50:08 - INFO - __main__ -     eval_ppl = 1.91788\n",
      "07/21/2023 23:50:08 - INFO - __main__ -     global_step = 4681\n",
      "07/21/2023 23:50:08 - INFO - __main__ -     train_loss = 0.008\n",
      "07/21/2023 23:50:08 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:50:26 - INFO - __main__ -     bleu-4 = 70.9 \n",
      "07/21/2023 23:50:26 - INFO - __main__ -     ********************\n",
      "epoch 60 loss 0.0092: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:51:23 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:51:23 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:51:23 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:51:25 - INFO - __main__ -     eval_ppl = 1.85809\n",
      "07/21/2023 23:51:25 - INFO - __main__ -     global_step = 4759\n",
      "07/21/2023 23:51:25 - INFO - __main__ -     train_loss = 0.0092\n",
      "07/21/2023 23:51:25 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:51:40 - INFO - __main__ -     bleu-4 = 71.33 \n",
      "07/21/2023 23:51:40 - INFO - __main__ -     ********************\n",
      "epoch 61 loss 0.0132: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:52:38 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:52:38 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:52:38 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:52:40 - INFO - __main__ -     eval_ppl = 1.98269\n",
      "07/21/2023 23:52:40 - INFO - __main__ -     global_step = 4837\n",
      "07/21/2023 23:52:40 - INFO - __main__ -     train_loss = 0.0132\n",
      "07/21/2023 23:52:40 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:52:57 - INFO - __main__ -     bleu-4 = 68.53 \n",
      "07/21/2023 23:52:57 - INFO - __main__ -     ********************\n",
      "epoch 62 loss 0.0112: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/21/2023 23:53:54 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:53:54 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:53:54 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:53:56 - INFO - __main__ -     eval_ppl = 1.95355\n",
      "07/21/2023 23:53:56 - INFO - __main__ -     global_step = 4915\n",
      "07/21/2023 23:53:56 - INFO - __main__ -     train_loss = 0.0112\n",
      "07/21/2023 23:53:56 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:54:13 - INFO - __main__ -     bleu-4 = 66.61 \n",
      "07/21/2023 23:54:13 - INFO - __main__ -     ********************\n",
      "epoch 63 loss 0.0089: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:55:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:55:10 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:55:10 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:55:12 - INFO - __main__ -     eval_ppl = 1.86497\n",
      "07/21/2023 23:55:12 - INFO - __main__ -     global_step = 4993\n",
      "07/21/2023 23:55:12 - INFO - __main__ -     train_loss = 0.0089\n",
      "07/21/2023 23:55:12 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:55:29 - INFO - __main__ -     bleu-4 = 69.09 \n",
      "07/21/2023 23:55:29 - INFO - __main__ -     ********************\n",
      "epoch 64 loss 0.0079: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:56:26 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:56:26 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:56:26 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:56:29 - INFO - __main__ -     eval_ppl = 1.84314\n",
      "07/21/2023 23:56:29 - INFO - __main__ -     global_step = 5071\n",
      "07/21/2023 23:56:29 - INFO - __main__ -     train_loss = 0.0079\n",
      "07/21/2023 23:56:29 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:56:46 - INFO - __main__ -     bleu-4 = 70.73 \n",
      "07/21/2023 23:56:46 - INFO - __main__ -     ********************\n",
      "epoch 65 loss 0.0066: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/21/2023 23:57:43 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:57:43 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:57:43 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:57:45 - INFO - __main__ -     eval_ppl = 1.88681\n",
      "07/21/2023 23:57:45 - INFO - __main__ -     global_step = 5149\n",
      "07/21/2023 23:57:45 - INFO - __main__ -     train_loss = 0.0066\n",
      "07/21/2023 23:57:45 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:58:01 - INFO - __main__ -     bleu-4 = 70.36 \n",
      "07/21/2023 23:58:01 - INFO - __main__ -     ********************\n",
      "epoch 66 loss 0.0081: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/21/2023 23:58:59 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/21/2023 23:58:59 - INFO - __main__ -     Num examples = 431\n",
      "07/21/2023 23:58:59 - INFO - __main__ -     Batch size = 50\n",
      "07/21/2023 23:59:01 - INFO - __main__ -     eval_ppl = 1.88041\n",
      "07/21/2023 23:59:01 - INFO - __main__ -     global_step = 5227\n",
      "07/21/2023 23:59:01 - INFO - __main__ -     train_loss = 0.0081\n",
      "07/21/2023 23:59:01 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/21/2023 23:59:17 - INFO - __main__ -     bleu-4 = 68.43 \n",
      "07/21/2023 23:59:17 - INFO - __main__ -     ********************\n",
      "epoch 67 loss 0.0071: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:00:14 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:00:14 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:00:14 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:00:16 - INFO - __main__ -     eval_ppl = 1.8963\n",
      "07/22/2023 00:00:16 - INFO - __main__ -     global_step = 5305\n",
      "07/22/2023 00:00:16 - INFO - __main__ -     train_loss = 0.0071\n",
      "07/22/2023 00:00:16 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:00:34 - INFO - __main__ -     bleu-4 = 68.83 \n",
      "07/22/2023 00:00:34 - INFO - __main__ -     ********************\n",
      "epoch 68 loss 0.0055: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:01:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:01:31 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:01:31 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:01:34 - INFO - __main__ -     eval_ppl = 1.92563\n",
      "07/22/2023 00:01:34 - INFO - __main__ -     global_step = 5383\n",
      "07/22/2023 00:01:34 - INFO - __main__ -     train_loss = 0.0055\n",
      "07/22/2023 00:01:34 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:01:50 - INFO - __main__ -     bleu-4 = 68.17 \n",
      "07/22/2023 00:01:50 - INFO - __main__ -     ********************\n",
      "epoch 69 loss 0.0054: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:02:47 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:02:47 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:02:47 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:02:49 - INFO - __main__ -     eval_ppl = 1.90096\n",
      "07/22/2023 00:02:49 - INFO - __main__ -     global_step = 5461\n",
      "07/22/2023 00:02:49 - INFO - __main__ -     train_loss = 0.0054\n",
      "07/22/2023 00:02:49 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:03:06 - INFO - __main__ -     bleu-4 = 70.31 \n",
      "07/22/2023 00:03:06 - INFO - __main__ -     ********************\n",
      "epoch 70 loss 0.0051: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:04:03 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:04:03 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:04:03 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:04:06 - INFO - __main__ -     eval_ppl = 1.90334\n",
      "07/22/2023 00:04:06 - INFO - __main__ -     global_step = 5539\n",
      "07/22/2023 00:04:06 - INFO - __main__ -     train_loss = 0.0051\n",
      "07/22/2023 00:04:06 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:04:24 - INFO - __main__ -     bleu-4 = 69.13 \n",
      "07/22/2023 00:04:24 - INFO - __main__ -     ********************\n",
      "epoch 71 loss 0.0057: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:05:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:05:21 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:05:21 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:05:23 - INFO - __main__ -     eval_ppl = 1.90166\n",
      "07/22/2023 00:05:23 - INFO - __main__ -     global_step = 5617\n",
      "07/22/2023 00:05:23 - INFO - __main__ -     train_loss = 0.0057\n",
      "07/22/2023 00:05:23 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:05:41 - INFO - __main__ -     bleu-4 = 69.98 \n",
      "07/22/2023 00:05:41 - INFO - __main__ -     ********************\n",
      "epoch 72 loss 0.0044: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:06:38 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:06:38 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:06:38 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:06:41 - INFO - __main__ -     eval_ppl = 1.90908\n",
      "07/22/2023 00:06:41 - INFO - __main__ -     global_step = 5695\n",
      "07/22/2023 00:06:41 - INFO - __main__ -     train_loss = 0.0044\n",
      "07/22/2023 00:06:41 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:06:57 - INFO - __main__ -     bleu-4 = 69.85 \n",
      "07/22/2023 00:06:57 - INFO - __main__ -     ********************\n",
      "epoch 73 loss 0.0037: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:07:54 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:07:54 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:07:54 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:07:56 - INFO - __main__ -     eval_ppl = 1.92952\n",
      "07/22/2023 00:07:56 - INFO - __main__ -     global_step = 5773\n",
      "07/22/2023 00:07:56 - INFO - __main__ -     train_loss = 0.0037\n",
      "07/22/2023 00:07:56 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:08:13 - INFO - __main__ -     bleu-4 = 69.55 \n",
      "07/22/2023 00:08:13 - INFO - __main__ -     ********************\n",
      "epoch 74 loss 0.004: 100%|██████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:09:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:09:10 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:09:10 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:09:12 - INFO - __main__ -     eval_ppl = 1.9788\n",
      "07/22/2023 00:09:12 - INFO - __main__ -     global_step = 5851\n",
      "07/22/2023 00:09:12 - INFO - __main__ -     train_loss = 0.004\n",
      "07/22/2023 00:09:12 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:09:29 - INFO - __main__ -     bleu-4 = 69.84 \n",
      "07/22/2023 00:09:29 - INFO - __main__ -     ********************\n",
      "epoch 75 loss 0.0042: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:10:26 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:10:26 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:10:26 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:10:29 - INFO - __main__ -     eval_ppl = 1.92087\n",
      "07/22/2023 00:10:29 - INFO - __main__ -     global_step = 5929\n",
      "07/22/2023 00:10:29 - INFO - __main__ -     train_loss = 0.0042\n",
      "07/22/2023 00:10:29 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:10:45 - INFO - __main__ -     bleu-4 = 69.61 \n",
      "07/22/2023 00:10:45 - INFO - __main__ -     ********************\n",
      "epoch 76 loss 0.0042: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:11:43 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:11:43 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:11:43 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:11:45 - INFO - __main__ -     eval_ppl = 1.95459\n",
      "07/22/2023 00:11:45 - INFO - __main__ -     global_step = 6007\n",
      "07/22/2023 00:11:45 - INFO - __main__ -     train_loss = 0.0042\n",
      "07/22/2023 00:11:45 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:12:01 - INFO - __main__ -     bleu-4 = 69.88 \n",
      "07/22/2023 00:12:01 - INFO - __main__ -     ********************\n",
      "epoch 77 loss 0.0043: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:12:58 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:12:58 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:12:58 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:13:01 - INFO - __main__ -     eval_ppl = 1.96541\n",
      "07/22/2023 00:13:01 - INFO - __main__ -     global_step = 6085\n",
      "07/22/2023 00:13:01 - INFO - __main__ -     train_loss = 0.0043\n",
      "07/22/2023 00:13:01 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:13:17 - INFO - __main__ -     bleu-4 = 69.73 \n",
      "07/22/2023 00:13:17 - INFO - __main__ -     ********************\n",
      "epoch 78 loss 0.0038: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:14:14 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:14:14 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:14:14 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:14:17 - INFO - __main__ -     eval_ppl = 1.97216\n",
      "07/22/2023 00:14:17 - INFO - __main__ -     global_step = 6163\n",
      "07/22/2023 00:14:17 - INFO - __main__ -     train_loss = 0.0038\n",
      "07/22/2023 00:14:17 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:14:34 - INFO - __main__ -     bleu-4 = 69.47 \n",
      "07/22/2023 00:14:34 - INFO - __main__ -     ********************\n",
      "epoch 79 loss 0.004: 100%|██████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:15:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:15:31 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:15:31 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:15:33 - INFO - __main__ -     eval_ppl = 1.92591\n",
      "07/22/2023 00:15:33 - INFO - __main__ -     global_step = 6241\n",
      "07/22/2023 00:15:33 - INFO - __main__ -     train_loss = 0.004\n",
      "07/22/2023 00:15:33 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:15:50 - INFO - __main__ -     bleu-4 = 70.04 \n",
      "07/22/2023 00:15:50 - INFO - __main__ -     ********************\n",
      "epoch 80 loss 0.0038: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:16:47 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:16:47 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:16:47 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:16:50 - INFO - __main__ -     eval_ppl = 1.9514\n",
      "07/22/2023 00:16:50 - INFO - __main__ -     global_step = 6319\n",
      "07/22/2023 00:16:50 - INFO - __main__ -     train_loss = 0.0038\n",
      "07/22/2023 00:16:50 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:17:06 - INFO - __main__ -     bleu-4 = 70.02 \n",
      "07/22/2023 00:17:06 - INFO - __main__ -     ********************\n",
      "epoch 81 loss 0.004: 100%|██████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:18:04 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:18:04 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:18:04 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:18:06 - INFO - __main__ -     eval_ppl = 1.95664\n",
      "07/22/2023 00:18:06 - INFO - __main__ -     global_step = 6397\n",
      "07/22/2023 00:18:06 - INFO - __main__ -     train_loss = 0.004\n",
      "07/22/2023 00:18:06 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:18:22 - INFO - __main__ -     bleu-4 = 71.22 \n",
      "07/22/2023 00:18:22 - INFO - __main__ -     ********************\n",
      "epoch 82 loss 0.0039: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:19:19 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:19:19 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:19:19 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:19:21 - INFO - __main__ -     eval_ppl = 1.97193\n",
      "07/22/2023 00:19:21 - INFO - __main__ -     global_step = 6475\n",
      "07/22/2023 00:19:21 - INFO - __main__ -     train_loss = 0.0039\n",
      "07/22/2023 00:19:21 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:19:38 - INFO - __main__ -     bleu-4 = 69.44 \n",
      "07/22/2023 00:19:38 - INFO - __main__ -     ********************\n",
      "epoch 83 loss 0.0039: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:20:35 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:20:35 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:20:35 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:20:38 - INFO - __main__ -     eval_ppl = 1.955\n",
      "07/22/2023 00:20:38 - INFO - __main__ -     global_step = 6553\n",
      "07/22/2023 00:20:38 - INFO - __main__ -     train_loss = 0.0039\n",
      "07/22/2023 00:20:38 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:20:54 - INFO - __main__ -     bleu-4 = 70.24 \n",
      "07/22/2023 00:20:54 - INFO - __main__ -     ********************\n",
      "epoch 84 loss 0.0035: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:21:51 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:21:51 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:21:51 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:21:53 - INFO - __main__ -     eval_ppl = 1.95919\n",
      "07/22/2023 00:21:53 - INFO - __main__ -     global_step = 6631\n",
      "07/22/2023 00:21:53 - INFO - __main__ -     train_loss = 0.0035\n",
      "07/22/2023 00:21:53 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:22:09 - INFO - __main__ -     bleu-4 = 69.11 \n",
      "07/22/2023 00:22:09 - INFO - __main__ -     ********************\n",
      "epoch 85 loss 0.0037: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:23:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:23:06 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:23:06 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:23:08 - INFO - __main__ -     eval_ppl = 1.9492\n",
      "07/22/2023 00:23:08 - INFO - __main__ -     global_step = 6709\n",
      "07/22/2023 00:23:08 - INFO - __main__ -     train_loss = 0.0037\n",
      "07/22/2023 00:23:08 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:23:24 - INFO - __main__ -     bleu-4 = 70.44 \n",
      "07/22/2023 00:23:24 - INFO - __main__ -     ********************\n",
      "epoch 86 loss 0.0033: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:24:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:24:21 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:24:21 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:24:23 - INFO - __main__ -     eval_ppl = 1.95116\n",
      "07/22/2023 00:24:23 - INFO - __main__ -     global_step = 6787\n",
      "07/22/2023 00:24:23 - INFO - __main__ -     train_loss = 0.0033\n",
      "07/22/2023 00:24:23 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:24:39 - INFO - __main__ -     bleu-4 = 70.86 \n",
      "07/22/2023 00:24:39 - INFO - __main__ -     ********************\n",
      "epoch 87 loss 0.0035: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/22/2023 00:25:36 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:25:36 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:25:36 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:25:38 - INFO - __main__ -     eval_ppl = 1.95282\n",
      "07/22/2023 00:25:38 - INFO - __main__ -     global_step = 6865\n",
      "07/22/2023 00:25:38 - INFO - __main__ -     train_loss = 0.0035\n",
      "07/22/2023 00:25:38 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:25:55 - INFO - __main__ -     bleu-4 = 69.99 \n",
      "07/22/2023 00:25:55 - INFO - __main__ -     ********************\n",
      "epoch 88 loss 0.0033: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:26:52 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:26:52 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:26:52 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:26:54 - INFO - __main__ -     eval_ppl = 1.95758\n",
      "07/22/2023 00:26:54 - INFO - __main__ -     global_step = 6943\n",
      "07/22/2023 00:26:54 - INFO - __main__ -     train_loss = 0.0033\n",
      "07/22/2023 00:26:54 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:27:09 - INFO - __main__ -     bleu-4 = 70.38 \n",
      "07/22/2023 00:27:09 - INFO - __main__ -     ********************\n",
      "epoch 89 loss 0.0032: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:28:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:28:06 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:28:06 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:28:08 - INFO - __main__ -     eval_ppl = 1.96401\n",
      "07/22/2023 00:28:08 - INFO - __main__ -     global_step = 7021\n",
      "07/22/2023 00:28:08 - INFO - __main__ -     train_loss = 0.0032\n",
      "07/22/2023 00:28:08 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:28:26 - INFO - __main__ -     bleu-4 = 70.33 \n",
      "07/22/2023 00:28:26 - INFO - __main__ -     ********************\n",
      "epoch 90 loss 0.0033: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/22/2023 00:29:23 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:29:23 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:29:23 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:29:25 - INFO - __main__ -     eval_ppl = 1.94782\n",
      "07/22/2023 00:29:25 - INFO - __main__ -     global_step = 7099\n",
      "07/22/2023 00:29:25 - INFO - __main__ -     train_loss = 0.0033\n",
      "07/22/2023 00:29:25 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:29:41 - INFO - __main__ -     bleu-4 = 70.96 \n",
      "07/22/2023 00:29:41 - INFO - __main__ -     ********************\n",
      "epoch 91 loss 0.0031: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:30:38 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:30:38 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:30:38 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:30:41 - INFO - __main__ -     eval_ppl = 1.95841\n",
      "07/22/2023 00:30:41 - INFO - __main__ -     global_step = 7177\n",
      "07/22/2023 00:30:41 - INFO - __main__ -     train_loss = 0.0031\n",
      "07/22/2023 00:30:41 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:30:58 - INFO - __main__ -     bleu-4 = 70.08 \n",
      "07/22/2023 00:30:58 - INFO - __main__ -     ********************\n",
      "epoch 92 loss 0.0032: 100%|█████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/22/2023 00:31:55 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:31:55 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:31:55 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:31:58 - INFO - __main__ -     eval_ppl = 1.96954\n",
      "07/22/2023 00:31:58 - INFO - __main__ -     global_step = 7255\n",
      "07/22/2023 00:31:58 - INFO - __main__ -     train_loss = 0.0032\n",
      "07/22/2023 00:31:58 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:32:13 - INFO - __main__ -     bleu-4 = 69.89 \n",
      "07/22/2023 00:32:13 - INFO - __main__ -     ********************\n",
      "epoch 93 loss 0.003: 100%|██████████████████████| 78/78 [00:57<00:00,  1.37it/s]\n",
      "07/22/2023 00:33:10 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:33:10 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:33:10 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:33:13 - INFO - __main__ -     eval_ppl = 1.96426\n",
      "07/22/2023 00:33:13 - INFO - __main__ -     global_step = 7333\n",
      "07/22/2023 00:33:13 - INFO - __main__ -     train_loss = 0.003\n",
      "07/22/2023 00:33:13 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:33:29 - INFO - __main__ -     bleu-4 = 70.58 \n",
      "07/22/2023 00:33:29 - INFO - __main__ -     ********************\n",
      "epoch 94 loss 0.0031: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:34:26 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:34:26 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:34:26 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:34:28 - INFO - __main__ -     eval_ppl = 1.96697\n",
      "07/22/2023 00:34:28 - INFO - __main__ -     global_step = 7411\n",
      "07/22/2023 00:34:28 - INFO - __main__ -     train_loss = 0.0031\n",
      "07/22/2023 00:34:28 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:34:44 - INFO - __main__ -     bleu-4 = 70.24 \n",
      "07/22/2023 00:34:44 - INFO - __main__ -     ********************\n",
      "epoch 95 loss 0.0028: 100%|█████████████████████| 78/78 [00:57<00:00,  1.36it/s]\n",
      "07/22/2023 00:35:42 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:35:42 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:35:42 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:35:44 - INFO - __main__ -     eval_ppl = 1.96675\n",
      "07/22/2023 00:35:44 - INFO - __main__ -     global_step = 7489\n",
      "07/22/2023 00:35:44 - INFO - __main__ -     train_loss = 0.0028\n",
      "07/22/2023 00:35:44 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:36:00 - INFO - __main__ -     bleu-4 = 70.8 \n",
      "07/22/2023 00:36:00 - INFO - __main__ -     ********************\n",
      "epoch 96 loss 0.0028: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:36:57 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:36:57 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:36:57 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:36:59 - INFO - __main__ -     eval_ppl = 1.9698\n",
      "07/22/2023 00:36:59 - INFO - __main__ -     global_step = 7567\n",
      "07/22/2023 00:36:59 - INFO - __main__ -     train_loss = 0.0028\n",
      "07/22/2023 00:36:59 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:37:15 - INFO - __main__ -     bleu-4 = 70.4 \n",
      "07/22/2023 00:37:15 - INFO - __main__ -     ********************\n",
      "epoch 97 loss 0.0027: 100%|█████████████████████| 78/78 [00:56<00:00,  1.37it/s]\n",
      "07/22/2023 00:38:12 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/22/2023 00:38:12 - INFO - __main__ -     Num examples = 431\n",
      "07/22/2023 00:38:12 - INFO - __main__ -     Batch size = 50\n",
      "07/22/2023 00:38:14 - INFO - __main__ -     eval_ppl = 1.97356\n",
      "07/22/2023 00:38:14 - INFO - __main__ -     global_step = 7645\n",
      "07/22/2023 00:38:14 - INFO - __main__ -     train_loss = 0.0027\n",
      "07/22/2023 00:38:14 - INFO - __main__ -     ********************\n",
      "Total: 431\n",
      "07/22/2023 00:38:31 - INFO - __main__ -     bleu-4 = 69.83 \n",
      "07/22/2023 00:38:31 - INFO - __main__ -     ********************\n",
      "epoch 98 loss 0.0027:  92%|███████████████████▍ | 72/78 [00:53<00:04,  1.36it/s]Total: 431\n",
      "07/22/2023 00:41:01 - INFO - __main__ -     bleu-4 = 69.67 \n",
      "07/22/2023 00:41:01 - INFO - __main__ -     ********************\n"
     ]
    }
   ],
   "source": [
    "lr = args.lr\n",
    "batch_size = args.batch_size # change depending on the GPU Colab gives you\n",
    "beam_size = args.beam_size\n",
    "source_length = args.max_source_length\n",
    "target_length = args.max_target_length\n",
    "data_dir = 'tmp_data'\n",
    "output_dir = f'{args.save_dir}/{args.prefix}_{args.task}'\n",
    "train_file = f'{data_dir}/{args.task}/train.jsonl'\n",
    "dev_file = f'{data_dir}/{args.task}/valid.jsonl'\n",
    "epochs = args.epochs \n",
    "pretrained_model = args.model_name\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_lower_case \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path {pretrained_model} \\\n",
    "    --train_filename {train_file} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --train_batch_size {batch_size} \\\n",
    "    --eval_batch_size {batch_size} \\\n",
    "    --learning_rate {lr} \\\n",
    "    --num_train_epochs {epochs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/22/2023 02:09:07 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='tf_board/neulab_vulnerability_type', load_model_path='tf_board/neulab_vulnerability_type/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename='tmp_data/vulnerability_type/valid.jsonl', test_filename='tmp_data/vulnerability_type/test.jsonl', config_name='', tokenizer_name='', max_source_length=512, max_target_length=53, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/22/2023 02:09:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "07/22/2023 02:09:13 - INFO - __main__ -   reload model from tf_board/neulab_vulnerability_type/checkpoint-best-bleu/pytorch_model.bin\n",
      "07/22/2023 02:09:14 - INFO - __main__ -   Test file: tmp_data/vulnerability_type/valid.jsonl\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:15<00:00,  2.17s/it]\n",
      "Total: 431\n",
      "07/22/2023 02:09:31 - INFO - __main__ -     bleu-4 = 72.38 \n",
      "07/22/2023 02:09:31 - INFO - __main__ -     ********************\n",
      "07/22/2023 02:09:31 - INFO - __main__ -   Test file: tmp_data/vulnerability_type/test.jsonl\n",
      "100%|███████████████████████████████████████████| 17/17 [00:30<00:00,  1.82s/it]\n",
      "Total: 1076\n",
      "07/22/2023 02:10:04 - INFO - __main__ -     bleu-4 = 64.79 \n",
      "07/22/2023 02:10:04 - INFO - __main__ -     ********************\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "dev_file= f'{data_dir}/{args.task}/valid.jsonl'\n",
    "test_file=f\"{data_dir}/{args.task}/test.jsonl\"\n",
    "test_model=f\"{output_dir}/checkpoint-best-bleu/pytorch_model.bin\" #checkpoint for test\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_test \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path microsoft/codebert-base \\\n",
    "    --load_model_path {test_model} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --test_filename {test_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --eval_batch_size {batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009281396865844727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 39,
       "postfix": null,
       "prefix": "Downloading (…)/main/tokenizer.json",
       "rate": null,
       "total": 2108591,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27691656e05d4c0ab62649702bff1d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name, do_lower_case=args.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neulab/codebert-cpp were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-cpp and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "config = RobertaConfig.from_pretrained(pretrained_model)\n",
    "encoder = RobertaModel.from_pretrained(pretrained_model, config = config)    \n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(encoder = encoder,decoder = decoder,config=config,\n",
    "                beam_size=beam_size,max_length=target_length,\n",
    "                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n",
    "model.load_state_dict(torch.load(Path(output_dir)/\"checkpoint-best-bleu/pytorch_model.bin\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static ssize_t read_mem(struct file *file, char __user *buf,    size_t count, loff_t *ppos) {  phys_addr_t p = *ppos;  ssize_t read, sz;  void *ptr;   if (p != *ppos)   return 0;   if (!valid_phys_addr_range(p, count))   return -EFAULT;  read = 0; #ifdef __ARCH_HAS_NO_PAGE_ZERO_MAPPED  /* we don't have page 0 mapped on sparc and m68k.. */  if (p < PAGE_SIZE) {   sz = size_inside_page(p, count);   if (sz > 0) {    if (clear_user(buf, sz))     return -EFAULT;    buf += sz;    p += sz;    count -= sz;    read += sz;   }  } #endif  while (count > 0) {  unsigned long remaining;  sz = size_inside_page(p, count);  if (!range_is_allowed(p >> PAGE_SHIFT, count))  return -EPERM;  /*    * On ia64 if a page has been mapped somewhere as uncached, then    * it must also be accessed uncached by the kernel or data    * corruption may occur.    */   ptr = xlate_dev_mem_ptr(p);   if (!ptr)    return -EFAULT;  remaining = copy_to_user(buf, ptr, sz);   unxlate_dev_mem_ptr(p, ptr);  if (remaining)  return -EFAULT;  buf += sz;   p += sz;   count -= sz;   read += sz;  }   *ppos += read;  return read; } \n",
      "Original Comment: buffer overflow\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "TEXT_TO_SUMMARIZE = df_test.func_before.values[idx]\n",
    "print('Code:', TEXT_TO_SUMMARIZE)\n",
    "print('Original Comment:', df_val.explain.values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from code2nl.run import convert_examples_to_features, Example\n",
    "\n",
    "def get_preds(df: pd.DataFrame):\n",
    "    ps = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        examples = [\n",
    "            Example(idx, source = row.func_before, target = row.explain)\n",
    "        ]\n",
    "        eval_features = convert_examples_to_features(\n",
    "            examples, tokenizer, args, stage='test'\n",
    "        )\n",
    "        source_ids = torch.tensor(eval_features[0].source_ids, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "        source_mask = torch.tensor(eval_features[0].source_mask, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(source_ids = source_ids, source_mask = source_mask)  \n",
    "            for pred in preds:\n",
    "                t = pred[0].cpu().numpy()\n",
    "                t = list(t)\n",
    "                if 0 in t:\n",
    "                    t = t[:t.index(0)]\n",
    "                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                ps.append(text)\n",
    "    \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009931802749633789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 47,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1076,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc849e1f7e604e37b8baf92fda99375b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/27/2023 00:26:24 - INFO - absl -   Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6450415600508539,\n",
       " 'rouge2': 0.6216708709506107,\n",
       " 'rougeL': 0.6470299784890862,\n",
       " 'rougeLsum': 0.6467197197680468}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = df_test.reset_index()\n",
    "preds = get_preds(df_test)\n",
    "references = []\n",
    "for idx, row in df_test.iterrows():\n",
    "    # print('Code:', row.func_before)\n",
    "    # print('Original Comment:', row.explain)\n",
    "    # print('Generated Comment:', preds[idx])\n",
    "    # print('='*40)\n",
    "    references.append(row.explain)\n",
    "\n",
    "results = rouge.compute(predictions=preds, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static ssize_t read_mem(struct file *file, char __user *buf,    size_t count, loff_t *ppos) {  phys_addr_t p = *ppos;  ssize_t read, sz;  void *ptr;   if (p != *ppos)   return 0;   if (!valid_phys_addr_range(p, count))   return -EFAULT;  read = 0; #ifdef __ARCH_HAS_NO_PAGE_ZERO_MAPPED  /* we don't have page 0 mapped on sparc and m68k.. */  if (p < PAGE_SIZE) {   sz = size_inside_page(p, count);   if (sz > 0) {    if (clear_user(buf, sz))     return -EFAULT;    buf += sz;    p += sz;    count -= sz;    read += sz;   }  } #endif  while (count > 0) {  unsigned long remaining;  sz = size_inside_page(p, count);  if (!range_is_allowed(p >> PAGE_SHIFT, count))  return -EPERM;  /*    * On ia64 if a page has been mapped somewhere as uncached, then    * it must also be accessed uncached by the kernel or data    * corruption may occur.    */   ptr = xlate_dev_mem_ptr(p);   if (!ptr)    return -EFAULT;  remaining = copy_to_user(buf, ptr, sz);   unxlate_dev_mem_ptr(p, ptr);  if (remaining)  return -EFAULT;  buf += sz;   p += sz;   count -= sz;   read += sz;  }   *ppos += read;  return read; } \n",
      "Original Comment: memory corruption\n",
      "Generated Comment: memory corruption\n",
      "========================================\n",
      "Code: void InspectorNetworkAgent::WillSendRequest(  ExecutionContext* execution_context,  unsigned long identifier,  DocumentLoader* loader,  ResourceRequest& request,  const ResourceResponse& redirect_response,  const FetchInitiatorInfo& initiator_info) {  if (initiator_info.name == FetchInitiatorTypeNames::internal)  return;   if (initiator_info.name == FetchInitiatorTypeNames::document &&  loader->GetSubstituteData().IsValid())  return;   protocol::DictionaryValue* headers =  state_->getObject(NetworkAgentState::kExtraRequestHeaders);  if (headers) {  for (size_t i = 0; i < headers->size(); ++i) {  auto header = headers->at(i);  String value;  if (header.second->asString(&value))  request.SetHTTPHeaderField(AtomicString(header.first),  AtomicString(value));  }  }   request.SetReportRawHeaders(true);   if (state_->booleanProperty(NetworkAgentState::kCacheDisabled, false)) {  if (LoadsFromCacheOnly(request) &&  request.GetRequestContext() != WebURLRequest::kRequestContextInternal) {  request.SetCachePolicy(WebCachePolicy::kBypassCacheLoadOnlyFromCache);  } else {  request.SetCachePolicy(WebCachePolicy::kBypassingCache);  }  request.SetShouldResetAppCache(true);  }  if (state_->booleanProperty(NetworkAgentState::kBypassServiceWorker, false))  request.SetServiceWorkerMode(WebURLRequest::ServiceWorkerMode::kNone);  WillSendRequestInternal(execution_context, identifier, loader, request,  redirect_response, initiator_info);  if (!host_id_.IsEmpty()) {  request.AddHTTPHeaderField(  HTTPNames::X_DevTools_Emulate_Network_Conditions_Client_Id,  AtomicString(host_id_));  } } \n",
      "Original Comment: out-of-bounds memory access\n",
      "Generated Comment: out-of-bounds memory access\n",
      "========================================\n",
      "Code: SSH_PACKET_CALLBACK(ssh_packet_newkeys){  ssh_string sig_blob = NULL;  int rc;  (void)packet;  (void)user;  (void)type;  SSH_LOG(SSH_LOG_PROTOCOL, \"Received SSH_MSG_NEWKEYS\");  if(session->session_state!= SSH_SESSION_STATE_DH &&   session->dh_handshake_state != DH_STATE_NEWKEYS_SENT){  ssh_set_error(session,SSH_FATAL,\"ssh_packet_newkeys called in wrong state : %d:%d\",    session->session_state,session->dh_handshake_state);  goto error;  }  if(session->server){  /* server things are done in server.c */  session->dh_handshake_state=DH_STATE_FINISHED;  if (rc != SSH_OK) {  goto error;  }   /*  * Set the cryptographic functions for the next crypto  * (it is needed for generate_session_keys for key lengths)  */  if (crypt_set_algorithms(session, SSH_3DES) /* knows nothing about DES*/ ) {  goto error;  }   if (generate_session_keys(session) < 0) {  goto error;  }   /* Verify the host's signature. FIXME do it sooner */  sig_blob = session->next_crypto->dh_server_signature;  session->next_crypto->dh_server_signature = NULL;   /* get the server public key */  rc = ssh_pki_import_pubkey_blob(session->next_crypto->server_pubkey, &key);  if (rc < 0) {  return SSH_ERROR;  }   /* check if public key from server matches user preferences */  if (session->opts.wanted_methods[SSH_HOSTKEYS]) {  if(!ssh_match_group(session->opts.wanted_methods[SSH_HOSTKEYS],  key->type_c)) {  ssh_set_error(session,  SSH_FATAL,  \"Public key from server (%s) doesn't match user \"  \"preference (%s)\",  key->type_c,  session->opts.wanted_methods[SSH_HOSTKEYS]);  ssh_key_free(key);  return -1;  }  }   rc = ssh_pki_signature_verify_blob(session,  sig_blob,  key,  session->next_crypto->secret_hash,  session->next_crypto->digest_len);  /* Set the server public key type for known host checking */  session->next_crypto->server_pubkey_type = key->type_c;   ssh_key_free(key);  ssh_string_burn(sig_blob);  ssh_string_free(sig_blob);  sig_blob = NULL;  if (rc == SSH_ERROR) {  goto error;  }  SSH_LOG(SSH_LOG_PROTOCOL,\"Signature verified and valid\");   /*  * Once we got SSH2_MSG_NEWKEYS we can switch next_crypto and  * current_crypto  */  if (session->current_crypto) {  crypto_free(session->current_crypto);  session->current_crypto=NULL;  }   /* FIXME later, include a function to change keys */  session->current_crypto = session->next_crypto;   session->next_crypto = crypto_new();  if (session->next_crypto == NULL) {  ssh_set_error_oom(session);  goto error;  }  session->next_crypto->session_id = malloc(session->current_crypto->digest_len);  if (session->next_crypto->session_id == NULL) {  ssh_set_error_oom(session);  goto error;  }  memcpy(session->next_crypto->session_id, session->current_crypto->session_id,  session->current_crypto->digest_len);  }  session->dh_handshake_state = DH_STATE_FINISHED;  session->ssh_connection_callback(session);  return SSH_PACKET_USED; error:  session->session_state=SSH_SESSION_STATE_ERROR;  return SSH_PACKET_USED; } \n",
      "Original Comment: pointer dereference\n",
      "Generated Comment: pointer dereference\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_test.head(3).iterrows():\n",
    "    print('Code:', row.func_before)\n",
    "    print('Original Comment:', row.explain)\n",
    "    print('Generated Comment:', preds[idx])\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
