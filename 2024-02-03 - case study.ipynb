{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e4b1aa-cef1-4ca4-ad41-75717a8057de",
   "metadata": {},
   "source": [
    "# Reproduce LineVul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904a3755-cf47-4982-aee8-b7f748f46e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bc90c5-090a-46c0-bec0-9276e10934c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a92f87-fa42-47df-bd95-2eaf7e8c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad470abb-1096-4c9c-bf9e-d04244f46bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some warning from transformer\n",
    "# due to its verbose, disable\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94444f12-daab-47a8-aa7c-c296af8cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665ef7f0-266f-4504-bb27-d55b2cfd3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f929d687-4a2f-4988-a45c-48dcbe0de2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b209c02c-cee8-47ba-b29b-688f5a26c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_model import Model\n",
    "from linevul_helpers import TextDataset\n",
    "from linevul_extra import extract_line_attention, linevul_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e70b49-deec-4ad5-ac81-77213d9241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2dd844-e8c3-4e63-8957-049a8c8ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b698f48-aff8-436f-b7f9-c62449919530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fd88e94-6911-4cb5-b638-4d27287f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from LineVul\n",
    "checkpoint = '/home/hqn650/LineVul/linevul/saved_models/checkpoint-best-f1/12heads_linevul_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218433bf-aee1-474d-b426-352bfd77b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d994a186-c905-442b-b5fe-2e54cae6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base', \n",
    "                                                             config=config, \n",
    "                                                             ignore_mismatched_sizes=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f577da66-2711-4216-97da-37b3b229b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    device = device\n",
    "    n_gpu = n_gpu\n",
    "    use_non_pretrained_model = False\n",
    "    block_size = 512\n",
    "    test_data_file = '/home/hqn650/LineVul/data/big-vul_dataset/test.csv'\n",
    "    code_length=256\n",
    "    do_local_explanation=True\n",
    "    reasoning_method='attention'\n",
    "    seed=42\n",
    "    num_attention_heads=12\n",
    "    do_sorting_by_line_scores=False\n",
    "    do_sorting_by_pred_prob=False\n",
    "    top_k_constant=10\n",
    "    use_word_level_tokenizer=False\n",
    "    eval_batch_size=512\n",
    "\n",
    "    task = \"attack_vector\"\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032a6625-6694-4299-9132-60ac6c3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(pre_train, config, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9ca781-54df-4aee-b028-946f8bb5d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=args.device))\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503ba7b6-5696-45a9-92d3-80dacce48583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_helpers import TextDataset, convert_examples_to_features\n",
    "\n",
    "class ExtendTextDataset(TextDataset):\n",
    "    def __init__(self, tokenizer, args, data_frame):\n",
    "        self.examples = []\n",
    "        funcs = data_frame[\"processed_func\"].tolist()\n",
    "        for i in tqdm(range(len(funcs)), desc='ExtendTextDataset'):\n",
    "            self.examples.append(convert_examples_to_features(funcs[i], 1, tokenizer, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c95b49-9206-4aa0-b23e-8f81fbaac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu evaluate\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1353b16f-771d-4734-9309-2743fd2f2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\n",
    "\"\"\"\n",
    "static void __put_super(struct super_block *sb)\n",
    "{\n",
    "\tif (!--sb->s_count) {\n",
    "\t\tlist_del_init(&sb->s_list);\n",
    "\t\tdestroy_super(sb);\n",
    "\t}\n",
    "}\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "pcf_read_TOC( FT_Stream  stream,\n",
    "                PCF_Face   face )\n",
    "  {\n",
    "    FT_Error   error;\n",
    "    PCF_Toc    toc = &face->toc;\n",
    "    PCF_Table  tables;\n",
    "\n",
    "    FT_Memory  memory = FT_FACE( face )->memory;\n",
    "    FT_UInt    n;\n",
    "\n",
    "\n",
    "    if ( FT_STREAM_SEEK ( 0 )                          ||\n",
    "         FT_STREAM_READ_FIELDS ( pcf_toc_header, toc ) )\n",
    "      return FT_THROW( Cannot_Open_Resource );\n",
    "\n",
    "    if ( toc->version != PCF_FILE_VERSION                 ||\n",
    "         toc->count   >  FT_ARRAY_MAX( face->toc.tables ) ||\n",
    "         toc->count   == 0                                )\n",
    "      return FT_THROW( Invalid_File_Format );\n",
    "\n",
    "    if ( FT_NEW_ARRAY( face->toc.tables, toc->count ) )\n",
    "      return FT_THROW( Out_Of_Memory );\n",
    "\n",
    "    tables = face->toc.tables;\n",
    "    for ( n = 0; n < toc->count; n++ )\n",
    "    {\n",
    "      if ( FT_STREAM_READ_FIELDS( pcf_table_header, tables ) )\n",
    "        goto Exit;\n",
    "      tables++;\n",
    "    }\n",
    "\n",
    "    /* Sort tables and check for overlaps.  Because they are almost      */\n",
    "    /* always ordered already, an in-place bubble sort with simultaneous */\n",
    "    /* boundary checking seems appropriate.                              */\n",
    "    tables = face->toc.tables;\n",
    "\n",
    "    for ( n = 0; n < toc->count - 1; n++ )\n",
    "    {\n",
    "      FT_UInt  i, have_change;\n",
    "\n",
    "\n",
    "      have_change = 0;\n",
    "\n",
    "      for ( i = 0; i < toc->count - 1 - n; i++ )\n",
    "      {\n",
    "        PCF_TableRec  tmp;\n",
    "\n",
    "\n",
    "        if ( tables[i].offset > tables[i + 1].offset )\n",
    "        {\n",
    "          tmp           = tables[i];\n",
    "          tables[i]     = tables[i + 1];\n",
    "          tables[i + 1] = tmp;\n",
    "\n",
    "          have_change = 1;\n",
    "        }\n",
    "\n",
    "        if ( ( tables[i].size   > tables[i + 1].offset )                  ||\n",
    "             ( tables[i].offset > tables[i + 1].offset - tables[i].size ) )\n",
    "        {\n",
    "          error = FT_THROW( Invalid_Offset );\n",
    "          goto Exit;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      if ( !have_change )\n",
    "        break;\n",
    "    }\n",
    "\n",
    "    /* we now check whether the `size' and `offset' values are reasonable: */\n",
    "    /* `offset' + `size' must not exceed the stream size                   */\n",
    "    tables = face->toc.tables;\n",
    "    for ( n = 0; n < toc->count; n++ )\n",
    "    {\n",
    "      /* we need two checks to avoid overflow */\n",
    "      if ( ( tables->size   > stream->size                ) ||\n",
    "           ( tables->offset > stream->size - tables->size ) )\n",
    "      {\n",
    "        error = FT_THROW( Invalid_Table );\n",
    "        goto Exit;\n",
    "      }\n",
    "      tables++;\n",
    "    }\n",
    "\n",
    "#ifdef FT_DEBUG_LEVEL_TRACE\n",
    "\n",
    "    {\n",
    "      FT_UInt      i, j;\n",
    "      const char*  name = \"?\";\n",
    "\n",
    "\n",
    "      FT_TRACE4(( \"pcf_read_TOC:\\n\" ));\n",
    "\n",
    "      FT_TRACE4(( \"  number of tables: %ld\\n\", face->toc.count ));\n",
    "\n",
    "      tables = face->toc.tables;\n",
    "      for ( i = 0; i < toc->count; i++ )\n",
    "      {\n",
    "        for ( j = 0; j < sizeof ( tableNames ) / sizeof ( tableNames[0] );\n",
    "              j++ )\n",
    "          if ( tables[i].type == (FT_UInt)( 1 << j ) )\n",
    "            name = tableNames[j];\n",
    "\n",
    "        FT_TRACE4(( \"  %d: type=%s, format=0x%X, \"\n",
    "                    \"size=%ld (0x%lX), offset=%ld (0x%lX)\\n\",\n",
    "                    i, name,\n",
    "                    tables[i].format,\n",
    "                    tables[i].size, tables[i].size,\n",
    "                    tables[i].offset, tables[i].offset ));\n",
    "      }\n",
    "    }\n",
    "\n",
    "#endif\n",
    "\n",
    "    return FT_Err_Ok;\n",
    "\n",
    "  Exit:\n",
    "    FT_FREE( face->toc.tables );\n",
    "    return error;\n",
    "  }\n",
    "\"\"\",\n",
    "\"\"\"static void make_response(struct xen_blkif_ring *ring, u64 id,\n",
    "                          unsigned short op, int st) {\n",
    "  struct blkif_response resp;\n",
    "  unsigned long flags;\n",
    "  union blkif_back_rings *blk_rings;\n",
    "  int notify;\n",
    "  resp.id = id; // unsecure statement\n",
    "  resp.operation = op; // unsecure statement\n",
    "  resp.status = st; // unsecure statement\n",
    "  spin_lock_irqsave(&ring->blk_ring_lock, flags);\n",
    "  blk_rings = &ring->blk_rings; \n",
    "  switch (ring->blkif->blk_protocol) {\n",
    "    case BLKIF_PROTOCOL_NATIVE:\n",
    "      memcpy(\n",
    "          RING_GET_RESPONSE(&blk_rings->native, blk_rings->native.rsp_prod_pvt),\n",
    "          &resp, sizeof(resp));  // unsecure statement\n",
    "      break;\n",
    "    case BLKIF_PROTOCOL_X86_32:\n",
    "      memcpy(\n",
    "          RING_GET_RESPONSE(&blk_rings->x86_32, blk_rings->x86_32.rsp_prod_pvt),\n",
    "          &resp, sizeof(resp)); // unsecure statement\n",
    "      break;\n",
    "    case BLKIF_PROTOCOL_X86_64:\n",
    "      memcpy(\n",
    "          RING_GET_RESPONSE(&blk_rings->x86_64, blk_rings->x86_64.rsp_prod_pvt),\n",
    "          &resp, sizeof(resp)); // unsecure statement\n",
    "      break;\n",
    "    default:\n",
    "      BUG();\n",
    "  }\n",
    "  blk_rings->common.rsp_prod_pvt++;\n",
    "  RING_PUSH_RESPONSES_AND_CHECK_NOTIFY(&blk_rings->common, notify);\n",
    "  spin_unlock_irqrestore(&ring->blk_ring_lock, flags);\n",
    "  if (notify) notify_remote_via_irq(ring->irq);\n",
    "}\"\"\",\n",
    "\"\"\"static void write_version(FILE *fp, const char *fname, const char *dirname,\n",
    "                          xref_t *xref) {\n",
    "  long start;\n",
    "  char *c, *new_fname, data;\n",
    "  FILE *new_fp;\n",
    "  start = ftell(fp);\n",
    "  if ((c = strstr(fname, \".pdf\"))) *c = '\\0';\n",
    "  new_fname = malloc(strlen(fname) + strlen(dirname) + 16); // insecure statement\n",
    "  snprintf(new_fname, strlen(fname) + strlen(dirname) + 16,\n",
    "           \"%s/%s-version-%d.pdf\", dirname, fname, xref->version);\n",
    "  if (!(new_fp = fopen(new_fname, \"w\"))) {\n",
    "    ERR(\"Could not create file '%s'\\n\", new_fname);\n",
    "    fseek(fp, start, SEEK_SET);\n",
    "    free(new_fname);\n",
    "    return;\n",
    "  } \n",
    "  fseek(fp, 0, SEEK_SET);\n",
    "  while (fread(&data, 1, 1, fp))\n",
    "    fwrite(&data, 1, 1,\n",
    "           new_fp); \n",
    "  fprintf(new_fp, \"\\r\\nstartxref\\r\\n%ld\\r\\n%%%%EOF\", xref->start);\n",
    "  fclose(new_fp);\n",
    "  free(new_fname);\n",
    "  fseek(fp, start, SEEK_SET);\n",
    "}\"\"\",\n",
    "\"\"\"\n",
    "void *vips_malloc( VipsObject *object, size_t size ) {\n",
    "  void *buf;\n",
    "  buf = g_malloc( size ); \n",
    "  if( object ) {\n",
    "  g_signal_connect( object, \"postclose\",\n",
    "  G_CALLBACK( vips_malloc_cb ), buf );\n",
    "      object->local_memory += size;\n",
    "  }\n",
    "  return( buf );\n",
    "}\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ee7ea1a-7bd4-48ce-aa00-9534e48fbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'processed_func': cases, \"target\": [0,0,1,1,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc0ed7c4-1e65-4c65-9605-9ae7fad0cb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_func</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nstatic void __put_super(struct super_block *...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\npcf_read_TOC( FT_Stream  stream,\\n          ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void make_response(struct xen_blkif_rin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void write_version(FILE *fp, const char...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nvoid *vips_malloc( VipsObject *object, size_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      processed_func  target\n",
       "0  \\nstatic void __put_super(struct super_block *...       0\n",
       "1  \\npcf_read_TOC( FT_Stream  stream,\\n          ...       0\n",
       "2  static void make_response(struct xen_blkif_rin...       1\n",
       "3  static void write_version(FILE *fp, const char...       1\n",
       "4  \\nvoid *vips_malloc( VipsObject *object, size_...       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18176fec-0ab9-40c1-a867-22b09e441ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find TP\n",
    "def find_tp(model, tokenizer, args, data_frame=None):\n",
    "    if data_frame is not None:\n",
    "        dataset = ExtendTextDataset(tokenizer, args, data_frame)\n",
    "    else:\n",
    "        dataset = TextDataset(tokenizer, args, file_type='test')\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    data_loader = DataLoader(dataset, sampler=sampler, batch_size=args.eval_batch_size, num_workers=0)\n",
    "    result, y_trues, y_preds = linevul_predict(model, data_loader, args.device)\n",
    "    tp_indices = np.where((y_trues == y_preds) & (y_trues == 1))\n",
    "    tp_indices = list(tp_indices[0])\n",
    "    return result, tp_indices, y_trues, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "477224b6-0abb-454f-b0de-7f4f31a473fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002747058868408203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 99,
       "postfix": null,
       "prefix": "ExtendTextDataset",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756e1b65bf964afb98a61ed76fe17318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExtendTextDataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "result, correct_indices, y, y_hat = find_tp(model, tokenizer, args, data_frame=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14aa0a8a-c916-4034-a0c8-c41d27318f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55a200c8-b3df-4e71-aa52-aa1977cb0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(model, tokenizer, explain_indices, data_frame=None): \n",
    "    \"\"\" \n",
    "        return (sample_idx, lines, n_lines)\n",
    "    \"\"\"\n",
    "    if data_frame is not None:\n",
    "        dataset = ExtendTextDataset(tokenizer, args, data_frame)\n",
    "    else:\n",
    "        dataset = TextDataset(tokenizer, args, file_type='test')\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    data_loader = DataLoader(dataset, sampler=sampler, batch_size=1, num_workers=0)\n",
    "    model.eval()\n",
    "    index = 0\n",
    "    progress_bar = tqdm(data_loader, total=len(data_loader))\n",
    "    extract_list = []\n",
    "    for mini_batch in progress_bar:\n",
    "        if index in explain_indices:\n",
    "            (input_ids, labels) = mini_batch\n",
    "            ids = input_ids[0].detach().tolist()\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "            all_tokens = [token.replace(\"Ġ\", \"\") for token in all_tokens]\n",
    "            all_tokens = [token.replace(\"ĉ\", \"Ċ\") for token in all_tokens]\n",
    "            with torch.no_grad():\n",
    "                prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "            lines_with_score, n_lines = extract_line_attention(attentions, all_tokens)\n",
    "            extract_list.append((index, lines_with_score, n_lines))\n",
    "        index += 1\n",
    "    return extract_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "688eecd2-a8af-4d8c-862c-4cd93f08a099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0031621456146240234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 99,
       "postfix": null,
       "prefix": "ExtendTextDataset",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff4179373e5433b8d7106d7ceec33ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExtendTextDataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0026121139526367188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 99,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4f3eb422b64b23adb857e1da94af82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_list = explain(model, tokenizer, [0,1,2,3,4], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0203581-99a2-48b8-b27d-853a90f74b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [(1, 'staticvoid__put_super(structsuper_block*sb)', 790.4317779541016),\n",
       "   (7, 'list_del_init(&sb->s_list);', 745.5436553955078),\n",
       "   (4, 'if(!--sb->s_count){', 630.649486541748),\n",
       "   (10, 'destroy_super(sb);', 390.7985954284668),\n",
       "   (13, '}', 112.63846588134766),\n",
       "   (12, '}', 111.76204681396484),\n",
       "   (2, '{', 96.75848007202148),\n",
       "   (0, '', 61.17894744873047),\n",
       "   (5, '', 36.56650161743164),\n",
       "   (6, '', 34.87374496459961),\n",
       "   (9, '', 28.109703063964844),\n",
       "   (8, '', 27.800952911376953),\n",
       "   (3, '', 27.059484481811523),\n",
       "   (11, '', 25.973024368286133)],\n",
       "  14),\n",
       " (1,\n",
       "  [(15, 'toc->count==0)', 399.1795516014099),\n",
       "   (14, 'toc->count>FT_ARRAY_MAX(face->toc.tables)||', 391.22833824157715),\n",
       "   (10, 'if(FT_STREAM_SEEK(0)||', 381.99241733551025),\n",
       "   (22,\n",
       "    'if(FT_STREAM_READ_FIELDS(pcf_table_header,tables))',\n",
       "    377.89522981643677),\n",
       "   (11, 'FT_STREAM_READ_FIELDS(pcf_toc_header,toc))', 367.79677963256836),\n",
       "   (17, 'if(FT_NEW_ARRAY(face->toc.tables,toc->count))', 363.3032703399658),\n",
       "   (13, 'if(toc->version!=PCF_FILE_VERSION||', 356.1378507614136),\n",
       "   (26,\n",
       "    '/*Sorttablesandcheckforoverlaps.Becausetheyarealmost*/',\n",
       "    350.92967987060547),\n",
       "   (20, 'for(n=0;n<toc->count;n++)', 263.66503524780273),\n",
       "   (7, 'FT_Memorymemory=FT_FACE(face)->memory;', 250.51574611663818),\n",
       "   (12, 'returnFT_THROW(Cannot_Open_Resource);', 248.8444151878357),\n",
       "   (16, 'returnFT_THROW(Invalid_File_Format);', 248.68031215667725),\n",
       "   (18, 'returnFT_THROW(Out_Of_Memory);', 248.31799602508545),\n",
       "   (5, 'PCF_Toctoc=&face->toc;', 240.79170894622803),\n",
       "   (1, 'pcf_read_TOC(FT_Streamstream,', 208.02318572998047),\n",
       "   (2, 'PCF_Faceface)', 207.5978503227234),\n",
       "   (19, 'tables=face->toc.tables;', 183.01623439788818),\n",
       "   (23, 'gotoExit;', 148.0626630783081),\n",
       "   (8, 'FT_UIntn;', 145.38961172103882),\n",
       "   (6, 'PCF_Tabletables;', 129.39732217788696),\n",
       "   (4, 'FT_Errorerror;', 121.80377769470215),\n",
       "   (27, '/*alwaysordered', 89.22587490081787),\n",
       "   (24, 'tables++;', 87.0548300743103),\n",
       "   (25, '}', 63.75015735626221),\n",
       "   (21, '{', 51.82007122039795),\n",
       "   (3, '{', 34.55564594268799),\n",
       "   (9, '', 17.5065860748291),\n",
       "   (0, '', 15.201930046081543)],\n",
       "  28),\n",
       " (2,\n",
       "  [(24,\n",
       "    'RING_GET_RESPONSE(&blk_rings->x86_64,blk_rings->x86_64.rsp_prod_pvt),',\n",
       "    614.1121644973755),\n",
       "   (19,\n",
       "    'RING_GET_RESPONSE(&blk_rings->x86_32,blk_rings->x86_32.rsp_prod_pvt),',\n",
       "    587.9667973518372),\n",
       "   (14,\n",
       "    'RING_GET_RESPONSE(&blk_rings->native,blk_rings->native.rsp_prod_pvt),',\n",
       "    518.7284593582153),\n",
       "   (0,\n",
       "    'staticvoidmake_response(structxen_blkif_ring*ring,u64id,',\n",
       "    293.1751251220703),\n",
       "   (1, 'unsignedshortop,intst){', 270.0005121231079),\n",
       "   (25, '&resp,sizeof(resp));//unsecurestatement', 263.88504695892334),\n",
       "   (9, 'spin_lock_irqsave(&ring->blk_ring_lock,flags);', 258.4215302467346),\n",
       "   (20, '&resp,sizeof(resp));//unsecurestatement', 256.488974571228),\n",
       "   (15, '&resp,sizeof(resp));//unsecurestatement', 255.69355583190918),\n",
       "   (22, 'caseBLKIF_PROTOCOL_X86_64:', 234.20462036132812),\n",
       "   (17, 'caseBLKIF_PROTOCOL_X86_32:', 222.03554153442383),\n",
       "   (11, 'switch(ring->blkif->blk_protocol){', 213.5333309173584),\n",
       "   (12, 'caseBLKIF_PROTOCOL_NATIVE:', 200.7964015007019),\n",
       "   (4, 'unionblkif_back_rings*blk_rings;', 190.21099853515625),\n",
       "   (10, 'blk_rings=&ring->blk_rings;', 187.27396202087402),\n",
       "   (7, 'resp.operation=op;//unsecurestatement', 159.3009638786316),\n",
       "   (8, 'resp.status=st;//unsecurestatement', 156.88555335998535),\n",
       "   (6, 'resp.id=id;//unsecurestatement', 155.9539279937744),\n",
       "   (2, 'structblkif_responseresp;', 124.97722148895264),\n",
       "   (23, 'memcpy(', 112.46838855743408),\n",
       "   (18, 'memcpy(', 105.7673192024231),\n",
       "   (13, 'memcpy(', 100.67088842391968),\n",
       "   (26, 'break;', 83.93399715423584),\n",
       "   (21, 'break;', 80.29248046875),\n",
       "   (16, 'break;', 76.23565435409546),\n",
       "   (3, 'unsignedlongflags;', 74.63678169250488),\n",
       "   (27, 'default:', 71.84339332580566),\n",
       "   (5, 'intnotify;', 62.56974458694458),\n",
       "   (28, 'BUG', 58.219040870666504)],\n",
       "  29),\n",
       " (3,\n",
       "  [(9,\n",
       "    '\"%s/%s-version-%d.pdf\",dirname,fname,xref->version);',\n",
       "    467.3765091896057),\n",
       "   (7,\n",
       "    'new_fname=malloc(strlen(fname)+strlen(dirname)+16);//insecurestatement',\n",
       "    417.97172927856445),\n",
       "   (8,\n",
       "    'snprintf(new_fname,strlen(fname)+strlen(dirname)+16,',\n",
       "    385.40984869003296),\n",
       "   (10, 'if(!(new_fp=fopen(new_fname,\"w\"))){', 370.90156269073486),\n",
       "   (0,\n",
       "    'staticvoidwrite_version(FILE*fp,constchar*fname,constchar*dirname,',\n",
       "    336.3478422164917),\n",
       "   (6, 'if((c=strstr(fname,\".pdf\")))*c=\\'Ā\\';', 333.64590644836426),\n",
       "   (1, 'xref_t*xref){', 289.2465877532959),\n",
       "   (13, 'fseek(fp,start,SEEK_SET);', 236.49481344223022),\n",
       "   (18, 'while(fread(&data,1,1,fp))', 232.9103388786316),\n",
       "   (11, 'ERR(\"Couldnotcreatefile\\'%s\\'', 222.87695407867432),\n",
       "   (17, 'fseek(fp,0,SEEK_SET);', 214.51242923736572),\n",
       "   (27, 'fseek(fp,start,SEEK_SET);', 201.7338089942932),\n",
       "   (3, 'char*c,*new_fname,data;', 176.89692878723145),\n",
       "   (19, 'fwrite(&data,1,1,', 175.41667795181274),\n",
       "   (21, 'fprintf(new_fp,\"č', 174.6598253250122),\n",
       "   (14, 'free(new_fname);', 156.52470016479492),\n",
       "   (24, '%%%%EOF\",xref->start);', 150.1839895248413),\n",
       "   (20, 'new_fp);', 147.54432487487793),\n",
       "   (25, 'fclose(new_fp);', 135.16268062591553),\n",
       "   (26, 'free(new_fname);', 127.71938180923462),\n",
       "   (5, 'start=ftell(fp);', 122.7153673171997),\n",
       "   (12, '\",new_fname);', 115.23520469665527),\n",
       "   (4, 'FILE*new_fp;', 108.72249412536621),\n",
       "   (22, 'startxrefč', 76.95495796203613),\n",
       "   (15, 'return;', 70.62212753295898),\n",
       "   (23, '%ldč', 68.10447788238525),\n",
       "   (2, 'longstart;', 67.362624168396),\n",
       "   (16, '}', 46.97175931930542),\n",
       "   (28, '}', 12.274026870727539)],\n",
       "  29),\n",
       " (4,\n",
       "  [(1, 'void*vips_malloc(VipsObject*object,size_tsize){', 732.6699409484863),\n",
       "   (6, 'G_CALLBACK(vips_malloc_cb),buf);', 648.0517845153809),\n",
       "   (5, 'g_signal_connect(object,\"postclose\",', 543.1841115951538),\n",
       "   (3, 'buf=g_malloc(size);', 501.38316345214844),\n",
       "   (7, 'object->local_memory+=size;', 411.53164863586426),\n",
       "   (9, 'return(buf);', 230.1158332824707),\n",
       "   (4, 'if(object){', 227.21017265319824),\n",
       "   (2, 'void*buf;', 192.69032859802246),\n",
       "   (8, '}', 80.7021131515503),\n",
       "   (10, '}', 65.12022018432617),\n",
       "   (0, '', 45.1768684387207)],\n",
       "  11)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#203\n",
    "extract_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428cf5e-3023-4990-9a0f-bdd78989cc16",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3bbc83-0135-413e-a9df-0047acb20a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons import clean_generated_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f8605ef-5bd5-41fc-9e09-b2211f1bbb58",
   "metadata": {},
   "source": [
    "# Attack vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46b65603-38d7-4038-9392-0b1855f00106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class AttackVectorArgs:\n",
    "    model_name = \"results/attack_vector/t5p_script_770m/checkpoint-1600/\"\n",
    "    max_des_length = 150\n",
    "    \n",
    "attack_vector_args = AttackVectorArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba1f1782-433f-4398-9b27-420d364de75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "attack_vector_tokenizer = AutoTokenizer.from_pretrained(attack_vector_args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c103293-4f84-4cae-b523-97ad2f441203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "attack_vector = AutoModelForSeq2SeqLM.from_pretrained(attack_vector_args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91a703dd-b698-4106-87fe-18a832555b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_vector_code = attack_vector_tokenizer(cases, return_tensors=\"pt\", padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9a9acfb-2fd3-4f83-ae0a-dcbc1cffbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    input_feature = attack_vector_tokenizer(example, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    return input_feature\n",
    "tokenized_cases = [preprocess_function(i) for i in cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb3f42c3-19a9-4805-9e2a-11d30c84ba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "via unspecified use of Asynchronous I/O (AIO ) operations.\n",
      "using a specially-crafted font\n",
      "via vectors related to the handling of input.\n",
      "creating a symbolic link from a temporary file to various files on the system\n",
      " which triggers a heap-based buffer overflow.\n"
     ]
    }
   ],
   "source": [
    "generated_attack_vec = []\n",
    "for i in tokenized_cases:\n",
    "    output = attack_vector.generate(**i, max_length=attack_vector_args.max_des_length)\n",
    "    explain = attack_vector_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(explain)\n",
    "    generated_attack_vec.append(explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14fc7a7-01e4-4cfc-8c11-c9827f746602",
   "metadata": {},
   "source": [
    "# Root Cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc42f556-7822-49c7-827b-020f5487fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RootCauseArgs:\n",
    "    model_name = \"results/root_cause/t5p_script_770m/checkpoint-1100/\"\n",
    "    max_des_length = 153\n",
    "    \n",
    "root_cause_args = RootCauseArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55299ee0-f1a6-4817-831d-360415c1e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_cause_tokenizer = AutoTokenizer.from_pretrained(root_cause_args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbe0ad37-58b6-4e7b-9d27-787c832f4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    input_feature = root_cause_tokenizer(example, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    return input_feature\n",
    "tokenized_cases = [preprocess_function(i) for i in cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9cf0bd8-2a2f-4162-b0a8-f5cb43fb8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_cause = AutoModelForSeq2SeqLM.from_pretrained(root_cause_args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f388b6e-0d48-4f6d-89e6-a635670bb6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a soft lockup when performing\\r\\nAsynchronous I/O operations due to files_lock excessive locking\n",
      "does not check for the end of the data during certain reading operations \n",
      "the failure to properly copy the contents of the ring producer/consumer pointers\n",
      "doesn't validate a certain size value \n",
      "an integer overflow when allocating memory\n"
     ]
    }
   ],
   "source": [
    "generated_root_cause = []\n",
    "for i in tokenized_cases:\n",
    "    output = root_cause.generate(**i, max_length=attack_vector_args.max_des_length)\n",
    "    explain = root_cause_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(explain)\n",
    "    generated_root_cause.append(explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58e21f-9b8b-4052-a6a7-1aef50635e83",
   "metadata": {},
   "source": [
    "# Vulnerability Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "076a2e2f-0c0f-451c-b235-8a473f43c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TypeArgs:\n",
    "    model_name = \"results/vulnerability_type/t5p_script_770m/checkpoint-1250/\"\n",
    "    max_des_length = 53\n",
    "    \n",
    "vul_type_args = TypeArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d955875c-9aad-4aa4-af17-041123e5d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "vul_type_tokenizer = AutoTokenizer.from_pretrained(vul_type_args.model_name)\n",
    "vul_type = AutoModelForSeq2SeqLM.from_pretrained(vul_type_args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae14a59d-789d-4e63-841c-f4aa3aac2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    input_feature = vul_type_tokenizer(example, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    return input_feature\n",
    "tokenized_cases = [preprocess_function(i) for i in cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "345cf0b5-5c7d-44b4-99ff-4da31e532831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use-after-free error\n",
      "pointer dereference\n",
      "memory corruption\n",
      "out-of-bounds write\n",
      "memory corruption\n"
     ]
    }
   ],
   "source": [
    "generated_vul_type = []\n",
    "for i in tokenized_cases:\n",
    "    output = vul_type.generate(**i, max_length=attack_vector_args.max_des_length)\n",
    "    explain = vul_type_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(explain)\n",
    "    generated_vul_type.append(explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59f8de-14b5-45f5-abfd-bc862658b346",
   "metadata": {},
   "source": [
    "# Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e4496f8-476c-420c-95f6-bc87cd224aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImpactArgs:\n",
    "    model_name = \"results/impact/t5p_script_770m/checkpoint-1750/\"\n",
    "    max_des_length = 167\n",
    "    \n",
    "impact_args = ImpactArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "228d1fa0-3b6b-4dca-9572-9abe3d155c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_tokenizer = AutoTokenizer.from_pretrained(impact_args.model_name)\n",
    "impact = AutoModelForSeq2SeqLM.from_pretrained(impact_args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "899ffbdc-a9d2-4e91-ab59-07d1ba9181b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    input_feature = impact_tokenizer(example, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    return input_feature\n",
    "tokenized_cases = [preprocess_function(i) for i in cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52d93b64-2e9e-4ad9-b8f4-90c0447acd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cause a denial of service (system crash )\n",
      "a denial of service\n",
      "leak kernel memory bytes and obtain sensitive information\n",
      "execute arbitrary code or cause a denial of service condition\n",
      "leaking raw process memory contents through the output image.\n"
     ]
    }
   ],
   "source": [
    "generated_impact = []\n",
    "for i in tokenized_cases:\n",
    "    output = impact.generate(**i, max_length=attack_vector_args.max_des_length)\n",
    "    explain = impact_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(explain)\n",
    "    generated_impact.append(explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd11a47-76d3-4a02-b0cf-9e85ee48a09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
