{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from project_dataset import load_dataset\n",
    "from code2nl.model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_name = \"microsoft/codebert-base\"\n",
    "    num_proc = 4\n",
    "    batch_size = 40\n",
    "    max_source_length = 512  \n",
    "    max_target_length = 167 \n",
    "    data_cols = [\"CVE ID\", \"explain\", \"func_before\"]\n",
    "    save_dir = 'tf_board'\n",
    "    epochs = 100\n",
    "    grad_acc_steps = 4\n",
    "    lr = 5e-5\n",
    "    log_freq = 10\n",
    "    local_rank = -1\n",
    "    deepspeed = None\n",
    "    fp16 = False\n",
    "    lr_warmup_steps = 200\n",
    "    weight_decay = 0.05\n",
    "    task = \"impact\"\n",
    "    prefix = 'codebert'\n",
    "    do_lower_case = False\n",
    "    beam_size = 10\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(args.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 7032\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 782\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 1954\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds['train']\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "df_val = ds['validation']\n",
    "df_val = df_val.to_pandas()\n",
    "\n",
    "df_test = ds['test']\n",
    "df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVE ID</th>\n",
       "      <th>explain</th>\n",
       "      <th>func_before</th>\n",
       "      <th>processed_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-2017-15537</td>\n",
       "      <td>read the FPU registers of other processes on t...</td>\n",
       "      <td>int xstateregs_set(struct task_struct *target,...</td>\n",
       "      <td>int xstateregs_set(struct task_struct *target,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-2011-2875</td>\n",
       "      <td>cause a denial of service or possibly have uns...</td>\n",
       "      <td>WebRTCSessionDescriptionDescriptor MockWebRTCP...</td>\n",
       "      <td>WebRTCSessionDescriptionDescriptor\\nMockWebRTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-2016-4303</td>\n",
       "      <td>overflow a buffer and execute arbitrary code o...</td>\n",
       "      <td>int cJSON_GetArraySize( cJSON *array ) {  cJSO...</td>\n",
       "      <td>int cJSON_GetArraySize(cJSON *array) {\\n  cJSO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CVE ID                                            explain  \\\n",
       "0  CVE-2017-15537  read the FPU registers of other processes on t...   \n",
       "1   CVE-2011-2875  cause a denial of service or possibly have uns...   \n",
       "2   CVE-2016-4303  overflow a buffer and execute arbitrary code o...   \n",
       "\n",
       "                                         func_before  \\\n",
       "0  int xstateregs_set(struct task_struct *target,...   \n",
       "1  WebRTCSessionDescriptionDescriptor MockWebRTCP...   \n",
       "2  int cJSON_GetArraySize( cJSON *array ) {  cJSO...   \n",
       "\n",
       "                                      processed_func  \n",
       "0  int xstateregs_set(struct task_struct *target,...  \n",
       "1  WebRTCSessionDescriptionDescriptor\\nMockWebRTC...  \n",
       "2  int cJSON_GetArraySize(cJSON *array) {\\n  cJSO...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "os.makedirs(f'tmp_data/{args.task}', exist_ok=True)\n",
    "os.makedirs(f'{args.save_dir}/{args.prefix}_{args.task}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_train['code_tokens'] = df_train.func_before.apply(lambda x: x.split())\n",
    "df_train['docstring_tokens'] = df_train.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/train.jsonl','w') as f:\n",
    "    for _, row in df_train.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_val['code_tokens'] = df_val.func_before.apply(lambda x: x.split())\n",
    "df_val['docstring_tokens'] = df_val.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/valid.jsonl','w') as f:\n",
    "    for _, row in df_val.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_test['code_tokens'] = df_test.func_before.apply(lambda x: x.split())\n",
    "df_test['docstring_tokens'] = df_test.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/test.jsonl','w') as f:\n",
    "    for _, row in df_test.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/20/2023 16:19:26 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='tf_board/codebert_impact', load_model_path=None, train_filename='tmp_data/impact/train.jsonl', dev_filename='tmp_data/impact/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=167, do_train=True, do_eval=True, do_test=False, do_lower_case=True, no_cuda=False, train_batch_size=40, eval_batch_size=40, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/20/2023 16:19:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   idx: 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_tokens: ['<s>', 'int', '_x', 'state', 'reg', 's', '_', 'set', '(', 'struct', '_task', '_', 'struct', '_*', 'target', ',', '_const', '_struct', '_user', '_', 'reg', 'set', '_*', 'reg', 'set', ',', '_unsigned', '_int', '_pos', ',', '_unsigned', '_int', '_count', ',', '_const', '_void', '_*', 'k', 'buf', ',', '_const', '_void', '___', 'user', '_*', 'ub', 'uf', ')', '_{', '_struct', '_f', 'pu', '_*', 'f', 'pu', '_=', '_&', 'target', '->', 'thread', '.', 'f', 'pu', ';', '_struct', '_x', 'reg', 's', '_', 'state', '_*', 'x', 'save', ';', '_int', '_ret', ';', '_if', '_(!', 'boot', '_', 'cpu', '_', 'has', '(', 'X', '86', '_', 'FE', 'ATURE', '_', 'X', 'SA', 'VE', '))', '_return', '_-', 'EN', 'ODE', 'V', ';', '_/*', '_*', '_A', '_whole', '_standard', '-', 'format', '_X', 'SA', 'VE', '_buffer', '_is', '_needed', ':', '_*/', '_if', '_((', 'pos', '_!=', '_0', ')', '_||', '_(', 'count', '_<', '_f', 'pu', '_', 'user', '_', 'x', 'state', '_', 'size', '))', '_return', '_-', 'E', 'FAULT', ';', '_x', 'save', '_=', '_&', 'f', 'pu', '->', 'state', '.', 'x', 'save', ';', '_f', 'pu', '__', 'activate', '_', 'fp', 'state', '_', 'write', '(', 'f', 'pu', ');', '_if', '_(', 'boot', '_', 'cpu', '_', 'has', '(', 'X', '86', '_', 'FE', 'ATURE', '_', 'X', 'SA', 'V', 'ES', '))', '_{', '_if', '_(', 'k', 'buf', ')', '_ret', '_=', '_copy', '_', 'kernel', '_', 'to', '_', 'x', 'state', '(', 'x', 'save', ',', '_k', 'buf', ');', '_else', '_ret', '_=', '_copy', '_', 'user', '_', 'to', '_', 'x', 'state', '(', 'x', 'save', ',', '_ub', 'uf', ');', '_}', '_else', '_{', '_ret', '_=', '_user', '_', 'reg', 'set', '_', 'copy', 'in', '(&', 'pos', ',', '_&', 'count', ',', '_&', 'k', 'buf', ',', '_&', 'ub', 'uf', ',', '_x', 'save', ',', '_0', ',', '_-', '1', ');', '_}', '_/*', '_*', '_In', '_case', '_of', '_failure', ',', '_mark', '_all', '_states', '_as', '_init', ':', '_*/', '_if', '_(', 'ret', ')', '_f', 'p', 'state', '_', 'init', '(&', 'f', 'pu', '->', 'state', ');', '_/*', '_*', '_m', 'x', 'cs', 'r', '_reserved', '_bits', '_must', '_be', '_masked', '_to', '_zero', '_for', '_security', '_reasons', '.', '_*/', '_x', 'save', '->', 'i', '387', '.', 'mx', 'cs', 'r', '_&', '=', '_m', 'x', 'cs', 'r', '_', 'feature', '_', 'mask', ';', '_x', 'save', '->', 'header', '.', 'xf', 'eatures', '_&', '=', '_x', 'features', '_', 'mask', ';', '_/*', '_*', '_These', '_bits', '_must', '_be', '_zero', '.', '_*/', '_mem', 'set', '(&', 'x', 'save', '->', 'header', '.', 'res', 'erved', ',', '_0', ',', '_48', ');', '_return', '_ret', ';', '_}', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_ids: 0 2544 3023 4897 4950 29 1215 8738 1640 25384 3685 1215 25384 1009 23976 6 10759 29916 3018 1215 4950 8738 1009 4950 8738 6 39023 6979 8593 6 39023 6979 3212 6 10759 13842 1009 330 48939 6 10759 13842 27148 12105 1009 1792 2951 43 25522 29916 856 30738 1009 506 30738 5457 359 23976 46613 43935 4 506 30738 131 29916 3023 4950 29 1215 4897 1009 1178 31575 131 6979 5494 131 114 48209 40571 1215 49345 1215 7333 1640 1000 5334 1215 10885 35576 1215 1000 3603 8856 35122 671 111 2796 38023 846 131 48565 1009 83 1086 2526 12 34609 1577 3603 8856 21944 16 956 35 48404 114 41006 11474 49333 321 43 45056 36 11432 28696 856 30738 1215 12105 1215 1178 4897 1215 10799 35122 671 111 717 47697 131 3023 31575 5457 359 506 30738 46613 4897 4 1178 31575 131 856 30738 30529 44410 1215 46004 4897 1215 29631 1640 506 30738 4397 114 36 40571 1215 49345 1215 7333 1640 1000 5334 1215 10885 35576 1215 1000 3603 846 1723 35122 25522 114 36 330 48939 43 5494 5457 5375 1215 48658 1215 560 1215 1178 4897 1640 1178 31575 6 449 48939 4397 1493 5494 5457 5375 1215 12105 1215 560 1215 1178 4897 1640 1178 31575 6 41099 2951 4397 35524 1493 25522 5494 5457 3018 1215 4950 8738 1215 44273 179 49763 11474 6 359 11432 6 359 330 48939 6 359 1792 2951 6 3023 31575 6 321 6 111 134 4397 35524 48565 1009 96 403 9 2988 6 2458 70 982 25 45511 35 48404 114 36 4903 43 856 642 4897 1215 25153 49763 506 30738 46613 4897 4397 48565 1009 475 1178 11365 338 1875 15239 531 28 24397 7 4276 13 573 2188 4 48404 3023 31575 46613 118 32498 4 42385 11365 338 359 5214 475 1178 11365 338 1215 44565 1215 43776 131 3023 31575 46613 24419 4 45678 49847 359 5214 3023 46076 1215 43776 131 48565 1009 1216 15239 531 28 4276 4 48404 26012 8738 49763 1178 31575 46613 24419 4 1535 13539 6 321 6 2929 4397 671 5494 131 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_tokens: ['<s>', 'read', '_the', '_F', 'PU', '_registers', '_of', '_other', '_processes', '_on', '_the', '_system', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_ids: 0 12745 5 274 16821 34416 9 97 5588 15 5 467 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   idx: 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_tokens: ['<s>', 'Web', 'R', 'TC', 'Session', 'Description', 'Desc', 'ript', 'or', '_Mock', 'Web', 'R', 'TC', 'Pe', 'er', 'Connection', 'Handler', '::', 'local', 'Description', '()', '_{', '_return', '_m', '_', 'local', 'Description', ';', '_}', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_ids: 0 27521 500 6078 48171 41602 47066 36423 368 38800 27521 500 6078 23029 254 48467 49191 38304 18076 41602 43048 25522 671 475 1215 18076 41602 131 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_tokens: ['<s>', 'cause', '_a', '_denial', '_of', '_service', '_or', '_possibly', '_have', '_unspecified', '_other', '_impact', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_ids: 0 27037 10 14752 9 544 50 3544 33 20022 97 913 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   idx: 2\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_tokens: ['<s>', 'int', '_c', 'JSON', '_', 'Get', 'Array', 'Size', '(', '_c', 'JSON', '_*', 'array', '_)', '_{', '_c', 'JSON', '_*', 'c', '_=', '_array', '->', 'child', ';', '_int', '_i', '_=', '_0', ';', '_while', '_(', '_c', '_)', '_{', '_++', 'i', ';', '_c', '_=', '_c', '->', 'next', ';', '_}', '_return', '_i', ';', '_}', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_ids: 0 2544 740 49437 1215 14181 48222 45698 1640 740 49437 1009 30766 4839 25522 740 49437 1009 438 5457 8932 46613 14069 131 6979 939 5457 321 131 150 36 740 4839 25522 48793 118 131 740 5457 740 46613 25616 131 35524 671 939 131 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_tokens: ['<s>', 'over', 'flow', '_a', '_buffer', '_and', '_execute', '_arbitrary', '_code', '_on', '_the', '_system', '_or', '_cause', '_the', '_application', '_to', '_crash', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_ids: 0 2137 19322 10 21944 8 11189 23501 3260 15 5 467 50 1303 5 2502 7 2058 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   idx: 3\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_int', '_b', 'tr', 'fs', '_', 'ren', 'ame', '(', 'struct', '_in', 'ode', '_*', 'old', '_', 'dir', ',', '_struct', '_d', 'entry', '_*', 'old', '_', 'd', 'entry', ',', '_struct', '_in', 'ode', '_*', 'new', '_', 'dir', ',', '_struct', '_d', 'entry', '_*', 'new', '_', 'd', 'entry', ')', '_{', '_struct', '_b', 'tr', 'fs', '_', 'trans', '_', 'handle', '_*', 'trans', ';', '_struct', '_b', 'tr', 'fs', '_', 'root', '_*', 'root', '_=', '_B', 'TR', 'FS', '_', 'I', '(', 'old', '_', 'dir', ')', '->', 'root', ';', '_struct', '_b', 'tr', 'fs', '_', 'root', '_*', 'dest', '_=', '_B', 'TR', 'FS', '_', 'I', '(', 'new', '_', 'dir', ')', '->', 'root', ';', '_struct', '_in', 'ode', '_*', 'new', '_', 'in', 'ode', '_=', '_new', '_', 'd', 'entry', '->', 'd', '_', 'in', 'ode', ';', '_struct', '_in', 'ode', '_*', 'old', '_', 'in', 'ode', '_=', '_old', '_', 'd', 'entry', '->', 'd', '_', 'in', 'ode', ';', '_struct', '_times', 'pec', '_c', 'time', '_=', '_C', 'URRENT', '_', 'TIME', ';', '_u', '64', '_index', '_=', '_0', ';', '_u', '64', '_root', '_', 'object', 'id', ';', '_int', '_ret', ';', '_u', '64', '_old', '_', 'ino', '_=', '_b', 'tr', 'fs', '_', 'ino', '(', 'old', '_', 'in', 'ode', ');', '_if', '_(', 'b', 'tr', 'fs', '_', 'ino', '(', 'new', '_', 'dir', ')', '_==', '_B', 'TR', 'FS', '_', 'EMP', 'TY', '_', 'S', 'UB', 'VOL', '_', 'DIR', '_', 'OB', 'JECT', 'ID', ')', '_return', '_-', 'EP', 'ER', 'M', ';', '_/*', '_we', '_only', '_allow', '_rename', '_sub', 'volume', '_link', '_between', '_sub', 'vol', 'umes', '_*/', '_if', '_(', 'old', '_', 'ino', '_!=', '_B', 'TR', 'FS', '_', 'FIR', 'ST', '_', 'FREE', '_', 'OB', 'JECT', 'ID', '_&&', '_root', '_!=', '_dest', ')', '_return', '_-', 'EX', 'DEV', ';', '_if', '_(', 'old', '_', 'ino', '_==', '_B', 'TR', 'FS', '_', 'EMP', 'TY', '_', 'S', 'UB', 'VOL', '_', 'DIR', '_', 'OB', 'JECT', 'ID', '_||', '_(', 'new', '_', 'in', 'ode', '_&&', '_b', 'tr', 'fs', '_', 'ino', '(', 'new', '_', 'in', 'ode', ')', '_==', '_B', 'TR', 'FS', '_', 'FIR', 'ST', '_', 'FREE', '_', 'OB', 'JECT', 'ID', '))', '_return', '_-', 'EN', 'OT', 'EMP', 'TY', ';', '_if', '_(', 'S', '_', 'IS', 'DIR', '(', 'old', '_', 'in', 'ode', '->', 'i', '_', 'mode', ')', '_&&', '_new', '_', 'in', 'ode', '_&&', '_new', '_', 'in', 'ode', '->', 'i', '_', 'size', '_>', '_B', 'TR', 'FS', '_', 'EMP', 'TY', '_', 'DIR', '_', 'SIZE', ')', '_return', '_-', 'EN', 'OT', 'EMP', 'TY', ';', '_/*', '_*', '_we', \"'re\", '_using', '_rename', '_to', '_replace', '_one', '_file', '_with', '_another', '.', '_*', '_and', '_the', '_replacement', '_file', '_is', '_large', '.', '_Start', '_IO', '_on', '_it', '_now', '_so', '_*', '_we', '_don', \"'t\", '_add', '_too', '_much', '_work', '_to', '_the', '_end', '_of', '_the', '_transaction', '_*/', '_if', '_(', 'new', '_', 'in', 'ode', '_&&', '_S', '_', 'IS', 'REG', '(', 'old', '_', 'in', 'ode', '->', 'i', '_', 'mode', ')', '_&&', '_new', '_', 'in', 'ode', '->', 'i', '_', 'size', '_&&', '_old', '_', 'in', 'ode', '->', 'i', '_', 'size', '_>', '_B', 'TR', 'FS', '_', 'ORD', 'ER', 'ED', '_', 'OPER', 'ATIONS', '_', 'FL', 'USH', '_', 'L', 'IM', 'IT', ')', '_file', 'map', '_', 'flush', '(', 'old', '_', 'in', 'ode', '->', 'i', '_', 'm', 'apping', ');', '_/*', '_close', '_the', '_r', 'acy', '_window', '_with', '_snapshot', '_create', '/', 'destroy', '_io', 'ctl', '_*/', '_if', '_(', 'old', '_', 'ino', '_==', '_B', 'TR', 'FS', '_', 'FIR', 'ST', '_', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_ids: 0 42653 6979 741 4328 17884 1215 2558 4344 1640 25384 11 4636 1009 279 1215 41292 6 29916 385 12595 1009 279 1215 417 12595 6 29916 11 4636 1009 4651 1215 41292 6 29916 385 12595 1009 4651 1215 417 12595 43 25522 29916 741 4328 17884 1215 9981 1215 26628 1009 9981 131 29916 741 4328 17884 1215 29059 1009 29059 5457 163 6997 7881 1215 100 1640 279 1215 41292 43 46613 29059 131 29916 741 4328 17884 1215 29059 1009 31549 5457 163 6997 7881 1215 100 1640 4651 1215 41292 43 46613 29059 131 29916 11 4636 1009 4651 1215 179 4636 5457 92 1215 417 12595 46613 417 1215 179 4636 131 29916 11 4636 1009 279 1215 179 4636 5457 793 1215 417 12595 46613 417 1215 179 4636 131 29916 498 26512 740 958 5457 230 42861 1215 39007 131 1717 4027 1965 5457 321 131 1717 4027 9749 1215 40412 808 131 6979 5494 131 1717 4027 793 1215 1696 5457 741 4328 17884 1215 1696 1640 279 1215 179 4636 4397 114 36 428 4328 17884 1215 1696 1640 4651 1215 41292 43 45994 163 6997 7881 1215 42257 6175 1215 104 12027 43302 1215 47992 1215 7912 33302 2688 43 671 111 9662 2076 448 131 48565 52 129 1157 38453 2849 33313 3104 227 2849 13728 19364 48404 114 36 279 1215 1696 49333 163 6997 7881 1215 39679 4014 1215 44789 1215 7912 33302 2688 48200 9749 49333 15357 43 671 111 6725 47233 131 114 36 279 1215 1696 45994 163 6997 7881 1215 42257 6175 1215 104 12027 43302 1215 47992 1215 7912 33302 2688 45056 36 4651 1215 179 4636 48200 741 4328 17884 1215 1696 1640 4651 1215 179 4636 43 45994 163 6997 7881 1215 39679 4014 1215 44789 1215 7912 33302 2688 35122 671 111 2796 3293 42257 6175 131 114 36 104 1215 1729 47992 1640 279 1215 179 4636 46613 118 1215 42253 43 48200 92 1215 179 4636 48200 92 1215 179 4636 46613 118 1215 10799 8061 163 6997 7881 1215 42257 6175 1215 47992 1215 49340 43 671 111 2796 3293 42257 6175 131 48565 1009 52 214 634 38453 7 3190 65 2870 19 277 4 1009 8 5 5010 2870 16 739 4 2776 38266 15 24 122 98 1009 52 218 75 1606 350 203 173 7 5 253 9 5 2676 48404 114 36 4651 1215 179 4636 48200 208 1215 1729 32239 1640 279 1215 179 4636 46613 118 1215 42253 43 48200 92 1215 179 4636 46613 118 1215 10799 48200 793 1215 179 4636 46613 118 1215 10799 8061 163 6997 7881 1215 11200 2076 1691 1215 35918 14939 1215 7613 29397 1215 574 3755 2068 43 2870 32557 1215 47742 1640 279 1215 179 4636 46613 118 1215 119 12040 4397 48565 593 5 910 5073 2931 19 24512 1045 73 42742 46155 47074 48404 114 36 279 1215 1696 45994 163 6997 7881 1215 39679 4014 1215 2\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_tokens: ['<s>', 'cross', '_privilege', '_boundaries', '_and', '_bypass', '_this', '_security', '_mechanism', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_ids: 0 15329 9951 10156 8 15037 42 573 9562 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   idx: 4\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_tokens: ['<s>', 'void', '_Thread', 'able', 'Bl', 'ob', 'Reg', 'istry', '::', 'final', 'ize', 'Stream', '(', 'const', '_K', 'URL', '&', '_url', ')', '_{', '_if', '_(', 'is', 'Main', 'Thread', '())', '_{', '_blob', 'Reg', 'istry', '().', 'final', 'ize', 'Stream', '(', 'url', ');', '_}', '_else', '_{', '_Own', 'Ptr', '<', 'Bl', 'ob', 'Reg', 'istry', 'Context', '>', '_context', '_=', '_adopt', 'Ptr', '(', 'new', '_Bl', 'ob', 'Reg', 'istry', 'Context', '(', 'url', '));', '_call', 'On', 'Main', 'Thread', '(&', 'final', 'ize', 'Stream', 'Task', ',', '_context', '.', 'le', 'ak', 'Ptr', '());', '_}', '_}', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_ids: 0 47908 6032 868 12654 2413 23007 20217 38304 6156 2072 36757 1640 20836 229 42703 947 46471 43 25522 114 36 354 31359 47563 49338 25522 45411 23007 20217 49123 6156 2072 36757 1640 6423 4397 35524 1493 25522 19981 49835 41552 12654 2413 23007 20217 48522 15698 5377 5457 7581 49835 1640 4651 2091 2413 23007 20217 48522 1640 6423 48749 486 4148 31359 47563 49763 6156 2072 36757 47744 6 5377 4 459 677 49835 49291 35524 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_tokens: ['<s>', 'cause', '_a', '_denial', '_of', '_service', '_or', '_possibly', '_have', '_unspecified', '_other', '_impact', '</s>']\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_ids: 0 27037 10 14752 9 544 50 3544 33 20022 97 913 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 16:19:29 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "07/20/2023 16:19:43 - INFO - __main__ -   ***** Running training *****\n",
      "07/20/2023 16:19:43 - INFO - __main__ -     Num examples = 7032\n",
      "07/20/2023 16:19:43 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:19:43 - INFO - __main__ -     Num epoch = 100\n",
      "  0%|                                                   | 0/176 [00:00<?, ?it/s]/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 0 loss 7.4124: 100%|████████████████████| 176/176 [02:05<00:00,  1.41it/s]\n",
      "07/20/2023 16:21:49 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:21:49 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:21:49 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:21:54 - INFO - __main__ -     eval_ppl = 42.64661\n",
      "07/20/2023 16:21:54 - INFO - __main__ -     global_step = 177\n",
      "07/20/2023 16:21:54 - INFO - __main__ -     train_loss = 7.4124\n",
      "07/20/2023 16:21:54 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:21:55 - INFO - __main__ -     Best ppl:42.64661\n",
      "07/20/2023 16:21:55 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:22:31 - INFO - __main__ -     bleu-4 = 12.43 \n",
      "07/20/2023 16:22:31 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:22:31 - INFO - __main__ -     Best bleu:12.43\n",
      "07/20/2023 16:22:31 - INFO - __main__ -     ********************\n",
      "epoch 1 loss 2.5148: 100%|████████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 16:24:35 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:24:35 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:24:35 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:24:40 - INFO - __main__ -     eval_ppl = 6.20393\n",
      "07/20/2023 16:24:40 - INFO - __main__ -     global_step = 353\n",
      "07/20/2023 16:24:40 - INFO - __main__ -     train_loss = 2.5148\n",
      "07/20/2023 16:24:40 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:24:42 - INFO - __main__ -     Best ppl:6.20393\n",
      "07/20/2023 16:24:42 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:25:27 - INFO - __main__ -     bleu-4 = 24.33 \n",
      "07/20/2023 16:25:27 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:25:27 - INFO - __main__ -     Best bleu:24.33\n",
      "07/20/2023 16:25:27 - INFO - __main__ -     ********************\n",
      "epoch 2 loss 1.6092: 100%|████████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 16:27:33 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:27:33 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:27:33 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:27:38 - INFO - __main__ -     eval_ppl = 4.13157\n",
      "07/20/2023 16:27:38 - INFO - __main__ -     global_step = 529\n",
      "07/20/2023 16:27:38 - INFO - __main__ -     train_loss = 1.6092\n",
      "07/20/2023 16:27:38 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:27:40 - INFO - __main__ -     Best ppl:4.13157\n",
      "07/20/2023 16:27:40 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:28:33 - INFO - __main__ -     bleu-4 = 26.29 \n",
      "07/20/2023 16:28:33 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:28:33 - INFO - __main__ -     Best bleu:26.29\n",
      "07/20/2023 16:28:33 - INFO - __main__ -     ********************\n",
      "epoch 3 loss 1.2701: 100%|████████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 16:30:38 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:30:38 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:30:38 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:30:44 - INFO - __main__ -     eval_ppl = 3.12488\n",
      "07/20/2023 16:30:44 - INFO - __main__ -     global_step = 705\n",
      "07/20/2023 16:30:44 - INFO - __main__ -     train_loss = 1.2701\n",
      "07/20/2023 16:30:44 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:30:46 - INFO - __main__ -     Best ppl:3.12488\n",
      "07/20/2023 16:30:46 - INFO - __main__ -     ********************\n",
      "epoch 4 loss 1.0353: 100%|████████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 16:33:40 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:33:40 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:33:40 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:33:45 - INFO - __main__ -     eval_ppl = 2.60699\n",
      "07/20/2023 16:33:45 - INFO - __main__ -     global_step = 881\n",
      "07/20/2023 16:33:45 - INFO - __main__ -     train_loss = 1.0353\n",
      "07/20/2023 16:33:45 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:33:47 - INFO - __main__ -     Best ppl:2.60699\n",
      "07/20/2023 16:33:47 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:34:43 - INFO - __main__ -     bleu-4 = 36.11 \n",
      "07/20/2023 16:34:43 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:34:43 - INFO - __main__ -     Best bleu:36.11\n",
      "07/20/2023 16:34:43 - INFO - __main__ -     ********************\n",
      "epoch 5 loss 0.8569: 100%|████████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 16:36:48 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:36:48 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:36:48 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:36:53 - INFO - __main__ -     eval_ppl = 2.25707\n",
      "07/20/2023 16:36:53 - INFO - __main__ -     global_step = 1057\n",
      "07/20/2023 16:36:53 - INFO - __main__ -     train_loss = 0.8569\n",
      "07/20/2023 16:36:53 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:36:55 - INFO - __main__ -     Best ppl:2.25707\n",
      "07/20/2023 16:36:55 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:37:51 - INFO - __main__ -     bleu-4 = 38.81 \n",
      "07/20/2023 16:37:51 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:37:51 - INFO - __main__ -     Best bleu:38.81\n",
      "07/20/2023 16:37:51 - INFO - __main__ -     ********************\n",
      "epoch 6 loss 0.6944: 100%|████████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 16:39:56 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:39:56 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:39:56 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:40:01 - INFO - __main__ -     eval_ppl = 1.98326\n",
      "07/20/2023 16:40:01 - INFO - __main__ -     global_step = 1233\n",
      "07/20/2023 16:40:01 - INFO - __main__ -     train_loss = 0.6944\n",
      "07/20/2023 16:40:01 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:40:04 - INFO - __main__ -     Best ppl:1.98326\n",
      "07/20/2023 16:40:04 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:40:56 - INFO - __main__ -     bleu-4 = 46.15 \n",
      "07/20/2023 16:40:56 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:40:56 - INFO - __main__ -     Best bleu:46.15\n",
      "07/20/2023 16:40:56 - INFO - __main__ -     ********************\n",
      "epoch 7 loss 0.5544: 100%|████████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 16:43:01 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:43:01 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:43:01 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:43:06 - INFO - __main__ -     eval_ppl = 1.83386\n",
      "07/20/2023 16:43:06 - INFO - __main__ -     global_step = 1409\n",
      "07/20/2023 16:43:06 - INFO - __main__ -     train_loss = 0.5544\n",
      "07/20/2023 16:43:06 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:43:09 - INFO - __main__ -     Best ppl:1.83386\n",
      "07/20/2023 16:43:09 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:43:56 - INFO - __main__ -     bleu-4 = 51.66 \n",
      "07/20/2023 16:43:56 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:43:56 - INFO - __main__ -     Best bleu:51.66\n",
      "07/20/2023 16:43:56 - INFO - __main__ -     ********************\n",
      "epoch 8 loss 0.4383: 100%|████████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 16:46:01 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:46:01 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:46:01 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:46:07 - INFO - __main__ -     eval_ppl = 1.73121\n",
      "07/20/2023 16:46:07 - INFO - __main__ -     global_step = 1585\n",
      "07/20/2023 16:46:07 - INFO - __main__ -     train_loss = 0.4383\n",
      "07/20/2023 16:46:07 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:46:09 - INFO - __main__ -     Best ppl:1.73121\n",
      "07/20/2023 16:46:09 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:47:00 - INFO - __main__ -     bleu-4 = 55.49 \n",
      "07/20/2023 16:47:00 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:47:00 - INFO - __main__ -     Best bleu:55.49\n",
      "07/20/2023 16:47:00 - INFO - __main__ -     ********************\n",
      "epoch 9 loss 0.337: 100%|█████████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 16:49:05 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:49:05 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:49:05 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:49:10 - INFO - __main__ -     eval_ppl = 1.68285\n",
      "07/20/2023 16:49:10 - INFO - __main__ -     global_step = 1761\n",
      "07/20/2023 16:49:10 - INFO - __main__ -     train_loss = 0.337\n",
      "07/20/2023 16:49:10 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:49:12 - INFO - __main__ -     Best ppl:1.68285\n",
      "07/20/2023 16:49:12 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:50:02 - INFO - __main__ -     bleu-4 = 57.05 \n",
      "07/20/2023 16:50:02 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:50:02 - INFO - __main__ -     Best bleu:57.05\n",
      "07/20/2023 16:50:02 - INFO - __main__ -     ********************\n",
      "epoch 10 loss 0.2583: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 16:52:06 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:52:06 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:52:06 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:52:12 - INFO - __main__ -     eval_ppl = 1.6411\n",
      "07/20/2023 16:52:12 - INFO - __main__ -     global_step = 1937\n",
      "07/20/2023 16:52:12 - INFO - __main__ -     train_loss = 0.2583\n",
      "07/20/2023 16:52:12 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:52:14 - INFO - __main__ -     Best ppl:1.6411\n",
      "07/20/2023 16:52:14 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:53:03 - INFO - __main__ -     bleu-4 = 58.53 \n",
      "07/20/2023 16:53:03 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:53:03 - INFO - __main__ -     Best bleu:58.53\n",
      "07/20/2023 16:53:03 - INFO - __main__ -     ********************\n",
      "epoch 11 loss 0.1852: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 16:55:08 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 16:55:08 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 16:55:08 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 16:55:13 - INFO - __main__ -     eval_ppl = 1.61424\n",
      "07/20/2023 16:55:13 - INFO - __main__ -     global_step = 2113\n",
      "07/20/2023 16:55:13 - INFO - __main__ -     train_loss = 0.1852\n",
      "07/20/2023 16:55:13 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:55:15 - INFO - __main__ -     Best ppl:1.61424\n",
      "07/20/2023 16:55:15 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 16:56:06 - INFO - __main__ -     bleu-4 = 61.0 \n",
      "07/20/2023 16:56:06 - INFO - __main__ -     ********************\n",
      "07/20/2023 16:56:06 - INFO - __main__ -     Best bleu:61.0\n",
      "07/20/2023 16:56:06 - INFO - __main__ -     ********************\n",
      "epoch 12 loss 0.1327:  64%|████████████       | 112/176 [01:17<00:44,  1.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 782\n",
      "07/20/2023 17:02:10 - INFO - __main__ -     bleu-4 = 62.94 \n",
      "07/20/2023 17:02:10 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:02:10 - INFO - __main__ -     Best bleu:62.94\n",
      "07/20/2023 17:02:10 - INFO - __main__ -     ********************\n",
      "epoch 14 loss 0.0803: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:04:16 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:04:16 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:04:16 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:04:21 - INFO - __main__ -     eval_ppl = 1.60257\n",
      "07/20/2023 17:04:21 - INFO - __main__ -     global_step = 2641\n",
      "07/20/2023 17:04:21 - INFO - __main__ -     train_loss = 0.0803\n",
      "07/20/2023 17:04:21 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:04:23 - INFO - __main__ -     Best ppl:1.60257\n",
      "07/20/2023 17:04:23 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:05:15 - INFO - __main__ -     bleu-4 = 63.49 \n",
      "07/20/2023 17:05:15 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:05:15 - INFO - __main__ -     Best bleu:63.49\n",
      "07/20/2023 17:05:15 - INFO - __main__ -     ********************\n",
      "epoch 15 loss 0.0605: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 17:07:20 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:07:20 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:07:20 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:07:25 - INFO - __main__ -     eval_ppl = 1.58812\n",
      "07/20/2023 17:07:25 - INFO - __main__ -     global_step = 2817\n",
      "07/20/2023 17:07:25 - INFO - __main__ -     train_loss = 0.0605\n",
      "07/20/2023 17:07:25 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:07:27 - INFO - __main__ -     Best ppl:1.58812\n",
      "07/20/2023 17:07:27 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:08:18 - INFO - __main__ -     bleu-4 = 63.02 \n",
      "07/20/2023 17:08:18 - INFO - __main__ -     ********************\n",
      "epoch 16 loss 0.0499: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:10:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:10:21 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:10:21 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:10:27 - INFO - __main__ -     eval_ppl = 1.57905\n",
      "07/20/2023 17:10:27 - INFO - __main__ -     global_step = 2993\n",
      "07/20/2023 17:10:27 - INFO - __main__ -     train_loss = 0.0499\n",
      "07/20/2023 17:10:27 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:10:29 - INFO - __main__ -     Best ppl:1.57905\n",
      "07/20/2023 17:10:29 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:11:22 - INFO - __main__ -     bleu-4 = 62.82 \n",
      "07/20/2023 17:11:22 - INFO - __main__ -     ********************\n",
      "epoch 17 loss 0.0435: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:13:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:13:25 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:13:25 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:13:30 - INFO - __main__ -     eval_ppl = 1.58581\n",
      "07/20/2023 17:13:30 - INFO - __main__ -     global_step = 3169\n",
      "07/20/2023 17:13:30 - INFO - __main__ -     train_loss = 0.0435\n",
      "07/20/2023 17:13:30 - INFO - __main__ -     ********************\n",
      "epoch 18 loss 0.0388: 100%|███████████████████| 176/176 [02:03<00:00,  1.42it/s]\n",
      "07/20/2023 17:16:27 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:16:27 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:16:27 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:16:32 - INFO - __main__ -     eval_ppl = 1.58774\n",
      "07/20/2023 17:16:32 - INFO - __main__ -     global_step = 3345\n",
      "07/20/2023 17:16:32 - INFO - __main__ -     train_loss = 0.0388\n",
      "07/20/2023 17:16:32 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:17:22 - INFO - __main__ -     bleu-4 = 62.56 \n",
      "07/20/2023 17:17:22 - INFO - __main__ -     ********************\n",
      "epoch 19 loss 0.0313: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:19:25 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:19:25 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:19:25 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:19:30 - INFO - __main__ -     eval_ppl = 1.62826\n",
      "07/20/2023 17:19:30 - INFO - __main__ -     global_step = 3521\n",
      "07/20/2023 17:19:30 - INFO - __main__ -     train_loss = 0.0313\n",
      "07/20/2023 17:19:30 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:20:24 - INFO - __main__ -     bleu-4 = 63.93 \n",
      "07/20/2023 17:20:24 - INFO - __main__ -     ********************\n",
      "epoch 20 loss 0.0285: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:22:27 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:22:27 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:22:27 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:22:32 - INFO - __main__ -     eval_ppl = 1.60837\n",
      "07/20/2023 17:22:32 - INFO - __main__ -     global_step = 3697\n",
      "07/20/2023 17:22:32 - INFO - __main__ -     train_loss = 0.0285\n",
      "07/20/2023 17:22:32 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:23:24 - INFO - __main__ -     bleu-4 = 64.78 \n",
      "07/20/2023 17:23:24 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:23:24 - INFO - __main__ -     Best bleu:64.78\n",
      "07/20/2023 17:23:24 - INFO - __main__ -     ********************\n",
      "epoch 21 loss 0.0257: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 17:25:29 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:25:29 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:25:29 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:25:34 - INFO - __main__ -     eval_ppl = 1.63365\n",
      "07/20/2023 17:25:34 - INFO - __main__ -     global_step = 3873\n",
      "07/20/2023 17:25:34 - INFO - __main__ -     train_loss = 0.0257\n",
      "07/20/2023 17:25:34 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:26:27 - INFO - __main__ -     bleu-4 = 64.86 \n",
      "07/20/2023 17:26:27 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:26:27 - INFO - __main__ -     Best bleu:64.86\n",
      "07/20/2023 17:26:27 - INFO - __main__ -     ********************\n",
      "epoch 22 loss 0.0234: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 17:28:32 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:28:32 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:28:32 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:28:37 - INFO - __main__ -     eval_ppl = 1.62222\n",
      "07/20/2023 17:28:37 - INFO - __main__ -     global_step = 4049\n",
      "07/20/2023 17:28:37 - INFO - __main__ -     train_loss = 0.0234\n",
      "07/20/2023 17:28:37 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:29:28 - INFO - __main__ -     bleu-4 = 64.97 \n",
      "07/20/2023 17:29:28 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:29:28 - INFO - __main__ -     Best bleu:64.97\n",
      "07/20/2023 17:29:28 - INFO - __main__ -     ********************\n",
      "epoch 23 loss 0.0221: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:31:32 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:31:32 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:31:32 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:31:37 - INFO - __main__ -     eval_ppl = 1.64337\n",
      "07/20/2023 17:31:37 - INFO - __main__ -     global_step = 4225\n",
      "07/20/2023 17:31:37 - INFO - __main__ -     train_loss = 0.0221\n",
      "07/20/2023 17:31:37 - INFO - __main__ -     ********************\n",
      "epoch 24 loss 0.0193: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:34:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:34:31 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:34:31 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:34:36 - INFO - __main__ -     eval_ppl = 1.62816\n",
      "07/20/2023 17:34:36 - INFO - __main__ -     global_step = 4401\n",
      "07/20/2023 17:34:36 - INFO - __main__ -     train_loss = 0.0193\n",
      "07/20/2023 17:34:36 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:35:26 - INFO - __main__ -     bleu-4 = 62.77 \n",
      "07/20/2023 17:35:26 - INFO - __main__ -     ********************\n",
      "epoch 25 loss 0.0193: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:37:30 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:37:30 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:37:30 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:37:35 - INFO - __main__ -     eval_ppl = 1.65314\n",
      "07/20/2023 17:37:35 - INFO - __main__ -     global_step = 4577\n",
      "07/20/2023 17:37:35 - INFO - __main__ -     train_loss = 0.0193\n",
      "07/20/2023 17:37:35 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:38:25 - INFO - __main__ -     bleu-4 = 63.17 \n",
      "07/20/2023 17:38:25 - INFO - __main__ -     ********************\n",
      "epoch 26 loss 0.0183: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:40:27 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:40:27 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:40:27 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:40:32 - INFO - __main__ -     eval_ppl = 1.65265\n",
      "07/20/2023 17:40:32 - INFO - __main__ -     global_step = 4753\n",
      "07/20/2023 17:40:32 - INFO - __main__ -     train_loss = 0.0183\n",
      "07/20/2023 17:40:32 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:41:25 - INFO - __main__ -     bleu-4 = 64.21 \n",
      "07/20/2023 17:41:25 - INFO - __main__ -     ********************\n",
      "epoch 27 loss 0.0178: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:43:27 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:43:27 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:43:27 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:43:32 - INFO - __main__ -     eval_ppl = 1.65008\n",
      "07/20/2023 17:43:32 - INFO - __main__ -     global_step = 4929\n",
      "07/20/2023 17:43:32 - INFO - __main__ -     train_loss = 0.0178\n",
      "07/20/2023 17:43:32 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:44:26 - INFO - __main__ -     bleu-4 = 65.79 \n",
      "07/20/2023 17:44:26 - INFO - __main__ -     ********************\n",
      "07/20/2023 17:44:26 - INFO - __main__ -     Best bleu:65.79\n",
      "07/20/2023 17:44:26 - INFO - __main__ -     ********************\n",
      "epoch 28 loss 0.0191: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:46:30 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:46:30 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:46:30 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:46:35 - INFO - __main__ -     eval_ppl = 1.67837\n",
      "07/20/2023 17:46:35 - INFO - __main__ -     global_step = 5105\n",
      "07/20/2023 17:46:35 - INFO - __main__ -     train_loss = 0.0191\n",
      "07/20/2023 17:46:35 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:47:28 - INFO - __main__ -     bleu-4 = 63.74 \n",
      "07/20/2023 17:47:28 - INFO - __main__ -     ********************\n",
      "epoch 29 loss 0.0198: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 17:49:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:49:31 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:49:31 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:49:36 - INFO - __main__ -     eval_ppl = 1.65757\n",
      "07/20/2023 17:49:36 - INFO - __main__ -     global_step = 5281\n",
      "07/20/2023 17:49:36 - INFO - __main__ -     train_loss = 0.0198\n",
      "07/20/2023 17:49:36 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:50:29 - INFO - __main__ -     bleu-4 = 64.61 \n",
      "07/20/2023 17:50:29 - INFO - __main__ -     ********************\n",
      "epoch 30 loss 0.0178: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:52:31 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:52:31 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:52:31 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:52:37 - INFO - __main__ -     eval_ppl = 1.67489\n",
      "07/20/2023 17:52:37 - INFO - __main__ -     global_step = 5457\n",
      "07/20/2023 17:52:37 - INFO - __main__ -     train_loss = 0.0178\n",
      "07/20/2023 17:52:37 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:53:30 - INFO - __main__ -     bleu-4 = 64.77 \n",
      "07/20/2023 17:53:30 - INFO - __main__ -     ********************\n",
      "epoch 31 loss 0.0187: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 17:55:32 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:55:32 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:55:32 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:55:38 - INFO - __main__ -     eval_ppl = 1.67763\n",
      "07/20/2023 17:55:38 - INFO - __main__ -     global_step = 5633\n",
      "07/20/2023 17:55:38 - INFO - __main__ -     train_loss = 0.0187\n",
      "07/20/2023 17:55:38 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:56:26 - INFO - __main__ -     bleu-4 = 62.4 \n",
      "07/20/2023 17:56:26 - INFO - __main__ -     ********************\n",
      "epoch 32 loss 0.0189: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 17:58:29 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 17:58:29 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 17:58:29 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 17:58:34 - INFO - __main__ -     eval_ppl = 1.68074\n",
      "07/20/2023 17:58:34 - INFO - __main__ -     global_step = 5809\n",
      "07/20/2023 17:58:34 - INFO - __main__ -     train_loss = 0.0189\n",
      "07/20/2023 17:58:34 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 17:59:26 - INFO - __main__ -     bleu-4 = 65.37 \n",
      "07/20/2023 17:59:26 - INFO - __main__ -     ********************\n",
      "epoch 33 loss 0.0133:  25%|█████               | 44/176 [00:30<01:31,  1.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 loss 0.0098: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 18:19:23 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:19:23 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:19:23 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:19:28 - INFO - __main__ -     eval_ppl = 1.68114\n",
      "07/20/2023 18:19:28 - INFO - __main__ -     global_step = 7041\n",
      "07/20/2023 18:19:28 - INFO - __main__ -     train_loss = 0.0098\n",
      "07/20/2023 18:19:28 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:20:17 - INFO - __main__ -     bleu-4 = 64.84 \n",
      "07/20/2023 18:20:17 - INFO - __main__ -     ********************\n",
      "epoch 41 loss 0.0087: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 18:25:24 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:25:24 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:25:24 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:25:29 - INFO - __main__ -     eval_ppl = 1.69763\n",
      "07/20/2023 18:25:29 - INFO - __main__ -     global_step = 7393\n",
      "07/20/2023 18:25:29 - INFO - __main__ -     train_loss = 0.0087\n",
      "07/20/2023 18:25:29 - INFO - __main__ -     ********************\n",
      "epoch 42 loss 0.0098: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 18:28:24 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:28:24 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:28:24 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:28:29 - INFO - __main__ -     eval_ppl = 1.7451\n",
      "07/20/2023 18:28:29 - INFO - __main__ -     global_step = 7569\n",
      "07/20/2023 18:28:29 - INFO - __main__ -     train_loss = 0.0098\n",
      "07/20/2023 18:28:29 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:29:21 - INFO - __main__ -     bleu-4 = 63.56 \n",
      "07/20/2023 18:29:21 - INFO - __main__ -     ********************\n",
      "epoch 43 loss 0.0101: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 18:31:23 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:31:23 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:31:23 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:31:29 - INFO - __main__ -     eval_ppl = 1.73412\n",
      "07/20/2023 18:31:29 - INFO - __main__ -     global_step = 7745\n",
      "07/20/2023 18:31:29 - INFO - __main__ -     train_loss = 0.0101\n",
      "07/20/2023 18:31:29 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:32:19 - INFO - __main__ -     bleu-4 = 64.61 \n",
      "07/20/2023 18:32:19 - INFO - __main__ -     ********************\n",
      "epoch 44 loss 0.0091: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 18:34:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:34:21 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:34:21 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:34:27 - INFO - __main__ -     eval_ppl = 1.6883\n",
      "07/20/2023 18:34:27 - INFO - __main__ -     global_step = 7921\n",
      "07/20/2023 18:34:27 - INFO - __main__ -     train_loss = 0.0091\n",
      "07/20/2023 18:34:27 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:35:17 - INFO - __main__ -     bleu-4 = 65.98 \n",
      "07/20/2023 18:35:17 - INFO - __main__ -     ********************\n",
      "07/20/2023 18:35:17 - INFO - __main__ -     Best bleu:65.98\n",
      "07/20/2023 18:35:17 - INFO - __main__ -     ********************\n",
      "epoch 45 loss 0.0098: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 18:37:22 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:37:22 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:37:22 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:37:27 - INFO - __main__ -     eval_ppl = 1.74\n",
      "07/20/2023 18:37:27 - INFO - __main__ -     global_step = 8097\n",
      "07/20/2023 18:37:27 - INFO - __main__ -     train_loss = 0.0098\n",
      "07/20/2023 18:37:27 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:38:19 - INFO - __main__ -     bleu-4 = 65.61 \n",
      "07/20/2023 18:38:19 - INFO - __main__ -     ********************\n",
      "epoch 46 loss 0.0114: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 18:40:22 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:40:22 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:40:22 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:40:27 - INFO - __main__ -     eval_ppl = 1.71189\n",
      "07/20/2023 18:40:27 - INFO - __main__ -     global_step = 8273\n",
      "07/20/2023 18:40:27 - INFO - __main__ -     train_loss = 0.0114\n",
      "07/20/2023 18:40:27 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:41:18 - INFO - __main__ -     bleu-4 = 64.86 \n",
      "07/20/2023 18:41:18 - INFO - __main__ -     ********************\n",
      "epoch 47 loss 0.013: 100%|████████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 18:43:21 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:43:21 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:43:21 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:43:26 - INFO - __main__ -     eval_ppl = 1.70059\n",
      "07/20/2023 18:43:26 - INFO - __main__ -     global_step = 8449\n",
      "07/20/2023 18:43:26 - INFO - __main__ -     train_loss = 0.013\n",
      "07/20/2023 18:43:26 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:44:16 - INFO - __main__ -     bleu-4 = 65.56 \n",
      "07/20/2023 18:44:16 - INFO - __main__ -     ********************\n",
      "epoch 48 loss 0.0092: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 18:46:19 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:46:19 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:46:19 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:46:24 - INFO - __main__ -     eval_ppl = 1.70615\n",
      "07/20/2023 18:46:24 - INFO - __main__ -     global_step = 8625\n",
      "07/20/2023 18:46:24 - INFO - __main__ -     train_loss = 0.0092\n",
      "07/20/2023 18:46:24 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:47:12 - INFO - __main__ -     bleu-4 = 64.97 \n",
      "07/20/2023 18:47:12 - INFO - __main__ -     ********************\n",
      "epoch 49 loss 0.0077: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 18:49:15 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 18:49:15 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 18:49:15 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 18:49:21 - INFO - __main__ -     eval_ppl = 1.69984\n",
      "07/20/2023 18:49:21 - INFO - __main__ -     global_step = 8801\n",
      "07/20/2023 18:49:21 - INFO - __main__ -     train_loss = 0.0077\n",
      "07/20/2023 18:49:21 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 18:50:09 - INFO - __main__ -     bleu-4 = 66.75 \n",
      "07/20/2023 18:50:09 - INFO - __main__ -     ********************\n",
      "07/20/2023 18:50:09 - INFO - __main__ -     Best bleu:66.75\n",
      "07/20/2023 18:50:09 - INFO - __main__ -     ********************\n",
      "epoch 50 loss 0.0068:  88%|████████████████▋  | 154/176 [01:47<00:15,  1.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78 loss 0.0039: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 20:16:04 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:16:04 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:16:04 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:16:09 - INFO - __main__ -     eval_ppl = 1.78331\n",
      "07/20/2023 20:16:09 - INFO - __main__ -     global_step = 13905\n",
      "07/20/2023 20:16:09 - INFO - __main__ -     train_loss = 0.0039\n",
      "07/20/2023 20:16:09 - INFO - __main__ -     ********************\n",
      "epoch 79 loss 0.004: 100%|████████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:19:01 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:19:01 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:19:01 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:19:06 - INFO - __main__ -     eval_ppl = 1.79603\n",
      "07/20/2023 20:19:06 - INFO - __main__ -     global_step = 14081\n",
      "07/20/2023 20:19:06 - INFO - __main__ -     train_loss = 0.004\n",
      "07/20/2023 20:19:06 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:19:59 - INFO - __main__ -     bleu-4 = 65.5 \n",
      "07/20/2023 20:19:59 - INFO - __main__ -     ********************\n",
      "epoch 80 loss 0.0041: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:22:02 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:22:02 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:22:02 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:22:07 - INFO - __main__ -     eval_ppl = 1.74829\n",
      "07/20/2023 20:22:07 - INFO - __main__ -     global_step = 14257\n",
      "07/20/2023 20:22:07 - INFO - __main__ -     train_loss = 0.0041\n",
      "07/20/2023 20:22:07 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:22:57 - INFO - __main__ -     bleu-4 = 66.02 \n",
      "07/20/2023 20:22:57 - INFO - __main__ -     ********************\n",
      "epoch 81 loss 0.0029: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 20:25:00 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:25:00 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:25:00 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:25:05 - INFO - __main__ -     eval_ppl = 1.76627\n",
      "07/20/2023 20:25:05 - INFO - __main__ -     global_step = 14433\n",
      "07/20/2023 20:25:05 - INFO - __main__ -     train_loss = 0.0029\n",
      "07/20/2023 20:25:05 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:25:55 - INFO - __main__ -     bleu-4 = 66.47 \n",
      "07/20/2023 20:25:55 - INFO - __main__ -     ********************\n",
      "epoch 82 loss 0.0027: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 20:27:58 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:27:58 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:27:58 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:28:03 - INFO - __main__ -     eval_ppl = 1.74847\n",
      "07/20/2023 20:28:03 - INFO - __main__ -     global_step = 14609\n",
      "07/20/2023 20:28:03 - INFO - __main__ -     train_loss = 0.0027\n",
      "07/20/2023 20:28:03 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:28:53 - INFO - __main__ -     bleu-4 = 66.4 \n",
      "07/20/2023 20:28:53 - INFO - __main__ -     ********************\n",
      "epoch 83 loss 0.0024: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:30:56 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:30:56 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:30:56 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:31:01 - INFO - __main__ -     eval_ppl = 1.76357\n",
      "07/20/2023 20:31:01 - INFO - __main__ -     global_step = 14785\n",
      "07/20/2023 20:31:01 - INFO - __main__ -     train_loss = 0.0024\n",
      "07/20/2023 20:31:01 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:31:51 - INFO - __main__ -     bleu-4 = 66.15 \n",
      "07/20/2023 20:31:51 - INFO - __main__ -     ********************\n",
      "epoch 84 loss 0.0026: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 20:33:54 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:33:54 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:33:54 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:33:59 - INFO - __main__ -     eval_ppl = 1.74938\n",
      "07/20/2023 20:33:59 - INFO - __main__ -     global_step = 14961\n",
      "07/20/2023 20:33:59 - INFO - __main__ -     train_loss = 0.0026\n",
      "07/20/2023 20:33:59 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:34:50 - INFO - __main__ -     bleu-4 = 66.29 \n",
      "07/20/2023 20:34:50 - INFO - __main__ -     ********************\n",
      "epoch 85 loss 0.0025: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 20:36:53 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:36:53 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:36:53 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:36:58 - INFO - __main__ -     eval_ppl = 1.76329\n",
      "07/20/2023 20:36:58 - INFO - __main__ -     global_step = 15137\n",
      "07/20/2023 20:36:58 - INFO - __main__ -     train_loss = 0.0025\n",
      "07/20/2023 20:36:58 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:37:49 - INFO - __main__ -     bleu-4 = 66.59 \n",
      "07/20/2023 20:37:49 - INFO - __main__ -     ********************\n",
      "epoch 86 loss 0.0026:  18%|███▌                | 31/176 [00:21<01:41,  1.43it/s]Total: 782\n",
      "07/20/2023 20:40:47 - INFO - __main__ -     bleu-4 = 66.0 \n",
      "07/20/2023 20:40:47 - INFO - __main__ -     ********************\n",
      "epoch 87 loss 0.0022: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:42:50 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:42:50 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:42:50 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:42:55 - INFO - __main__ -     eval_ppl = 1.76988\n",
      "07/20/2023 20:42:55 - INFO - __main__ -     global_step = 15489\n",
      "07/20/2023 20:42:55 - INFO - __main__ -     train_loss = 0.0022\n",
      "07/20/2023 20:42:55 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:43:46 - INFO - __main__ -     bleu-4 = 66.26 \n",
      "07/20/2023 20:43:46 - INFO - __main__ -     ********************\n",
      "epoch 88 loss 0.0023: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:45:48 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:45:48 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:45:48 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:45:54 - INFO - __main__ -     eval_ppl = 1.76571\n",
      "07/20/2023 20:45:54 - INFO - __main__ -     global_step = 15665\n",
      "07/20/2023 20:45:54 - INFO - __main__ -     train_loss = 0.0023\n",
      "07/20/2023 20:45:54 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:46:44 - INFO - __main__ -     bleu-4 = 66.08 \n",
      "07/20/2023 20:46:44 - INFO - __main__ -     ********************\n",
      "epoch 89 loss 0.0024: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:48:47 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:48:47 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:48:47 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:48:52 - INFO - __main__ -     eval_ppl = 1.75437\n",
      "07/20/2023 20:48:52 - INFO - __main__ -     global_step = 15841\n",
      "07/20/2023 20:48:52 - INFO - __main__ -     train_loss = 0.0024\n",
      "07/20/2023 20:48:52 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:49:42 - INFO - __main__ -     bleu-4 = 66.43 \n",
      "07/20/2023 20:49:42 - INFO - __main__ -     ********************\n",
      "epoch 91 loss 0.0022: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:54:43 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:54:43 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:54:43 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:54:48 - INFO - __main__ -     eval_ppl = 1.77736\n",
      "07/20/2023 20:54:48 - INFO - __main__ -     global_step = 16193\n",
      "07/20/2023 20:54:48 - INFO - __main__ -     train_loss = 0.0022\n",
      "07/20/2023 20:54:48 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:55:39 - INFO - __main__ -     bleu-4 = 66.37 \n",
      "07/20/2023 20:55:39 - INFO - __main__ -     ********************\n",
      "epoch 92 loss 0.0021: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 20:57:42 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 20:57:42 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 20:57:42 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 20:57:47 - INFO - __main__ -     eval_ppl = 1.77612\n",
      "07/20/2023 20:57:47 - INFO - __main__ -     global_step = 16369\n",
      "07/20/2023 20:57:47 - INFO - __main__ -     train_loss = 0.0021\n",
      "07/20/2023 20:57:47 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 20:58:37 - INFO - __main__ -     bleu-4 = 66.6 \n",
      "07/20/2023 20:58:37 - INFO - __main__ -     ********************\n",
      "epoch 93 loss 0.0021: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 21:00:39 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 21:00:39 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 21:00:39 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 21:00:44 - INFO - __main__ -     eval_ppl = 1.77633\n",
      "07/20/2023 21:00:44 - INFO - __main__ -     global_step = 16545\n",
      "07/20/2023 21:00:44 - INFO - __main__ -     train_loss = 0.0021\n",
      "07/20/2023 21:00:44 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 21:01:34 - INFO - __main__ -     bleu-4 = 67.0 \n",
      "07/20/2023 21:01:34 - INFO - __main__ -     ********************\n",
      "epoch 94 loss 0.0019: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 21:03:37 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 21:03:37 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 21:03:37 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 21:03:42 - INFO - __main__ -     eval_ppl = 1.77944\n",
      "07/20/2023 21:03:42 - INFO - __main__ -     global_step = 16721\n",
      "07/20/2023 21:03:42 - INFO - __main__ -     train_loss = 0.0019\n",
      "07/20/2023 21:03:42 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 21:04:33 - INFO - __main__ -     bleu-4 = 66.89 \n",
      "07/20/2023 21:04:33 - INFO - __main__ -     ********************\n",
      "epoch 95 loss 0.0019: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 21:06:35 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 21:06:35 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 21:06:35 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 21:06:41 - INFO - __main__ -     eval_ppl = 1.78301\n",
      "07/20/2023 21:06:41 - INFO - __main__ -     global_step = 16897\n",
      "07/20/2023 21:06:41 - INFO - __main__ -     train_loss = 0.0019\n",
      "07/20/2023 21:06:41 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 21:07:30 - INFO - __main__ -     bleu-4 = 66.71 \n",
      "07/20/2023 21:07:30 - INFO - __main__ -     ********************\n",
      "epoch 96 loss 0.0019: 100%|███████████████████| 176/176 [02:03<00:00,  1.43it/s]\n",
      "07/20/2023 21:09:33 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 21:09:33 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 21:09:33 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 21:09:38 - INFO - __main__ -     eval_ppl = 1.78351\n",
      "07/20/2023 21:09:38 - INFO - __main__ -     global_step = 17073\n",
      "07/20/2023 21:09:38 - INFO - __main__ -     train_loss = 0.0019\n",
      "07/20/2023 21:09:38 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 21:10:28 - INFO - __main__ -     bleu-4 = 66.71 \n",
      "07/20/2023 21:10:28 - INFO - __main__ -     ********************\n",
      "epoch 97 loss 0.0018: 100%|███████████████████| 176/176 [02:02<00:00,  1.43it/s]\n",
      "07/20/2023 21:12:30 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 21:12:30 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 21:12:30 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 21:12:36 - INFO - __main__ -     eval_ppl = 1.78579\n",
      "07/20/2023 21:12:36 - INFO - __main__ -     global_step = 17249\n",
      "07/20/2023 21:12:36 - INFO - __main__ -     train_loss = 0.0018\n",
      "07/20/2023 21:12:36 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 21:13:26 - INFO - __main__ -     bleu-4 = 66.46 \n",
      "07/20/2023 21:13:26 - INFO - __main__ -     ********************\n",
      "epoch 98 loss 0.0018: 100%|███████████████████| 176/176 [02:02<00:00,  1.44it/s]\n",
      "07/20/2023 21:15:28 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "07/20/2023 21:15:28 - INFO - __main__ -     Num examples = 782\n",
      "07/20/2023 21:15:28 - INFO - __main__ -     Batch size = 40\n",
      "07/20/2023 21:15:33 - INFO - __main__ -     eval_ppl = 1.78719\n",
      "07/20/2023 21:15:33 - INFO - __main__ -     global_step = 17425\n",
      "07/20/2023 21:15:33 - INFO - __main__ -     train_loss = 0.0018\n",
      "07/20/2023 21:15:33 - INFO - __main__ -     ********************\n",
      "Total: 782\n",
      "07/20/2023 21:16:23 - INFO - __main__ -     bleu-4 = 66.76 \n",
      "07/20/2023 21:16:23 - INFO - __main__ -     ********************\n",
      "epoch 99 loss 0.0016:  71%|█████████████▍     | 125/176 [01:27<00:35,  1.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = args.lr\n",
    "batch_size = args.batch_size # change depending on the GPU Colab gives you\n",
    "beam_size = args.beam_size\n",
    "source_length = args.max_source_length\n",
    "target_length = args.max_target_length\n",
    "data_dir = 'tmp_data'\n",
    "output_dir = f'{args.save_dir}/{args.prefix}_{args.task}'\n",
    "train_file = f'{data_dir}/{args.task}/train.jsonl'\n",
    "dev_file = f'{data_dir}/{args.task}/valid.jsonl'\n",
    "epochs = args.epochs \n",
    "pretrained_model = args.model_name\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_lower_case \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path {pretrained_model} \\\n",
    "    --train_filename {train_file} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --train_batch_size {batch_size} \\\n",
    "    --eval_batch_size {batch_size} \\\n",
    "    --learning_rate {lr} \\\n",
    "    --num_train_epochs {epochs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/20/2023 22:52:44 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='tf_board/codebert_impact', load_model_path='tf_board/codebert_impact/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename='tmp_data/impact/valid.jsonl', test_filename='tmp_data/impact/test.jsonl', config_name='', tokenizer_name='', max_source_length=512, max_target_length=167, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/20/2023 22:52:44 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "07/20/2023 22:52:46 - INFO - __main__ -   reload model from tf_board/codebert_impact/checkpoint-best-bleu/pytorch_model.bin\n",
      "07/20/2023 22:52:47 - INFO - __main__ -   Test file: tmp_data/impact/valid.jsonl\n",
      "100%|███████████████████████████████████████████| 13/13 [00:49<00:00,  3.83s/it]\n",
      "Total: 782\n",
      "07/20/2023 22:53:39 - INFO - __main__ -     bleu-4 = 67.3 \n",
      "07/20/2023 22:53:39 - INFO - __main__ -     ********************\n",
      "07/20/2023 22:53:39 - INFO - __main__ -   Test file: tmp_data/impact/test.jsonl\n",
      "100%|███████████████████████████████████████████| 31/31 [02:03<00:00,  3.98s/it]\n",
      "Total: 1954\n",
      "07/20/2023 22:55:47 - INFO - __main__ -     bleu-4 = 65.82 \n",
      "07/20/2023 22:55:47 - INFO - __main__ -     ********************\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "dev_file= f'{data_dir}/{args.task}/valid.jsonl'\n",
    "test_file=f\"{data_dir}/{args.task}/test.jsonl\"\n",
    "test_model=f\"{output_dir}/checkpoint-best-bleu/pytorch_model.bin\" #checkpoint for test\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_test \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path microsoft/codebert-base \\\n",
    "    --load_model_path {test_model} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --test_filename {test_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --eval_batch_size {batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name, do_lower_case=args.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "config = RobertaConfig.from_pretrained(pretrained_model)\n",
    "encoder = RobertaModel.from_pretrained(pretrained_model, config = config)    \n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(encoder = encoder,decoder = decoder,config=config,\n",
    "                beam_size=beam_size,max_length=target_length,\n",
    "                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n",
    "model.load_state_dict(torch.load(Path(output_dir)/\"checkpoint-best-bleu/pytorch_model.bin\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static int cg_getattr(const char *path, struct stat *sb) {  struct timespec now;  struct fuse_context *fc = fuse_get_context();  char * cgdir = NULL;  char *fpath = NULL, *path1, *path2;  struct cgfs_files *k = NULL;  const char *cgroup;  const char *controller = NULL;  int ret = -ENOENT;    if (!fc)   return -EIO;   memset(sb, 0, sizeof(struct stat));   if (clock_gettime(CLOCK_REALTIME, &now) < 0)   return -EINVAL;   sb->st_uid = sb->st_gid = 0;  sb->st_atim = sb->st_mtim = sb->st_ctim = now;  sb->st_size = 0;   if (strcmp(path, \"/cgroup\") == 0) {   sb->st_mode = S_IFDIR | 00755;   sb->st_nlink = 2;   return 0;  }   controller = pick_controller_from_path(fc, path);  if (!controller)   return -EIO;  cgroup = find_cgroup_in_path(path);  if (!cgroup) {   /* this is just /cgroup/controller, return it as a dir */   sb->st_mode = S_IFDIR | 00755;   sb->st_nlink = 2;   return 0;  }   get_cgdir_and_path(cgroup, &cgdir, &fpath);   if (!fpath) {   path1 = \"/\";   path2 = cgdir;  } else {   path1 = cgdir;   path2 = fpath;  }   /* check that cgcopy is either a child cgroup of cgdir, or listed in its keys.   * Then check that caller's cgroup is under path if fpath is a child  * cgroup, or cgdir if fpath is a file */  if (is_child_cgroup(controller, path1, path2)) {  if (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {  /* this is just /cgroup/controller, return it as a dir */  sb->st_mode = S_IFDIR | 00555;    sb->st_nlink = 2;    ret = 0;    goto out;   }   if (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {    ret = -EACCES;    goto out;   }    sb->st_mode = S_IFDIR | 00755;   k = cgfs_get_key(controller, cgroup, \"tasks\");   if (!k) {    sb->st_uid = sb->st_gid = 0;   } else {    sb->st_uid = k->uid;    sb->st_gid = k->gid;   }   free_key(k);   sb->st_nlink = 2;   ret = 0;   goto out;  }   if ((k = cgfs_get_key(controller, path1, path2)) != NULL) {   sb->st_mode = S_IFREG | k->mode;   sb->st_nlink = 1;   sb->st_uid = k->uid;   sb->st_gid = k->gid;   sb->st_size = 0;   free_key(k);   if (!caller_is_in_ancestor(fc->pid, controller, path1, NULL)) {    ret = -ENOENT;    goto out;   }   if (!fc_may_access(fc, controller, path1, path2, O_RDONLY)) {    ret = -EACCES;    goto out;   }    ret = 0;  }  out:  free(cgdir);  return ret; } \n",
      "Original Comment: a denial of service condition\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "TEXT_TO_SUMMARIZE = df_test.func_before.values[idx]\n",
    "print('Code:', TEXT_TO_SUMMARIZE)\n",
    "print('Original Comment:', df_val.explain.values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from code2nl.run import convert_examples_to_features, Example\n",
    "\n",
    "def get_preds(df: pd.DataFrame):\n",
    "    ps = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        examples = [\n",
    "            Example(idx, source = row.func_before, target = row.explain)\n",
    "        ]\n",
    "        eval_features = convert_examples_to_features(\n",
    "            examples, tokenizer, args, stage='test'\n",
    "        )\n",
    "        source_ids = torch.tensor(eval_features[0].source_ids, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "        source_mask = torch.tensor(eval_features[0].source_mask, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(source_ids = source_ids, source_mask = source_mask)  \n",
    "            for pred in preds:\n",
    "                t = pred[0].cpu().numpy()\n",
    "                t = list(t)\n",
    "                if 0 in t:\n",
    "                    t = t[:t.index(0)]\n",
    "                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                ps.append(text)\n",
    "    \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0037648677825927734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 39,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1954,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592e352d0ace47f0b631a871ae5110f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
      "07/20/2023 23:00:12 - INFO - absl -   Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6982222490058205,\n",
       " 'rouge2': 0.6540618651933405,\n",
       " 'rougeL': 0.6913723062609138,\n",
       " 'rougeLsum': 0.6907947959979734}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = df_test.reset_index()\n",
    "preds = get_preds(df_test)\n",
    "references = []\n",
    "for idx, row in df_test.iterrows():\n",
    "    # print('Code:', row.func_before)\n",
    "    # print('Original Comment:', row.explain)\n",
    "    # print('Generated Comment:', preds[idx])\n",
    "    # print('='*40)\n",
    "    references.append(row.explain)\n",
    "\n",
    "results = rouge.compute(predictions=preds, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static int cg_getattr(const char *path, struct stat *sb) {  struct timespec now;  struct fuse_context *fc = fuse_get_context();  char * cgdir = NULL;  char *fpath = NULL, *path1, *path2;  struct cgfs_files *k = NULL;  const char *cgroup;  const char *controller = NULL;  int ret = -ENOENT;    if (!fc)   return -EIO;   memset(sb, 0, sizeof(struct stat));   if (clock_gettime(CLOCK_REALTIME, &now) < 0)   return -EINVAL;   sb->st_uid = sb->st_gid = 0;  sb->st_atim = sb->st_mtim = sb->st_ctim = now;  sb->st_size = 0;   if (strcmp(path, \"/cgroup\") == 0) {   sb->st_mode = S_IFDIR | 00755;   sb->st_nlink = 2;   return 0;  }   controller = pick_controller_from_path(fc, path);  if (!controller)   return -EIO;  cgroup = find_cgroup_in_path(path);  if (!cgroup) {   /* this is just /cgroup/controller, return it as a dir */   sb->st_mode = S_IFDIR | 00755;   sb->st_nlink = 2;   return 0;  }   get_cgdir_and_path(cgroup, &cgdir, &fpath);   if (!fpath) {   path1 = \"/\";   path2 = cgdir;  } else {   path1 = cgdir;   path2 = fpath;  }   /* check that cgcopy is either a child cgroup of cgdir, or listed in its keys.   * Then check that caller's cgroup is under path if fpath is a child  * cgroup, or cgdir if fpath is a file */  if (is_child_cgroup(controller, path1, path2)) {  if (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {  /* this is just /cgroup/controller, return it as a dir */  sb->st_mode = S_IFDIR | 00555;    sb->st_nlink = 2;    ret = 0;    goto out;   }   if (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {    ret = -EACCES;    goto out;   }    sb->st_mode = S_IFDIR | 00755;   k = cgfs_get_key(controller, cgroup, \"tasks\");   if (!k) {    sb->st_uid = sb->st_gid = 0;   } else {    sb->st_uid = k->uid;    sb->st_gid = k->gid;   }   free_key(k);   sb->st_nlink = 2;   ret = 0;   goto out;  }   if ((k = cgfs_get_key(controller, path1, path2)) != NULL) {   sb->st_mode = S_IFREG | k->mode;   sb->st_nlink = 1;   sb->st_uid = k->uid;   sb->st_gid = k->gid;   sb->st_size = 0;   free_key(k);   if (!caller_is_in_ancestor(fc->pid, controller, path1, NULL)) {    ret = -ENOENT;    goto out;   }   if (!fc_may_access(fc, controller, path1, path2, O_RDONLY)) {    ret = -EACCES;    goto out;   }    ret = 0;  }  out:  free(cgdir);  return ret; } \n",
      "Original Comment: gain elevated privileges on the system\n",
      "Generated Comment: gain elevated privileges on the system\n",
      "========================================\n",
      "Code: void BufferQueueConsumer::dump(String8& result, const char* prefix) const {  const IPCThreadState* ipc = IPCThreadState::self();  const pid_t pid = ipc->getCallingPid();  const uid_t uid = ipc->getCallingUid();  if ((uid != AID_SHELL)  && !PermissionCache::checkPermission(String16(   \"android.permission.DUMP\"), pid, uid)) {  result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"  \"from pid=%d, uid=%d\\n\", pid, uid);  } else {  mCore->dump(result, prefix);  } } \n",
      "Original Comment: obtain sensitive information from process memory and bypass protection mechanism\n",
      "Generated Comment: cause a denial of service or possibly have unspecified other impact\n",
      "========================================\n",
      "Code:  TemplateURLRef::SearchTermsArgs::ContextualSearchParams::ContextualSearchParams(  int version,  const std::string& selection,  const std::string& base_page_url,  int now_on_tap_version)  : version(version),  start(base::string16::npos),  end(base::string16::npos),  selection(selection),  base_page_url(base_page_url),  now_on_tap_version(now_on_tap_version) {} \n",
      "Original Comment: cause a denial of service or possibly have other impact\n",
      "Generated Comment: cause a denial of service or possibly have other impact\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_test.head(3).iterrows():\n",
    "    print('Code:', row.func_before)\n",
    "    print('Original Comment:', row.explain)\n",
    "    print('Generated Comment:', preds[idx])\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
