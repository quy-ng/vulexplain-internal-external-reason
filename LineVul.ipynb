{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e4b1aa-cef1-4ca4-ad41-75717a8057de",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e98141f-66e9-4e33-aaf1-3ff5e855d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a92f87-fa42-47df-bd95-2eaf7e8c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad470abb-1096-4c9c-bf9e-d04244f46bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some warning from transformer\n",
    "# due to its verbose, disable\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94444f12-daab-47a8-aa7c-c296af8cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665ef7f0-266f-4504-bb27-d55b2cfd3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f929d687-4a2f-4988-a45c-48dcbe0de2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b209c02c-cee8-47ba-b29b-688f5a26c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_model import Model\n",
    "from linevul_helpers import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2dd844-e8c3-4e63-8957-049a8c8ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b698f48-aff8-436f-b7f9-c62449919530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd88e94-6911-4cb5-b638-4d27287f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from LineVul\n",
    "checkpoint = '/home/hqn650/LineVul/linevul/saved_models/checkpoint-best-f1/12heads_linevul_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218433bf-aee1-474d-b426-352bfd77b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d994a186-c905-442b-b5fe-2e54cae6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base', \n",
    "                                                             config=config, \n",
    "                                                             ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f577da66-2711-4216-97da-37b3b229b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    use_non_pretrained_model = False\n",
    "    block_size = 512\n",
    "    test_data_file = '/home/hqn650/LineVul/data/big-vul_dataset/test.csv'\n",
    "    code_length=256\n",
    "    do_local_explanation=True\n",
    "    reasoning_method='attention'\n",
    "    seed=42\n",
    "    num_attention_heads=12\n",
    "    do_sorting_by_line_scores=False\n",
    "    do_sorting_by_pred_prob=False\n",
    "    top_k_constant=10\n",
    "    use_word_level_tokenizer=False\n",
    "    eval_batch_size=512\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032a6625-6694-4299-9132-60ac6c3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(pre_train, config, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9ca781-54df-4aee-b028-946f8bb5d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=args.device))\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153d1699-2c3c-4be3-a13b-37c769ef260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a67769633594ab69e49cbfd3ebb9ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = TextDataset(tokenizer, args, file_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6f96191-e52a-4532-90f2-03835ad029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41471949-e260-4430-898d-20b7f7da822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c95b49-9206-4aa0-b23e-8f81fbaac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu evaluate\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0a069d6-8af2-49c7-bf74-274365038b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "nb_eval_steps = 0\n",
    "model.eval()\n",
    "logits=[]  \n",
    "y_trues=[]\n",
    "for batch in test_dataloader:\n",
    "    (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "        logits.append(logit.cpu().numpy())\n",
    "        y_trues.append(labels.cpu().numpy())\n",
    "    nb_eval_steps += 1\n",
    "# calculate scores\n",
    "logits = np.concatenate(logits, 0)\n",
    "y_trues = np.concatenate(y_trues, 0)\n",
    "y_preds = logits[:, 1] > best_threshold\n",
    "acc = accuracy_score(y_trues, y_preds)\n",
    "recall = recall_score(y_trues, y_preds)\n",
    "precision = precision_score(y_trues, y_preds)   \n",
    "f1 = f1_score(y_trues, y_preds)             \n",
    "result = {\n",
    "    \"test_accuracy\": float(acc),\n",
    "    \"test_recall\": float(recall),\n",
    "    \"test_precision\": float(precision),\n",
    "    \"test_f1\": float(f1),\n",
    "    \"test_threshold\":best_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c8c1bc-73cc-4c8c-bc1f-9877e7b71112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.9909351145038168,\n",
       " 'test_recall': 0.8635071090047394,\n",
       " 'test_precision': 0.9712153518123667,\n",
       " 'test_f1': 0.9141996989463121,\n",
       " 'test_threshold': 0.5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05a2585-762c-46c7-abb6-9a1429bf3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = np.where((y_trues == y_preds))\n",
    "correct_indices = list(correct_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "202b9aa2-d737-4ac2-b3cc-2469ffe634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_indices = np.where((y_trues == y_preds) & (y_trues == 1))\n",
    "tp_indices = list(tp_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ea70331-1364-47b4-879f-ae1f8c5e8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after identify true positive sample, create new loader for explaination\n",
    "\n",
    "dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ce4a810-b1c9-49fd-95f5-cf714e58729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d53f3cd3-0acf-41b0-89f3-893aa84ea2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_constant = [args.top_k_constant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "482fc72b-72dc-448d-b0b2-42358b84163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_token_values(all_values, padding=False):\n",
    "    # special token in the beginning of the seq \n",
    "    all_values[0] = 0\n",
    "    if padding:\n",
    "        # get the last non-zero value which represents the att score for </s> token\n",
    "        idx = [index for index, item in enumerate(all_values) if item != 0][-1]\n",
    "        all_values[idx] = 0\n",
    "    else:\n",
    "        # special token in the end of the seq \n",
    "        all_values[-1] = 0\n",
    "    return all_values\n",
    "def get_word_att_scores(all_tokens: list, att_scores: list) -> list:\n",
    "    word_att_scores = []\n",
    "    for i in range(len(all_tokens)):\n",
    "        token, att_score = all_tokens[i], att_scores[i]\n",
    "        word_att_scores.append([token, att_score])\n",
    "    return word_att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bc3bb71-e41e-4318-a730-96d3fd013f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853f0bae85bb4664aabd8684a9198384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "with torch.no_grad():\n",
    "    for mini_batch in progress_bar:\n",
    "        if index in tp_indices and index == 99:\n",
    "            (input_ids, labels) = mini_batch\n",
    "            ids = input_ids[0].detach().tolist()\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "            all_tokens = [token.replace(\"Ġ\", \"\") for token in all_tokens]\n",
    "            all_tokens = [token.replace(\"ĉ\", \"Ċ\") for token in all_tokens]\n",
    "            \n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "            attentions = attentions[0][0]\n",
    "            attention = None\n",
    "            # go into the layer\n",
    "            for i in range(len(attentions)):\n",
    "                layer_attention = attentions[i]\n",
    "                # summerize the values of each token dot other tokens\n",
    "                layer_attention = sum(layer_attention)\n",
    "                if attention is None:\n",
    "                    attention = layer_attention\n",
    "                else:\n",
    "                    attention += layer_attention\n",
    "            # clean att score for <s> and </s>\n",
    "            attention = clean_special_token_values(attention, padding=True)\n",
    "            # attention should be 1D tensor with seq length representing each token's attention value\n",
    "            # word_att_scores -> [[token, att_value], [token, att_value], ...]\n",
    "            word_att_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attention)\n",
    "\n",
    "\n",
    "            # go through each line\n",
    "            separator = [\"Ċ\", \" Ċ\", \"ĊĊ\", \" ĊĊ\"]\n",
    "            score_sum = 0\n",
    "            line = \"\"\n",
    "            score_sum = 0\n",
    "            lines_with_score = []\n",
    "            line_idx = 0\n",
    "            for i in range(len(word_att_scores)):\n",
    "                score_sum += word_att_scores[i][1]\n",
    "                if word_att_scores[i][0] not in separator:\n",
    "                    line += word_att_scores[i][0]\n",
    "                else:\n",
    "                    lines_with_score.append((line_idx, line, score_sum.detach().item()))\n",
    "                    line = \"\"\n",
    "                    score_sum = 0\n",
    "                    line_idx += 1\n",
    "            break\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bebb10dc-81d2-4c84-95a0-83b66e201b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5bcd092-098c-4ac6-a9f5-c24c3097f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15,\n",
       "  'if((cur->prev!=NULL)&&(cur->prev->type==XML_DTD_NODE))',\n",
       "  480.56585693359375),\n",
       " (3,\n",
       "  'if((ctxt==NULL)||(ctxt->context==NULL))return(NULL);',\n",
       "  379.0490417480469),\n",
       " (4,\n",
       "  'if((ctxt->context->node->type==XML_ATTRIBUTE_NODE)||',\n",
       "  357.1581115722656),\n",
       " (6, '(ctxt->context->node->type==XML_NAMESPACE_DECL))', 304.76922607421875)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lines = sorted(lines_with_score, key=lambda x: x[2], reverse=True)\n",
    "sorted_lines[:int(0.15*line_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "add765fc-bf45-4205-9360-9d65ff125ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xmlXPathNextPrecedingInternal(xmlXPathParserContextPtr ctxt,\n",
      "                               xmlNodePtr cur)\n",
      " {\n",
      "     if ((ctxt == NULL) || (ctxt->context == NULL)) return(NULL);\n",
      "    if ((ctxt->context->node->type == XML_ATTRIBUTE_NODE) ||\n",
      "\t(ctxt->context->node->type == XML_NAMESPACE_DECL))\n",
      "\treturn(NULL);\n",
      "     if (cur == NULL) {\n",
      "         cur = ctxt->context->node;\n",
      "         if (cur == NULL)\n",
      "             return (NULL);\n",
      "         ctxt->ancestor = cur->parent;\n",
      "     }\n",
      "     if ((cur->prev != NULL) && (cur->prev->type == XML_DTD_NODE))\n",
      "\tcur = cur->prev;\n",
      "    while (cur->prev == NULL) {\n",
      "        cur = cur->parent;\n",
      "        if (cur == NULL)\n",
      "            return (NULL);\n",
      "        if (cur == ctxt->context->doc->children)\n",
      "            return (NULL);\n",
      "        if (cur != ctxt->ancestor)\n",
      "            return (cur);\n",
      "        ctxt->ancestor = cur->parent;\n",
      "    }\n",
      "    cur = cur->prev;\n",
      "    while (cur->last != NULL)\n",
      "        cur = cur->last;\n",
      "    return (cur);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "context = df.iloc[99]['func_before']\n",
    "modified_context = codecs.decode(context, 'unicode_escape')\n",
    "\n",
    "new_variable = modified_context.replace(r'\\n', '\\n')\n",
    "\n",
    "print(new_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "392be2c9-5cb6-40f3-b3dd-b4ad0d4db118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ffcf83d-2fcb-4b21-b681-844821a5f8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                      183429\n",
       "Access Gained                                                                 NaN\n",
       "Attack Origin                                                                 NaN\n",
       "Authentication Required                                                       NaN\n",
       "Availability                                                                  NaN\n",
       "CVE ID                                                                        NaN\n",
       "CVE Page                                                                      NaN\n",
       "CWE ID                                                                        NaN\n",
       "Complexity                                                                    NaN\n",
       "Confidentiality                                                               NaN\n",
       "Integrity                                                                     NaN\n",
       "Known Exploits                                                                NaN\n",
       "Publish Date                                                                  NaN\n",
       "Score                                                                         NaN\n",
       "Summary                                                                       NaN\n",
       "Update Date                                                               2010-11\n",
       "Vulnerability Classification                                                  NaN\n",
       "add_lines                                                                       2\n",
       "codeLink                        https://github.com/chromium/chromium/commit/a4...\n",
       "commit_id                                a44b00c88bc5ea35b5b150217c5fd6e4ce168e58\n",
       "commit_message                  Apply behaviour change fix from upstream for p...\n",
       "del_lines                                                                       3\n",
       "file_name                                          third_party/libxml/src/xpath.c\n",
       "files_changed                   {\"sha\": \"832678a8b6360e45389c42744108c046cf695...\n",
       "func_after                      xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "func_before                     xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "lang                                                                            C\n",
       "lines_after                             if (cur->type == XML_NAMESPACE_DECL)\\n...\n",
       "lines_before                        if ((ctxt->context->node->type == XML_ATTR...\n",
       "parentID                                                                      NaN\n",
       "patch                           @@ -8106,17 +8106,17 @@ xmlXPathNextPrecedingS...\n",
       "project                                                                    Chrome\n",
       "project_after                            a44b00c88bc5ea35b5b150217c5fd6e4ce168e58\n",
       "project_before                           eef2c2ed6ea089b49c0f6468154d5a4d524abaeb\n",
       "target                                                                          1\n",
       "vul_func_with_fix               xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "processed_func                  xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "flaw_line                           if ((ctxt->context->node->type == XML_ATTR...\n",
       "flaw_line_index                                                             4,5,6\n",
       "Name: 99, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76e75-8f64-4810-9a32-a7c7d8dfda85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0d99757-a565-4f27-9d2f-9f85e62c69f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d335dcc-d4b4-4feb-8a4a-afcc3da44ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9413a17-d41c-4abd-b28c-2267f04245b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
