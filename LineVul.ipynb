{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e4b1aa-cef1-4ca4-ad41-75717a8057de",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e98141f-66e9-4e33-aaf1-3ff5e855d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a92f87-fa42-47df-bd95-2eaf7e8c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad470abb-1096-4c9c-bf9e-d04244f46bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some warning from transformer\n",
    "# due to its verbose, disable\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94444f12-daab-47a8-aa7c-c296af8cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665ef7f0-266f-4504-bb27-d55b2cfd3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f929d687-4a2f-4988-a45c-48dcbe0de2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b209c02c-cee8-47ba-b29b-688f5a26c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_model import Model\n",
    "from linevul_helpers import TextDataset\n",
    "from linevul_extra import extract_line_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2dd844-e8c3-4e63-8957-049a8c8ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b698f48-aff8-436f-b7f9-c62449919530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd88e94-6911-4cb5-b638-4d27287f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from LineVul\n",
    "checkpoint = '/home/hqn650/LineVul/linevul/saved_models/checkpoint-best-f1/12heads_linevul_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218433bf-aee1-474d-b426-352bfd77b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d994a186-c905-442b-b5fe-2e54cae6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base', \n",
    "                                                             config=config, \n",
    "                                                             ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f577da66-2711-4216-97da-37b3b229b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    use_non_pretrained_model = False\n",
    "    block_size = 512\n",
    "    test_data_file = '/home/hqn650/LineVul/data/big-vul_dataset/test.csv'\n",
    "    code_length=256\n",
    "    do_local_explanation=True\n",
    "    reasoning_method='attention'\n",
    "    seed=42\n",
    "    num_attention_heads=12\n",
    "    do_sorting_by_line_scores=False\n",
    "    do_sorting_by_pred_prob=False\n",
    "    top_k_constant=10\n",
    "    use_word_level_tokenizer=False\n",
    "    eval_batch_size=512\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032a6625-6694-4299-9132-60ac6c3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(pre_train, config, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9ca781-54df-4aee-b028-946f8bb5d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=args.device))\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153d1699-2c3c-4be3-a13b-37c769ef260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2df6b6fd78b44f7b68b74cee738850f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = TextDataset(tokenizer, args, file_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41471949-e260-4430-898d-20b7f7da822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04c95b49-9206-4aa0-b23e-8f81fbaac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu evaluate\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79df8544-cf4c-44a7-a4be-27bba95fb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linevul_predict(model, dataloader, threshold=0.5):\n",
    "    model.eval()\n",
    "    logits=[]  \n",
    "    y_trues=[]\n",
    "    for batch in test_dataloader:\n",
    "        (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "        with torch.no_grad():\n",
    "            lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            y_trues.append(labels.cpu().numpy())\n",
    "    # calculate scores\n",
    "    logits = np.concatenate(logits, 0)\n",
    "    y_trues = np.concatenate(y_trues, 0)\n",
    "    y_preds = logits[:, 1] > threshold\n",
    "    acc = accuracy_score(y_trues, y_preds)\n",
    "    recall = recall_score(y_trues, y_preds)\n",
    "    precision = precision_score(y_trues, y_preds)   \n",
    "    f1 = f1_score(y_trues, y_preds)             \n",
    "    result = {\n",
    "        \"test_accuracy\": float(acc),\n",
    "        \"test_recall\": float(recall),\n",
    "        \"test_precision\": float(precision),\n",
    "        \"test_f1\": float(f1),\n",
    "        \"test_threshold\":threshold,\n",
    "    }\n",
    "    return result, y_trues, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "339e2633-15a5-43c0-8a30-4b7f3f675c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "result, y_trues, y_preds = linevul_predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6c8c1bc-73cc-4c8c-bc1f-9877e7b71112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.9909351145038168,\n",
       " 'test_recall': 0.8635071090047394,\n",
       " 'test_precision': 0.9712153518123667,\n",
       " 'test_f1': 0.9141996989463121,\n",
       " 'test_threshold': 0.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b05a2585-762c-46c7-abb6-9a1429bf3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = np.where((y_trues == y_preds))\n",
    "correct_indices = list(correct_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "202b9aa2-d737-4ac2-b3cc-2469ffe634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_indices = np.where((y_trues == y_preds) & (y_trues == 1))\n",
    "tp_indices = list(tp_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ea70331-1364-47b4-879f-ae1f8c5e8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after identify true positive sample, create new loader for explaination\n",
    "\n",
    "dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ce4a810-b1c9-49fd-95f5-cf714e58729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d53f3cd3-0acf-41b0-89f3-893aa84ea2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_constant = [args.top_k_constant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc2e3f91-641b-4699-ac37-27011136a154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e5efc839a64ac19ccc33e15e5fde40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "index = 0\n",
    "progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "extract_list = []\n",
    "for mini_batch in progress_bar:\n",
    "    if index in tp_indices:\n",
    "        (input_ids, labels) = mini_batch\n",
    "        ids = input_ids[0].detach().tolist()\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "        all_tokens = [token.replace(\"Ġ\", \"\") for token in all_tokens]\n",
    "        all_tokens = [token.replace(\"ĉ\", \"Ċ\") for token in all_tokens]\n",
    "        with torch.no_grad():\n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "        lines_with_score, n_lines = extract_line_attention(attentions, all_tokens)\n",
    "        extract_list.append((lines_with_score, n_lines))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0203581-99a2-48b8-b27d-853a90f74b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extract_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad6ec6-f492-4360-b157-48ace09b1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcd092-098c-4ac6-a9f5-c24c3097f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lines = sorted(lines_with_score, key=lambda x: x[2], reverse=True)\n",
    "sorted_lines[:int(0.15*line_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add765fc-bf45-4205-9360-9d65ff125ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "context = df.iloc[99]['func_before']\n",
    "modified_context = codecs.decode(context, 'unicode_escape')\n",
    "\n",
    "new_variable = modified_context.replace(r'\\n', '\\n')\n",
    "\n",
    "print(new_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392be2c9-5cb6-40f3-b3dd-b4ad0d4db118",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcf83d-2fcb-4b21-b681-844821a5f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76e75-8f64-4810-9a32-a7c7d8dfda85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0d99757-a565-4f27-9d2f-9f85e62c69f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d335dcc-d4b4-4feb-8a4a-afcc3da44ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9413a17-d41c-4abd-b28c-2267f04245b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
