{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e4b1aa-cef1-4ca4-ad41-75717a8057de",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e98141f-66e9-4e33-aaf1-3ff5e855d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a92f87-fa42-47df-bd95-2eaf7e8c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad470abb-1096-4c9c-bf9e-d04244f46bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some warning from transformer\n",
    "# due to its verbose, disable\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94444f12-daab-47a8-aa7c-c296af8cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665ef7f0-266f-4504-bb27-d55b2cfd3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f929d687-4a2f-4988-a45c-48dcbe0de2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b209c02c-cee8-47ba-b29b-688f5a26c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_model import Model\n",
    "from linevul_helpers import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2dd844-e8c3-4e63-8957-049a8c8ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b698f48-aff8-436f-b7f9-c62449919530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd88e94-6911-4cb5-b638-4d27287f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from LineVul\n",
    "checkpoint = '/home/hqn650/LineVul/linevul/saved_models/checkpoint-best-f1/12heads_linevul_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218433bf-aee1-474d-b426-352bfd77b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d994a186-c905-442b-b5fe-2e54cae6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base', \n",
    "                                                             config=config, \n",
    "                                                             ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f577da66-2711-4216-97da-37b3b229b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    use_non_pretrained_model = False\n",
    "    block_size = 512\n",
    "    test_data_file = '/home/hqn650/LineVul/data/big-vul_dataset/test.csv'\n",
    "    code_length=256\n",
    "    do_local_explanation=True\n",
    "    reasoning_method='attention'\n",
    "    seed=42\n",
    "    num_attention_heads=12\n",
    "    do_sorting_by_line_scores=False\n",
    "    do_sorting_by_pred_prob=False\n",
    "    top_k_constant=10\n",
    "    use_word_level_tokenizer=False\n",
    "    eval_batch_size=512\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032a6625-6694-4299-9132-60ac6c3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(pre_train, config, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9ca781-54df-4aee-b028-946f8bb5d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=args.device))\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153d1699-2c3c-4be3-a13b-37c769ef260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d30fedb4d744f0a5d011f9f6ce551e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = TextDataset(tokenizer, args, file_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6f96191-e52a-4532-90f2-03835ad029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41471949-e260-4430-898d-20b7f7da822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c95b49-9206-4aa0-b23e-8f81fbaac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu evaluate\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79df8544-cf4c-44a7-a4be-27bba95fb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linevul_predict(model, dataloader):\n",
    "    model.eval()\n",
    "    logits=[]  \n",
    "    y_trues=[]\n",
    "    for batch in test_dataloader:\n",
    "        (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "        with torch.no_grad():\n",
    "            lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            y_trues.append(labels.cpu().numpy())\n",
    "    # calculate scores\n",
    "    logits = np.concatenate(logits, 0)\n",
    "    y_trues = np.concatenate(y_trues, 0)\n",
    "    y_preds = logits[:, 1] > best_threshold\n",
    "    acc = accuracy_score(y_trues, y_preds)\n",
    "    recall = recall_score(y_trues, y_preds)\n",
    "    precision = precision_score(y_trues, y_preds)   \n",
    "    f1 = f1_score(y_trues, y_preds)             \n",
    "    result = {\n",
    "        \"test_accuracy\": float(acc),\n",
    "        \"test_recall\": float(recall),\n",
    "        \"test_precision\": float(precision),\n",
    "        \"test_f1\": float(f1),\n",
    "        \"test_threshold\":best_threshold,\n",
    "    }\n",
    "    return result, y_trues, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "339e2633-15a5-43c0-8a30-4b7f3f675c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, y_trues, y_preds = linevul_predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a069d6-8af2-49c7-bf74-274365038b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_eval_steps = 0\n",
    "# model.eval()\n",
    "# logits=[]  \n",
    "# y_trues=[]\n",
    "# for batch in test_dataloader:\n",
    "#     (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "#     with torch.no_grad():\n",
    "#         lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "#         logits.append(logit.cpu().numpy())\n",
    "#         y_trues.append(labels.cpu().numpy())\n",
    "#     nb_eval_steps += 1\n",
    "# # calculate scores\n",
    "# logits = np.concatenate(logits, 0)\n",
    "# y_trues = np.concatenate(y_trues, 0)\n",
    "# y_preds = logits[:, 1] > best_threshold\n",
    "# acc = accuracy_score(y_trues, y_preds)\n",
    "# recall = recall_score(y_trues, y_preds)\n",
    "# precision = precision_score(y_trues, y_preds)   \n",
    "# f1 = f1_score(y_trues, y_preds)             \n",
    "# result = {\n",
    "#     \"test_accuracy\": float(acc),\n",
    "#     \"test_recall\": float(recall),\n",
    "#     \"test_precision\": float(precision),\n",
    "#     \"test_f1\": float(f1),\n",
    "#     \"test_threshold\":best_threshold,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8c1bc-73cc-4c8c-bc1f-9877e7b71112",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a2585-762c-46c7-abb6-9a1429bf3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = np.where((y_trues == y_preds))\n",
    "correct_indices = list(correct_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b9aa2-d737-4ac2-b3cc-2469ffe634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_indices = np.where((y_trues == y_preds) & (y_trues == 1))\n",
    "tp_indices = list(tp_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea70331-1364-47b4-879f-ae1f8c5e8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after identify true positive sample, create new loader for explaination\n",
    "\n",
    "dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4a810-b1c9-49fd-95f5-cf714e58729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f3cd3-0acf-41b0-89f3-893aa84ea2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_constant = [args.top_k_constant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fc72b-72dc-448d-b0b2-42358b84163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_token_values(all_values, padding=False):\n",
    "    # special token in the beginning of the seq \n",
    "    all_values[0] = 0\n",
    "    if padding:\n",
    "        # get the last non-zero value which represents the att score for </s> token\n",
    "        idx = [index for index, item in enumerate(all_values) if item != 0][-1]\n",
    "        all_values[idx] = 0\n",
    "    else:\n",
    "        # special token in the end of the seq \n",
    "        all_values[-1] = 0\n",
    "    return all_values\n",
    "def get_word_att_scores(all_tokens: list, att_scores: list) -> list:\n",
    "    word_att_scores = []\n",
    "    for i in range(len(all_tokens)):\n",
    "        token, att_score = all_tokens[i], att_scores[i]\n",
    "        word_att_scores.append([token, att_score])\n",
    "    return word_att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3bb71-e41e-4318-a730-96d3fd013f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "with torch.no_grad():\n",
    "    for mini_batch in progress_bar:\n",
    "        if index in tp_indices and index == 99:\n",
    "            (input_ids, labels) = mini_batch\n",
    "            ids = input_ids[0].detach().tolist()\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "            all_tokens = [token.replace(\"Ġ\", \"\") for token in all_tokens]\n",
    "            all_tokens = [token.replace(\"ĉ\", \"Ċ\") for token in all_tokens]\n",
    "            \n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "            attentions = attentions[0][0]\n",
    "            attention = None\n",
    "            # go into the layer\n",
    "            for i in range(len(attentions)):\n",
    "                layer_attention = attentions[i]\n",
    "                # summerize the values of each token dot other tokens\n",
    "                layer_attention = sum(layer_attention)\n",
    "                if attention is None:\n",
    "                    attention = layer_attention\n",
    "                else:\n",
    "                    attention += layer_attention\n",
    "            # clean att score for <s> and </s>\n",
    "            attention = clean_special_token_values(attention, padding=True)\n",
    "            # attention should be 1D tensor with seq length representing each token's attention value\n",
    "            # word_att_scores -> [[token, att_value], [token, att_value], ...]\n",
    "            word_att_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attention)\n",
    "\n",
    "\n",
    "            # go through each line\n",
    "            separator = [\"Ċ\", \" Ċ\", \"ĊĊ\", \" ĊĊ\"]\n",
    "            score_sum = 0\n",
    "            line = \"\"\n",
    "            score_sum = 0\n",
    "            lines_with_score = []\n",
    "            line_idx = 0\n",
    "            for i in range(len(word_att_scores)):\n",
    "                score_sum += word_att_scores[i][1]\n",
    "                if word_att_scores[i][0] not in separator:\n",
    "                    line += word_att_scores[i][0]\n",
    "                else:\n",
    "                    lines_with_score.append((line_idx, line, score_sum.detach().item()))\n",
    "                    line = \"\"\n",
    "                    score_sum = 0\n",
    "                    line_idx += 1\n",
    "            break\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb10dc-81d2-4c84-95a0-83b66e201b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcd092-098c-4ac6-a9f5-c24c3097f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lines = sorted(lines_with_score, key=lambda x: x[2], reverse=True)\n",
    "sorted_lines[:int(0.15*line_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add765fc-bf45-4205-9360-9d65ff125ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "context = df.iloc[99]['func_before']\n",
    "modified_context = codecs.decode(context, 'unicode_escape')\n",
    "\n",
    "new_variable = modified_context.replace(r'\\n', '\\n')\n",
    "\n",
    "print(new_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392be2c9-5cb6-40f3-b3dd-b4ad0d4db118",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcf83d-2fcb-4b21-b681-844821a5f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76e75-8f64-4810-9a32-a7c7d8dfda85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0d99757-a565-4f27-9d2f-9f85e62c69f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d335dcc-d4b4-4feb-8a4a-afcc3da44ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9413a17-d41c-4abd-b28c-2267f04245b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
