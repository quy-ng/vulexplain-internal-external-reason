{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e98141f-66e9-4e33-aaf1-3ff5e855d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a92f87-fa42-47df-bd95-2eaf7e8c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad470abb-1096-4c9c-bf9e-d04244f46bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some warning from transformer\n",
    "# due to its verbose, disable\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94444f12-daab-47a8-aa7c-c296af8cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "665ef7f0-266f-4504-bb27-d55b2cfd3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b209c02c-cee8-47ba-b29b-688f5a26c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_model import Model\n",
    "from linevul_helpers import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2dd844-e8c3-4e63-8957-049a8c8ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b698f48-aff8-436f-b7f9-c62449919530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd88e94-6911-4cb5-b638-4d27287f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from LineVul\n",
    "checkpoint = '/home/hqn650/LineVul/linevul/saved_models/checkpoint-best-f1/12heads_linevul_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218433bf-aee1-474d-b426-352bfd77b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d994a186-c905-442b-b5fe-2e54cae6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base', \n",
    "                                                             config=config, \n",
    "                                                             ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f577da66-2711-4216-97da-37b3b229b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    use_non_pretrained_model = False\n",
    "    block_size = 512\n",
    "    test_data_file = '/home/hqn650/LineVul/data/big-vul_dataset/test.csv'\n",
    "    code_length=256\n",
    "    do_local_explanation=True\n",
    "    reasoning_method='attention'\n",
    "    seed=42\n",
    "    num_attention_heads=12\n",
    "    do_sorting_by_line_scores=False\n",
    "    do_sorting_by_pred_prob=False\n",
    "    top_k_constant=10\n",
    "    use_word_level_tokenizer=False\n",
    "    eval_batch_size=512\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032a6625-6694-4299-9132-60ac6c3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(pre_train, config, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c9ca781-54df-4aee-b028-946f8bb5d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=args.device))\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "153d1699-2c3c-4be3-a13b-37c769ef260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1ed1c0fc3a4facbe50f024f6feb954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = TextDataset(tokenizer, args, file_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f96191-e52a-4532-90f2-03835ad029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41471949-e260-4430-898d-20b7f7da822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04c95b49-9206-4aa0-b23e-8f81fbaac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu evaluate\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0a069d6-8af2-49c7-bf74-274365038b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "nb_eval_steps = 0\n",
    "model.eval()\n",
    "logits=[]  \n",
    "y_trues=[]\n",
    "for batch in test_dataloader:\n",
    "    (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "        logits.append(logit.cpu().numpy())\n",
    "        y_trues.append(labels.cpu().numpy())\n",
    "    nb_eval_steps += 1\n",
    "# calculate scores\n",
    "logits = np.concatenate(logits, 0)\n",
    "y_trues = np.concatenate(y_trues, 0)\n",
    "y_preds = logits[:, 1] > best_threshold\n",
    "acc = accuracy_score(y_trues, y_preds)\n",
    "recall = recall_score(y_trues, y_preds)\n",
    "precision = precision_score(y_trues, y_preds)   \n",
    "f1 = f1_score(y_trues, y_preds)             \n",
    "result = {\n",
    "    \"test_accuracy\": float(acc),\n",
    "    \"test_recall\": float(recall),\n",
    "    \"test_precision\": float(precision),\n",
    "    \"test_f1\": float(f1),\n",
    "    \"test_threshold\":best_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8c1bc-73cc-4c8c-bc1f-9877e7b71112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
