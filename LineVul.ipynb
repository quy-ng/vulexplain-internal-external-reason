{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e98141f-66e9-4e33-aaf1-3ff5e855d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a92f87-fa42-47df-bd95-2eaf7e8c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad470abb-1096-4c9c-bf9e-d04244f46bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some warning from transformer\n",
    "# due to its verbose, disable\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94444f12-daab-47a8-aa7c-c296af8cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "665ef7f0-266f-4504-bb27-d55b2cfd3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f929d687-4a2f-4988-a45c-48dcbe0de2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b209c02c-cee8-47ba-b29b-688f5a26c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linevul_model import Model\n",
    "from linevul_helpers import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2dd844-e8c3-4e63-8957-049a8c8ffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b698f48-aff8-436f-b7f9-c62449919530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd88e94-6911-4cb5-b638-4d27287f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from LineVul\n",
    "checkpoint = '/home/hqn650/LineVul/linevul/saved_models/checkpoint-best-f1/12heads_linevul_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218433bf-aee1-474d-b426-352bfd77b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d994a186-c905-442b-b5fe-2e54cae6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = RobertaForSequenceClassification.from_pretrained('microsoft/codebert-base', \n",
    "                                                             config=config, \n",
    "                                                             ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f577da66-2711-4216-97da-37b3b229b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    use_non_pretrained_model = False\n",
    "    block_size = 512\n",
    "    test_data_file = '/home/hqn650/LineVul/data/big-vul_dataset/test.csv'\n",
    "    code_length=256\n",
    "    do_local_explanation=True\n",
    "    reasoning_method='attention'\n",
    "    seed=42\n",
    "    num_attention_heads=12\n",
    "    do_sorting_by_line_scores=False\n",
    "    do_sorting_by_pred_prob=False\n",
    "    top_k_constant=10\n",
    "    use_word_level_tokenizer=False\n",
    "    eval_batch_size=512\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032a6625-6694-4299-9132-60ac6c3f03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(pre_train, config, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c9ca781-54df-4aee-b028-946f8bb5d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=args.device))\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "153d1699-2c3c-4be3-a13b-37c769ef260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1ed1c0fc3a4facbe50f024f6feb954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = TextDataset(tokenizer, args, file_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f96191-e52a-4532-90f2-03835ad029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41471949-e260-4430-898d-20b7f7da822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04c95b49-9206-4aa0-b23e-8f81fbaac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu evaluate\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0a069d6-8af2-49c7-bf74-274365038b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "nb_eval_steps = 0\n",
    "model.eval()\n",
    "logits=[]  \n",
    "y_trues=[]\n",
    "for batch in test_dataloader:\n",
    "    (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "        logits.append(logit.cpu().numpy())\n",
    "        y_trues.append(labels.cpu().numpy())\n",
    "    nb_eval_steps += 1\n",
    "# calculate scores\n",
    "logits = np.concatenate(logits, 0)\n",
    "y_trues = np.concatenate(y_trues, 0)\n",
    "y_preds = logits[:, 1] > best_threshold\n",
    "acc = accuracy_score(y_trues, y_preds)\n",
    "recall = recall_score(y_trues, y_preds)\n",
    "precision = precision_score(y_trues, y_preds)   \n",
    "f1 = f1_score(y_trues, y_preds)             \n",
    "result = {\n",
    "    \"test_accuracy\": float(acc),\n",
    "    \"test_recall\": float(recall),\n",
    "    \"test_precision\": float(precision),\n",
    "    \"test_f1\": float(f1),\n",
    "    \"test_threshold\":best_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6c8c1bc-73cc-4c8c-bc1f-9877e7b71112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.9909351145038168,\n",
       " 'test_recall': 0.8635071090047394,\n",
       " 'test_precision': 0.9712153518123667,\n",
       " 'test_f1': 0.9141996989463121,\n",
       " 'test_threshold': 0.5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b05a2585-762c-46c7-abb6-9a1429bf3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = np.where((y_trues == y_preds))\n",
    "correct_indices = list(correct_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202b9aa2-d737-4ac2-b3cc-2469ffe634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_indices = np.where((y_trues == y_preds) & (y_trues == 1))\n",
    "tp_indices = list(tp_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ea70331-1364-47b4-879f-ae1f8c5e8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after identify true positive sample, create new loader for explaination\n",
    "\n",
    "dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ce4a810-b1c9-49fd-95f5-cf714e58729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d53f3cd3-0acf-41b0-89f3-893aa84ea2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_constant = [args.top_k_constant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d2c8b8f-e4fc-4bcd-93ff-9c626805210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_level_localization_tp(flaw_lines: str, tokenizer, model, mini_batch, original_func: str, args, top_k_loc: list, top_k_constant: list, reasoning_method: str, index: int, write_invalid_data: bool):\n",
    "    # function for captum LIG.\n",
    "    def predict(input_ids):\n",
    "        return model(input_ids=input_ids)[0]\n",
    "\n",
    "    def lig_forward(input_ids):\n",
    "        logits = model(input_ids=input_ids)[0]\n",
    "        y_pred = 1 # for positive attribution, y_pred = 0 for negative attribution\n",
    "        pred_prob = logits[y_pred].unsqueeze(-1)\n",
    "        return pred_prob\n",
    "\n",
    "    flaw_line_seperator = \"/~/\"\n",
    "    (input_ids, labels) = mini_batch\n",
    "    ids = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "    all_tokens = [token.replace(\"Ġ\", \"\") for token in all_tokens]\n",
    "    all_tokens = [token.replace(\"ĉ\", \"Ċ\") for token in all_tokens]\n",
    "    original_lines = ''.join(all_tokens).split(\"Ċ\")\n",
    "\n",
    "    # flaw line verification\n",
    "    # get flaw tokens ground truth\n",
    "    flaw_lines = get_all_flaw_lines(flaw_lines=flaw_lines, flaw_line_seperator=flaw_line_seperator)\n",
    "    flaw_tokens_encoded = encode_all_lines(all_lines=flaw_lines, tokenizer=tokenizer)\n",
    "    verified_flaw_lines = []\n",
    "    do_explanation = False\n",
    "    for i in range(len(flaw_tokens_encoded)):\n",
    "        encoded_flaw = ''.join(flaw_tokens_encoded[i])\n",
    "        encoded_all = ''.join(all_tokens)\n",
    "        if encoded_flaw in encoded_all:\n",
    "            verified_flaw_lines.append(flaw_tokens_encoded[i])\n",
    "            do_explanation = True\n",
    "\n",
    "    # do explanation if at least one flaw line exist in the encoded input\n",
    "    if do_explanation:\n",
    "        if reasoning_method == \"attention\":\n",
    "            # attentions: a tuple with of one Tensor with 4D shape (batch_size, num_heads, sequence_length, sequence_length)\n",
    "            input_ids = input_ids.to(args.device)\n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "            # take from tuple then take out mini-batch attention values\n",
    "            attentions = attentions[0][0]\n",
    "            attention = None\n",
    "            # go into the layer\n",
    "            for i in range(len(attentions)):\n",
    "                layer_attention = attentions[i]\n",
    "                # summerize the values of each token dot other tokens\n",
    "                layer_attention = sum(layer_attention)\n",
    "                if attention is None:\n",
    "                    attention = layer_attention\n",
    "                else:\n",
    "                    attention += layer_attention\n",
    "            # clean att score for <s> and </s>\n",
    "            attention = clean_special_token_values(attention, padding=True)\n",
    "            # attention should be 1D tensor with seq length representing each token's attention value\n",
    "            word_att_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attention)\n",
    "            all_lines_score, flaw_line_indices = get_all_lines_score(word_att_scores, verified_flaw_lines)\n",
    "            # return if no flaw lines exist\n",
    "            if len(flaw_line_indices) == 0:\n",
    "                return \"NA\"\n",
    "            total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, top_10_correct_idx, top_10_not_correct_idx \\\n",
    "            = \\\n",
    "            line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=True, index=index)\n",
    "        elif reasoning_method == \"lig\":\n",
    "            ref_token_id, sep_token_id, cls_token_id = tokenizer.pad_token_id, tokenizer.sep_token_id, tokenizer.cls_token_id\n",
    "            ref_input_ids = create_ref_input_ids(input_ids, ref_token_id, sep_token_id, cls_token_id)\n",
    "            # send data to device\n",
    "            input_ids = input_ids.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            ref_input_ids = ref_input_ids.to(args.device)\n",
    "            lig = LayerIntegratedGradients(lig_forward, model.encoder.roberta.embeddings)\n",
    "            attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                                baselines=ref_input_ids,\n",
    "                                                internal_batch_size=32,\n",
    "                                                return_convergence_delta=True)\n",
    "            score = predict(input_ids)\n",
    "            pred_idx = torch.argmax(score).cpu().numpy()\n",
    "            pred_prob = score[pred_idx]\n",
    "            attributions_sum = summarize_attributions(attributions)        \n",
    "            attr_scores = attributions_sum.tolist()\n",
    "            # each token should have one score\n",
    "            assert len(all_tokens) == len(attr_scores)\n",
    "            # store tokens and attr scores together in a list of tuple [(token, attr_score)]\n",
    "            word_attr_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attr_scores)\n",
    "            # remove <s>, </s>, <unk>, <pad>\n",
    "            word_attr_scores = clean_word_attr_scores(word_attr_scores=word_attr_scores)\n",
    "            all_lines_score, flaw_line_indices = get_all_lines_score(word_attr_scores, verified_flaw_lines)\n",
    "            # return if no flaw lines exist\n",
    "            if len(flaw_line_indices) == 0:\n",
    "                return \"NA\"\n",
    "            total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, top_10_correct_idx, top_10_not_correct_idx \\\n",
    "             = \\\n",
    "            line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=True, index=index)\n",
    "        elif reasoning_method == \"deeplift\" or \\\n",
    "             reasoning_method == \"deeplift_shap\" or \\\n",
    "             reasoning_method == \"gradient_shap\" or \\\n",
    "             reasoning_method == \"saliency\":\n",
    "            # send data to device\n",
    "            input_ids = input_ids.to(args.device)\n",
    "            input_embed = model.encoder.roberta.embeddings(input_ids).to(args.device)\n",
    "            if reasoning_method == \"deeplift\":\n",
    "                #baselines = torch.randn(1, 512, 768, requires_grad=True).to(args.device)\n",
    "                baselines = torch.zeros(1, 512, 768, requires_grad=True).to(args.device)\n",
    "                reasoning_model = DeepLift(model)\n",
    "            elif reasoning_method == \"deeplift_shap\":\n",
    "                #baselines = torch.randn(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                baselines = torch.zeros(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                reasoning_model = DeepLiftShap(model)\n",
    "            elif reasoning_method == \"gradient_shap\":\n",
    "                #baselines = torch.randn(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                baselines = torch.zeros(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                reasoning_model = GradientShap(model)\n",
    "            elif reasoning_method == \"saliency\":\n",
    "                reasoning_model = Saliency(model)\n",
    "            # attributions -> [1, 512, 768]\n",
    "            if reasoning_method == \"saliency\":\n",
    "                attributions = reasoning_model.attribute(input_embed, target=1)\n",
    "            else:\n",
    "                attributions = reasoning_model.attribute(input_embed, baselines=baselines, target=1)\n",
    "            attributions_sum = summarize_attributions(attributions)        \n",
    "            attr_scores = attributions_sum.tolist()\n",
    "            # each token should have one score\n",
    "            assert len(all_tokens) == len(attr_scores)\n",
    "            # store tokens and attr scores together in a list of tuple [(token, attr_score)]\n",
    "            word_attr_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attr_scores)\n",
    "            # remove <s>, </s>, <unk>, <pad>\n",
    "            word_attr_scores = clean_word_attr_scores(word_attr_scores=word_attr_scores)\n",
    "            all_lines_score, flaw_line_indices = get_all_lines_score(word_attr_scores, verified_flaw_lines)\n",
    "            # return if no flaw lines exist\n",
    "            if len(flaw_line_indices) == 0:\n",
    "                return \"NA\"\n",
    "            total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, top_10_correct_idx, top_10_not_correct_idx \\\n",
    "             = \\\n",
    "            line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=True, index=index)        \n",
    "      \n",
    "        results = {\"total_lines\": total_lines,\n",
    "                    \"num_of_flaw_lines\": num_of_flaw_lines,\n",
    "                    \"all_correctly_predicted_flaw_lines\": all_correctly_predicted_flaw_lines,\n",
    "                    \"all_correctly_localized_function\": all_correctly_localized_func,\n",
    "                    \"min_clean_lines_inspected\": min_clean_lines_inspected,\n",
    "                    \"max_clean_lines_inspected\": max_clean_lines_inspected,\n",
    "                    \"top_10_correct_idx\": top_10_correct_idx,\n",
    "                    \"top_10_not_correct_idx\": top_10_not_correct_idx}\n",
    "        return results\n",
    "    else:\n",
    "        if write_invalid_data:\n",
    "            with open(\"../invalid_data/invalid_line_lev_data.txt\", \"a\") as f:\n",
    "                f.writelines(\"--- ALL TOKENS ---\")\n",
    "                f.writelines(\"\\n\")\n",
    "                alltok = ''.join(all_tokens)\n",
    "                alltok = alltok.split(\"Ċ\")\n",
    "                for tok in alltok:\n",
    "                    f.writelines(tok)\n",
    "                    f.writelines(\"\\n\")\n",
    "                f.writelines(\"--- FLAW ---\")\n",
    "                f.writelines(\"\\n\")\n",
    "                for i in range(len(flaw_tokens_encoded)):\n",
    "                    f.writelines(''.join(flaw_tokens_encoded[i]))\n",
    "                    f.writelines(\"\\n\")\n",
    "                f.writelines(\"\\n\")\n",
    "                f.writelines(\"\\n\")\n",
    "    # if no flaw line exist in the encoded input\n",
    "    return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "482fc72b-72dc-448d-b0b2-42358b84163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_flaw_lines(flaw_lines: str, flaw_line_seperator: str) -> list:\n",
    "    if isinstance(flaw_lines, str):\n",
    "        flaw_lines = flaw_lines.strip(flaw_line_seperator)\n",
    "        flaw_lines = flaw_lines.split(flaw_line_seperator)\n",
    "        flaw_lines = [line.strip() for line in flaw_lines]\n",
    "    else:\n",
    "        flaw_lines = []\n",
    "    return flaw_lines\n",
    "def encode_all_lines(all_lines: list, tokenizer) -> list:\n",
    "    encoded = []\n",
    "    for line in all_lines:\n",
    "        encoded.append(encode_one_line(line=line, tokenizer=tokenizer))\n",
    "    return encoded\n",
    "def encode_one_line(line, tokenizer):\n",
    "    # add \"@ \" at the beginning to ensure the encoding consistency, i.e., previous -> previous, not previous > pre + vious\n",
    "    code_tokens = tokenizer.tokenize(\"@ \" + line)\n",
    "    return [token.replace(\"Ġ\", \"\") for token in code_tokens if token != \"@\"]\n",
    "def clean_special_token_values(all_values, padding=False):\n",
    "    # special token in the beginning of the seq \n",
    "    all_values[0] = 0\n",
    "    if padding:\n",
    "        # get the last non-zero value which represents the att score for </s> token\n",
    "        idx = [index for index, item in enumerate(all_values) if item != 0][-1]\n",
    "        all_values[idx] = 0\n",
    "    else:\n",
    "        # special token in the end of the seq \n",
    "        all_values[-1] = 0\n",
    "    return all_values\n",
    "def get_word_att_scores(all_tokens: list, att_scores: list) -> list:\n",
    "    word_att_scores = []\n",
    "    for i in range(len(all_tokens)):\n",
    "        token, att_score = all_tokens[i], att_scores[i]\n",
    "        word_att_scores.append([token, att_score])\n",
    "    return word_att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6e85c75-f2d9-4797-9ba0-800feff6c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_lines_score(word_att_scores: list, verified_flaw_lines: list):\n",
    "    verified_flaw_lines = [''.join(l) for l in verified_flaw_lines]\n",
    "    # word_att_scores -> [[token, att_value], [token, att_value], ...]\n",
    "    separator = [\"Ċ\", \" Ċ\", \"ĊĊ\", \" ĊĊ\"]\n",
    "    # to return\n",
    "    all_lines_score = []\n",
    "    score_sum = 0\n",
    "    line_idx = 0\n",
    "    flaw_line_indices = []\n",
    "    line = \"\"\n",
    "    for i in range(len(word_att_scores)):\n",
    "        # summerize if meet line separator or the last token\n",
    "        if ((word_att_scores[i][0] in separator) or (i == (len(word_att_scores) - 1))) and score_sum != 0:\n",
    "            score_sum += word_att_scores[i][1]\n",
    "            all_lines_score.append(score_sum)\n",
    "            is_flaw_line = False\n",
    "            for l in verified_flaw_lines:\n",
    "                if l == line:\n",
    "                    is_flaw_line = True\n",
    "            if is_flaw_line:\n",
    "                flaw_line_indices.append(line_idx)\n",
    "            line = \"\"\n",
    "            score_sum = 0\n",
    "            line_idx += 1\n",
    "        # else accumulate score\n",
    "        elif word_att_scores[i][0] not in separator:\n",
    "            line += word_att_scores[i][0]\n",
    "            score_sum += word_att_scores[i][1]\n",
    "    return all_lines_score, flaw_line_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12da6c07-017f-4c18-aa15-0940acf627df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_level_evaluation(all_lines_score: list, flaw_line_indices: list, top_k_loc: list, top_k_constant: list, true_positive_only: bool, index=None):\n",
    "    if true_positive_only:    \n",
    "        # line indices ranking based on attr values \n",
    "        ranking = sorted(range(len(all_lines_score)), key=lambda i: all_lines_score[i], reverse=True)\n",
    "        # total flaw lines\n",
    "        num_of_flaw_lines = len(flaw_line_indices)\n",
    "        # clean lines + flaw lines\n",
    "        total_lines = len(all_lines_score)\n",
    "        ### TopK% Recall ###\n",
    "        all_correctly_predicted_flaw_lines = []  \n",
    "        ### IFA ###\n",
    "        ifa = True\n",
    "        all_clean_lines_inspected = []\n",
    "        for top_k in top_k_loc:\n",
    "            correctly_predicted_flaw_lines = 0\n",
    "            for indice in flaw_line_indices:\n",
    "                # if within top-k\n",
    "                k = int(len(all_lines_score) * top_k)\n",
    "                # if detecting any flaw lines\n",
    "                if indice in ranking[: k]:\n",
    "                    correctly_predicted_flaw_lines += 1\n",
    "                if ifa:\n",
    "                    # calculate Initial False Alarm\n",
    "                    # IFA counts how many clean lines are inspected until the first vulnerable line is found when inspecting the lines ranked by the approaches.\n",
    "                    flaw_line_idx_in_ranking = ranking.index(indice)\n",
    "                    # e.g. flaw_line_idx_in_ranking = 3 will include 1 vulnerable line and 3 clean lines\n",
    "                    all_clean_lines_inspected.append(flaw_line_idx_in_ranking)  \n",
    "            # for IFA\n",
    "            min_clean_lines_inspected = min(all_clean_lines_inspected)\n",
    "            # for All Effort\n",
    "            max_clean_lines_inspected = max(all_clean_lines_inspected)\n",
    "            # only do IFA and All Effort once\n",
    "            ifa = False\n",
    "            # append result for one top-k value\n",
    "            all_correctly_predicted_flaw_lines.append(correctly_predicted_flaw_lines)\n",
    "        \n",
    "        ### Top10 Accuracy ###\n",
    "        all_correctly_localized_func = []\n",
    "        top_10_correct_idx = []\n",
    "        top_10_not_correct_idx = []\n",
    "        correctly_located = False\n",
    "        for k in top_k_constant:\n",
    "            for indice in flaw_line_indices:\n",
    "                # if detecting any flaw lines\n",
    "                if indice in ranking[: k]:\n",
    "                    \"\"\"\n",
    "                    # extract example for the paper\n",
    "                    if index == 2797:\n",
    "                        print(\"2797\")\n",
    "                        print(\"ground truth flaw line index: \", indice)\n",
    "                        print(\"ranked line\")\n",
    "                        print(ranking)\n",
    "                        print(\"original score\")\n",
    "                        print(all_lines_score)\n",
    "                    \"\"\"\n",
    "                    # append result for one top-k value\n",
    "                    all_correctly_localized_func.append(1)\n",
    "                    correctly_located = True\n",
    "                else:\n",
    "                    all_correctly_localized_func.append(0)\n",
    "            if correctly_located:\n",
    "                top_10_correct_idx.append(index)\n",
    "            else:\n",
    "                top_10_not_correct_idx.append(index)\n",
    "        return total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, \\\n",
    "               top_10_correct_idx, top_10_not_correct_idx\n",
    "    else:\n",
    "        # all_lines_score_with_label: [[line score, line level label], [line score, line level label], ...]\n",
    "        all_lines_score_with_label = []\n",
    "        for i in range(len(all_lines_score)):\n",
    "            if i in flaw_line_indices:\n",
    "                all_lines_score_with_label.append([all_lines_score[i], 1])\n",
    "            else:\n",
    "                all_lines_score_with_label.append([all_lines_score[i], 0])\n",
    "        return all_lines_score_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cec4aa26-1c25-4a2d-98b9-9539af70cf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904cfb4a96434566a8186b09411c0330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_k_locs = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "index = 0\n",
    "na_explanation_case_01 = 0\n",
    "na_explanation_case_02 = 0\n",
    "explain_list = []\n",
    "progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "for mini_batch in progress_bar:\n",
    "    if index in tp_indices:\n",
    "        if isinstance(df[\"flaw_line\"][index], str) and isinstance(df[\"flaw_line_index\"][index], str):  \n",
    "            line_eval_results = \\\n",
    "                        line_level_localization_tp(flaw_lines=df[\"flaw_line\"][index],\n",
    "                                                tokenizer=tokenizer, \n",
    "                                                model=model, \n",
    "                                                mini_batch=mini_batch, \n",
    "                                                original_func=df[\"processed_func\"][index], \n",
    "                                                args=args,\n",
    "                                                top_k_loc=top_k_locs,\n",
    "                                                top_k_constant=top_k_constant,\n",
    "                                                reasoning_method=args.reasoning_method,\n",
    "                                                index=index,\n",
    "                                                write_invalid_data=False)\n",
    "            if line_eval_results != \"NA\":\n",
    "                explain_list.append((index, line_eval_results))\n",
    "            else:\n",
    "                na_explanation_case_01 +=1\n",
    "        else:\n",
    "            na_explanation_case_02 +=1\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3f8ef6d-65fb-4a95-867a-e483d0aea3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 911, 104, 179)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explain_list), len(tp_indices), na_explanation_case_01, na_explanation_case_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd0dfafd-1123-4dd1-a818-6eab8919aee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2410,\n",
       " {'total_lines': 4,\n",
       "  'num_of_flaw_lines': 2,\n",
       "  'all_correctly_predicted_flaw_lines': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2],\n",
       "  'all_correctly_localized_function': [1, 1],\n",
       "  'min_clean_lines_inspected': 1,\n",
       "  'max_clean_lines_inspected': 3,\n",
       "  'top_10_correct_idx': [2410],\n",
       "  'top_10_not_correct_idx': []})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_list[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "73266e23-b275-4604-98aa-6a46ba99c078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xmlXPathNextPrecedingInternal(xmlXPathParserContextPtr ctxt,\\n                               xmlNodePtr cur)\\n {\\n     if ((ctxt == NULL) || (ctxt->context == NULL)) return(NULL);\\n    if ((ctxt->context->node->type == XML_ATTRIBUTE_NODE) ||\\n\\t(ctxt->context->node->type == XML_NAMESPACE_DECL))\\n\\treturn(NULL);\\n     if (cur == NULL) {\\n         cur = ctxt->context->node;\\n         if (cur == NULL)\\n             return (NULL);\\n         ctxt->ancestor = cur->parent;\\n     }\\n     if ((cur->prev != NULL) && (cur->prev->type == XML_DTD_NODE))\\n\\tcur = cur->prev;\\n    while (cur->prev == NULL) {\\n        cur = cur->parent;\\n        if (cur == NULL)\\n            return (NULL);\\n        if (cur == ctxt->context->doc->children)\\n            return (NULL);\\n        if (cur != ctxt->ancestor)\\n            return (cur);\\n        ctxt->ancestor = cur->parent;\\n    }\\n    cur = cur->prev;\\n    while (cur->last != NULL)\\n        cur = cur->last;\\n    return (cur);\\n}\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[99]['func_before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1bc3bb71-e41e-4318-a730-96d3fd013f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c46b1db04c24f4d9dec0ab73e184c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "with torch.no_grad():\n",
    "    for mini_batch in progress_bar:\n",
    "        if index in tp_indices and index == 99:\n",
    "            (input_ids, labels) = mini_batch\n",
    "            ids = input_ids[0].detach().tolist()\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "            all_tokens = [token.replace(\"Ġ\", \"\") for token in all_tokens]\n",
    "            all_tokens = [token.replace(\"ĉ\", \"Ċ\") for token in all_tokens]\n",
    "            \n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "            attentions = attentions[0][0]\n",
    "            attention = None\n",
    "            # go into the layer\n",
    "            for i in range(len(attentions)):\n",
    "                layer_attention = attentions[i]\n",
    "                # summerize the values of each token dot other tokens\n",
    "                layer_attention = sum(layer_attention)\n",
    "                if attention is None:\n",
    "                    attention = layer_attention\n",
    "                else:\n",
    "                    attention += layer_attention\n",
    "            # clean att score for <s> and </s>\n",
    "            attention = clean_special_token_values(attention, padding=True)\n",
    "            # attention should be 1D tensor with seq length representing each token's attention value\n",
    "            # word_att_scores -> [[token, att_value], [token, att_value], ...]\n",
    "            word_att_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attention)\n",
    "\n",
    "\n",
    "            # go through each line\n",
    "            separator = [\"Ċ\", \" Ċ\", \"ĊĊ\", \" ĊĊ\"]\n",
    "            score_sum = 0\n",
    "            line = \"\"\n",
    "            score_sum = 0\n",
    "            lines_with_score = []\n",
    "            line_idx = 0\n",
    "            for i in range(len(word_att_scores)):\n",
    "                score_sum += word_att_scores[i][1]\n",
    "                if word_att_scores[i][0] not in separator:\n",
    "                    line += word_att_scores[i][0]\n",
    "                else:\n",
    "                    lines_with_score.append((line_idx, line, score_sum.detach().item()))\n",
    "                    line = \"\"\n",
    "                    score_sum = 0\n",
    "                    line_idx += 1\n",
    "            break\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bebb10dc-81d2-4c84-95a0-83b66e201b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c5bcd092-098c-4ac6-a9f5-c24c3097f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15,\n",
       "  'if((cur->prev!=NULL)&&(cur->prev->type==XML_DTD_NODE))',\n",
       "  480.56585693359375),\n",
       " (3,\n",
       "  'if((ctxt==NULL)||(ctxt->context==NULL))return(NULL);',\n",
       "  379.0490417480469),\n",
       " (4,\n",
       "  'if((ctxt->context->node->type==XML_ATTRIBUTE_NODE)||',\n",
       "  357.1581115722656),\n",
       " (6, '(ctxt->context->node->type==XML_NAMESPACE_DECL))', 304.76922607421875)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lines = sorted(lines_with_score, key=lambda x: x[2], reverse=True)\n",
    "sorted_lines[:int(0.15*line_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "add765fc-bf45-4205-9360-9d65ff125ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xmlXPathNextPrecedingInternal(xmlXPathParserContextPtr ctxt,\n",
      "                               xmlNodePtr cur)\n",
      " {\n",
      "     if ((ctxt == NULL) || (ctxt->context == NULL)) return(NULL);\n",
      "    if ((ctxt->context->node->type == XML_ATTRIBUTE_NODE) ||\n",
      "\t(ctxt->context->node->type == XML_NAMESPACE_DECL))\n",
      "\treturn(NULL);\n",
      "     if (cur == NULL) {\n",
      "         cur = ctxt->context->node;\n",
      "         if (cur == NULL)\n",
      "             return (NULL);\n",
      "         ctxt->ancestor = cur->parent;\n",
      "     }\n",
      "     if ((cur->prev != NULL) && (cur->prev->type == XML_DTD_NODE))\n",
      "\tcur = cur->prev;\n",
      "    while (cur->prev == NULL) {\n",
      "        cur = cur->parent;\n",
      "        if (cur == NULL)\n",
      "            return (NULL);\n",
      "        if (cur == ctxt->context->doc->children)\n",
      "            return (NULL);\n",
      "        if (cur != ctxt->ancestor)\n",
      "            return (cur);\n",
      "        ctxt->ancestor = cur->parent;\n",
      "    }\n",
      "    cur = cur->prev;\n",
      "    while (cur->last != NULL)\n",
      "        cur = cur->last;\n",
      "    return (cur);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "context = df.iloc[99]['func_before']\n",
    "modified_context = codecs.decode(context, 'unicode_escape')\n",
    "\n",
    "new_variable = modified_context.replace(r'\\n', '\\n')\n",
    "\n",
    "print(new_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "392be2c9-5cb6-40f3-b3dd-b4ad0d4db118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_with_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2ffcf83d-2fcb-4b21-b681-844821a5f8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                      183429\n",
       "Access Gained                                                                 NaN\n",
       "Attack Origin                                                                 NaN\n",
       "Authentication Required                                                       NaN\n",
       "Availability                                                                  NaN\n",
       "CVE ID                                                                        NaN\n",
       "CVE Page                                                                      NaN\n",
       "CWE ID                                                                        NaN\n",
       "Complexity                                                                    NaN\n",
       "Confidentiality                                                               NaN\n",
       "Integrity                                                                     NaN\n",
       "Known Exploits                                                                NaN\n",
       "Publish Date                                                                  NaN\n",
       "Score                                                                         NaN\n",
       "Summary                                                                       NaN\n",
       "Update Date                                                               2010-11\n",
       "Vulnerability Classification                                                  NaN\n",
       "add_lines                                                                       2\n",
       "codeLink                        https://github.com/chromium/chromium/commit/a4...\n",
       "commit_id                                a44b00c88bc5ea35b5b150217c5fd6e4ce168e58\n",
       "commit_message                  Apply behaviour change fix from upstream for p...\n",
       "del_lines                                                                       3\n",
       "file_name                                          third_party/libxml/src/xpath.c\n",
       "files_changed                   {\"sha\": \"832678a8b6360e45389c42744108c046cf695...\n",
       "func_after                      xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "func_before                     xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "lang                                                                            C\n",
       "lines_after                             if (cur->type == XML_NAMESPACE_DECL)\\n...\n",
       "lines_before                        if ((ctxt->context->node->type == XML_ATTR...\n",
       "parentID                                                                      NaN\n",
       "patch                           @@ -8106,17 +8106,17 @@ xmlXPathNextPrecedingS...\n",
       "project                                                                    Chrome\n",
       "project_after                            a44b00c88bc5ea35b5b150217c5fd6e4ce168e58\n",
       "project_before                           eef2c2ed6ea089b49c0f6468154d5a4d524abaeb\n",
       "target                                                                          1\n",
       "vul_func_with_fix               xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "processed_func                  xmlXPathNextPrecedingInternal(xmlXPathParserCo...\n",
       "flaw_line                           if ((ctxt->context->node->type == XML_ATTR...\n",
       "flaw_line_index                                                             4,5,6\n",
       "Name: 99, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76e75-8f64-4810-9a32-a7c7d8dfda85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
