{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=codebert_attack_vector\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=codebert_attack_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from project_dataset import load_dataset\n",
    "from code2nl.model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_name = \"microsoft/codebert-base\"\n",
    "    num_proc = 4\n",
    "    batch_size = 5\n",
    "    max_source_length = 512  \n",
    "    max_target_length = 153 \n",
    "    data_cols = [\"CVE ID\", \"explain\", \"func_before\"]\n",
    "    save_dir = 'tf_board'\n",
    "    epochs = 100\n",
    "    grad_acc_steps = 4\n",
    "    lr = 5e-5\n",
    "    log_freq = 10\n",
    "    local_rank = -1\n",
    "    deepspeed = None\n",
    "    fp16 = False\n",
    "    lr_warmup_steps = 200\n",
    "    weight_decay = 0.05\n",
    "    task = \"root_cause\"\n",
    "    prefix = 'codebert'\n",
    "    do_lower_case = False\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(args.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 3431\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 382\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['CVE ID', 'explain', 'func_before', 'processed_func'],\n",
       "        num_rows: 954\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds['train']\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "df_val = ds['validation']\n",
    "df_val = df_val.to_pandas()\n",
    "\n",
    "df_test = ds['test']\n",
    "df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVE ID</th>\n",
       "      <th>explain</th>\n",
       "      <th>func_before</th>\n",
       "      <th>processed_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-2016-2546</td>\n",
       "      <td>uses an incorrect type of mutex</td>\n",
       "      <td>static int snd_timer_user_tselect(struct file ...</td>\n",
       "      <td>static int snd_timer_user_tselect(struct file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-2016-1683</td>\n",
       "      <td>mishandles namespace nodes</td>\n",
       "      <td>xsltCopyOf(xsltTransformContextPtr ctxt, xmlNo...</td>\n",
       "      <td>xsltCopyOf(xsltTransformContextPtr ctxt, xmlNo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-2016-3078</td>\n",
       "      <td>No boundary checking</td>\n",
       "      <td>static void php_zip_get_from(INTERNAL_FUNCTION...</td>\n",
       "      <td>static void php_zip_get_from(INTERNAL_FUNCTION...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CVE ID                           explain  \\\n",
       "0  CVE-2016-2546  uses an incorrect type of mutex    \n",
       "1  CVE-2016-1683       mishandles namespace nodes    \n",
       "2  CVE-2016-3078              No boundary checking   \n",
       "\n",
       "                                         func_before  \\\n",
       "0  static int snd_timer_user_tselect(struct file ...   \n",
       "1  xsltCopyOf(xsltTransformContextPtr ctxt, xmlNo...   \n",
       "2  static void php_zip_get_from(INTERNAL_FUNCTION...   \n",
       "\n",
       "                                      processed_func  \n",
       "0  static int snd_timer_user_tselect(struct file ...  \n",
       "1  xsltCopyOf(xsltTransformContextPtr ctxt, xmlNo...  \n",
       "2  static void php_zip_get_from(INTERNAL_FUNCTION...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "os.makedirs(f'tmp_data/{args.task}', exist_ok=True)\n",
    "os.makedirs(f'{args.save_dir}/{args.prefix}_{args.task}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_train['code_tokens'] = df_train.func_before.apply(lambda x: x.split())\n",
    "df_train['docstring_tokens'] = df_train.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/train.jsonl','w') as f:\n",
    "    for _, row in df_train.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_val['code_tokens'] = df_val.func_before.apply(lambda x: x.split())\n",
    "df_val['docstring_tokens'] = df_val.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/valid.jsonl','w') as f:\n",
    "    for _, row in df_val.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')\n",
    "\n",
    "df_test['code_tokens'] = df_test.func_before.apply(lambda x: x.split())\n",
    "df_test['docstring_tokens'] = df_test.explain.apply(lambda x: x.split())\n",
    "with open(f'tmp_data/{args.task}/test.jsonl','w') as f:\n",
    "    for _, row in df_test.iterrows():\n",
    "        f.write(json.dumps(row.to_dict()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/20/2023 02:34:35 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='tf_board/codebert_root_cause', load_model_path=None, train_filename='tmp_data/root_cause/train.jsonl', dev_filename='tmp_data/root_cause/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=153, do_train=True, do_eval=True, do_test=False, do_lower_case=True, no_cuda=False, train_batch_size=50, eval_batch_size=50, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/20/2023 02:34:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   idx: 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_int', '_s', 'nd', '_', 'timer', '_', 'user', '_', 't', 'select', '(', 'struct', '_file', '_*', 'file', ',', '_struct', '_s', 'nd', '_', 'timer', '_', 'select', '___', 'user', '_*', '_', 't', 'select', ')', '_{', '_struct', '_s', 'nd', '_', 'timer', '_', 'user', '_*', 'tu', ';', '_struct', '_s', 'nd', '_', 'timer', '_', 'select', '_t', 'select', ';', '_char', '_str', '[', '32', '];', '_int', '_err', '_=', '_0', ';', '_tu', '_=', '_file', '->', 'private', '_', 'data', ';', '_mut', 'ex', '_', 'lock', '(&', 'tu', '->', 't', 'read', '_', 'sem', ');', '_if', '_(', 'tu', '->', 'tim', 'eri', ')', '_{', '_s', 'nd', '_', 'timer', '_', 'close', '(', 'tu', '->', 'tim', 'eri', ');', '_tu', '->', 'tim', 'eri', '_=', '_NULL', ';', '_}', '_if', '_(', 'copy', '_', 'from', '_', 'user', '(&', 't', 'select', ',', '__', 't', 'select', ',', '_sizeof', '(', 't', 'select', ')))', '_{', '_err', '_=', '_-', 'E', 'FAULT', ';', '_goto', '___', 'err', ';', '_}', '_sprint', 'f', '(', 'str', ',', '_\"', 'application', '_%', 'i', '\",', '_current', '->', 'pid', ');', '_if', '_(', 't', 'select', '.', 'id', '.', 'dev', '_', 'class', '_!=', '_SN', 'DR', 'V', '_', 'T', 'IM', 'ER', '_', 'CLASS', '_', 'SL', 'A', 'VE', ')', '_t', 'select', '.', 'id', '.', 'dev', '_', 's', 'class', '_=', '_SN', 'DR', 'V', '_', 'T', 'IM', 'ER', '_', 'S', 'CLASS', '_', 'AP', 'PLIC', 'ATION', ';', '_err', '_=', '_s', 'nd', '_', 'timer', '_', 'open', '(&', 'tu', '->', 'tim', 'eri', ',', '_str', ',', '_&', 't', 'select', '.', 'id', ',', '_current', '->', 'pid', ');', '_if', '_(', 'err', '_<', '_0', ')', '_goto', '___', 'err', ';', '_k', 'free', '(', 'tu', '->', 'queue', ');', '_tu', '->', 'queue', '_=', '_NULL', ';', '_k', 'free', '(', 'tu', '->', 't', 'queue', ');', '_tu', '->', 't', 'queue', '_=', '_NULL', ';', '_if', '_(', 'tu', '->', 't', 'read', ')', '_{', '_tu', '->', 't', 'queue', '_=', '_km', 'alloc', '(', 'tu', '->', 'queue', '_', 'size', '_*', '_sizeof', '(', 'struct', '_s', 'nd', '_', 'timer', '_', 't', 'read', '),', '_G', 'FP', '_', 'K', 'ERN', 'EL', ');', '_if', '_(', 'tu', '->', 't', 'queue', '_==', '_NULL', ')', '_err', '_=', '_-', 'EN', 'OM', 'EM', ';', '_}', '_else', '_{', '_tu', '->', 'queue', '_=', '_km', 'alloc', '(', 'tu', '->', 'queue', '_', 'size', '_*', '_sizeof', '(', 'struct', '_s', 'nd', '_', 'timer', '_', 'read', '),', '_G', 'FP', '_', 'K', 'ERN', 'EL', ');', '_if', '_(', 'tu', '->', 'queue', '_==', '_NULL', ')', '_err', '_=', '_-', 'EN', 'OM', 'EM', ';', '_}', '_if', '_(', 'err', '_<', '_0', ')', '_{', '_s', 'nd', '_', 'timer', '_', 'close', '(', 'tu', '->', 'tim', 'eri', ');', '_tu', '->', 'tim', 'eri', '_=', '_NULL', ';', '_}', '_else', '_{', '_tu', '->', 'tim', 'eri', '->', 'flags', '_|', '=', '_SN', 'DR', 'V', '_', 'T', 'IM', 'ER', '_', 'I', 'FL', 'G', '_', 'F', 'AST', ';', '_tu', '->', 'tim', 'eri', '->', 'callback', '_=', '_tu', '->', 't', 'read', '_?', '_s', 'nd', '_', 'timer', '_', 'user', '_', 't', 'inter', 'rupt', '_:', '_s', 'nd', '_', 'timer', '_', 'user', '_', 'inter', 'rupt', ';', '_tu', '->', 'tim', 'eri', '->', 'cc', 'all', 'back', '_=', '_s', 'nd', '_', 'timer', '_', 'user', '_', 'cc', 'all', 'back', ';', '_tu', '->', 'tim', 'eri', '->', 'callback', '_', 'data', '_=', '_(', 'void', '_*)', 'tu', ';', '_}', '___', 'err', ':', '_mut', 'ex', '_', 'un', 'lock', '(&', 'tu', '->', 't', 'read', '_', 'sem', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_ids: 0 42653 6979 579 1187 1215 36588 1215 12105 1215 90 38450 1640 25384 2870 1009 21710 6 29916 579 1187 1215 36588 1215 38450 27148 12105 1009 1215 90 38450 43 25522 29916 579 1187 1215 36588 1215 12105 1009 10109 131 29916 579 1187 1215 36588 1215 38450 326 38450 131 16224 7031 10975 2881 44082 6979 22379 5457 321 131 13145 5457 2870 46613 22891 1215 23687 131 16119 3463 1215 8292 49763 10109 46613 90 12745 1215 26976 4397 114 36 10109 46613 10519 16367 43 25522 579 1187 1215 36588 1215 22641 1640 10109 46613 10519 16367 4397 13145 46613 10519 16367 5457 48955 131 35524 114 36 44273 1215 7761 1215 12105 49763 90 38450 6 18134 90 38450 6 49907 1640 90 38450 47619 25522 22379 5457 111 717 47697 131 49325 27148 14385 131 35524 12631 506 1640 6031 6 22 40545 7606 118 1297 595 46613 43708 4397 114 36 90 38450 4 808 4 20068 1215 4684 49333 13687 10644 846 1215 565 3755 2076 1215 47986 1215 11160 250 8856 43 326 38450 4 808 4 20068 1215 29 4684 5457 13687 10644 846 1215 565 3755 2076 1215 104 47986 1215 591 44597 6034 131 22379 5457 579 1187 1215 36588 1215 12592 49763 10109 46613 10519 16367 6 7031 6 359 90 38450 4 808 6 595 46613 43708 4397 114 36 14385 28696 321 43 49325 27148 14385 131 449 3743 1640 10109 46613 48702 4397 13145 46613 48702 5457 48955 131 449 3743 1640 10109 46613 90 48702 4397 13145 46613 90 48702 5457 48955 131 114 36 10109 46613 90 12745 43 25522 13145 46613 90 48702 5457 6301 48429 1640 10109 46613 48702 1215 10799 1009 49907 1640 25384 579 1187 1215 36588 1215 90 12745 238 272 9763 1215 530 29092 3721 4397 114 36 10109 46613 90 48702 45994 48955 43 22379 5457 111 2796 3765 5330 131 35524 1493 25522 13145 46613 48702 5457 6301 48429 1640 10109 46613 48702 1215 10799 1009 49907 1640 25384 579 1187 1215 36588 1215 12745 238 272 9763 1215 530 29092 3721 4397 114 36 10109 46613 48702 45994 48955 43 22379 5457 111 2796 3765 5330 131 35524 114 36 14385 28696 321 43 25522 579 1187 1215 36588 1215 22641 1640 10109 46613 10519 16367 4397 13145 46613 10519 16367 5457 48955 131 35524 1493 25522 13145 46613 10519 16367 46613 46760 1721 5214 13687 10644 846 1215 565 3755 2076 1215 100 7613 534 1215 597 10388 131 13145 46613 10519 16367 46613 49499 5457 13145 46613 90 12745 17487 579 1187 1215 36588 1215 12105 1215 90 8007 14709 4832 579 1187 1215 36588 1215 12105 1215 8007 14709 131 13145 46613 10519 16367 46613 7309 1250 1644 5457 579 1187 1215 36588 1215 12105 1215 7309 1250 1644 131 13145 46613 10519 16367 46613 49499 1215 23687 5457 36 47908 49521 10109 131 35524 27148 14385 35 16119 3463 1215 879 8292 49763 10109 46613 90 12745 1215 26976 2\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_tokens: ['<s>', 'uses', '_an', '_incorrect', '_type', '_of', '_mut', 'ex', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_ids: 0 9764 41 17401 1907 9 16119 3463 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   idx: 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_tokens: ['<s>', 'xs', 'lt', 'Copy', 'Of', '(', 'xs', 'lt', 'Transform', 'Context', 'Ptr', '_c', 'txt', ',', '_xml', 'Node', 'Ptr', '_node', ',', '_xml', 'Node', 'Ptr', '_inst', ',', '_x', 's', 'lt', 'Style', 'Pre', 'Comp', 'Ptr', '_cast', 'ed', 'Comp', ')', '_{', '_#', 'if', 'def', '_X', 'SL', 'T', '_', 'REF', 'ACT', 'ORED', '_x', 's', 'lt', 'Style', 'Item', 'Copy', 'Of', 'Ptr', '_comp', '_=', '_(', 'xs', 'lt', 'Style', 'Item', 'Copy', 'Of', 'Ptr', ')', '_cast', 'ed', 'Comp', ';', '_#', 'else', '_x', 's', 'lt', 'Style', 'Pre', 'Comp', 'Ptr', '_comp', '_=', '_cast', 'ed', 'Comp', ';', '_#', 'endif', '_xml', 'X', 'Path', 'Object', 'Ptr', '_res', '_=', '_NULL', ';', '_xml', 'Node', 'Set', 'Ptr', '_list', '_=', '_NULL', ';', '_int', '_i', ';', '_xml', 'Doc', 'Ptr', '_old', 'XP', 'Context', 'Doc', ';', '_xml', 'Ns', 'Ptr', '_*', 'old', 'X', 'PN', 'ames', 'paces', ';', '_xml', 'Node', 'Ptr', '_old', 'XP', 'Context', 'Node', ';', '_int', '_old', 'XP', 'Pro', 'x', 'imity', 'Position', ',', '_old', 'XP', 'Context', 'Size', ',', '_old', 'X', 'PN', 's', 'N', 'r', ';', '_xml', 'X', 'Path', 'Context', 'Ptr', '_xp', 'ct', 'xt', ';', '_if', '_((', 'ct', 'xt', '_==', '_NULL', ')', '_||', '_(', 'node', '_==', '_NULL', ')', '_||', '_(', 'inst', '_==', '_NULL', '))', '_return', ';', '_if', '_((', 'comp', '_==', '_NULL', ')', '_||', '_(', 'comp', '->', 'select', '_==', '_NULL', ')', '_||', '_(', 'comp', '->', 'comp', '_==', '_NULL', '))', '_{', '_x', 's', 'lt', 'Transform', 'Error', '(', 'ct', 'xt', ',', '_NULL', ',', '_inst', ',', '_\"', 'x', 'sl', ':', 'copy', '-', 'of', '_:', '_compilation', '_failed', '\\\\', 'n', '\");', '_return', ';', '_}', '_/*', '_*', '_SPEC', '_X', 'SL', 'T', '_1', '.', '0', ':', '_*', '_\"', 'The', '_x', 'sl', ':', 'copy', '-', 'of', '_element', '_can', '_be', '_used', '_to', '_insert', '_a', '_result', '_tree', '_*', '_fragment', '_into', '_the', '_result', '_tree', ',', '_without', '_first', '_converting', '_it', '_to', '_*', '_a', '_string', '_as', '_x', 'sl', ':', 'value', '-', 'of', '_does', '_(', 'see', '_[', '7', '.', '6', '.', '1', '_Gener', 'ating', '_Text', '_with', '_*', '_x', 'sl', ':', 'value', '-', 'of', ']).', '_The', '_required', '_select', '_attribute', '_contains', '_an', '_*', '_expression', '.', '_When', '_the', '_result', '_of', '_evaluating', '_the', '_expression', '_is', '_a', '_*', '_result', '_tree', '_fragment', ',', '_the', '_complete', '_fragment', '_is', '_copied', '_into', '_the', '_*', '_result', '_tree', '.', '_When', '_the', '_result', '_is', '_a', '_node', '-', 'set', ',', '_all', '_the', '_nodes', '_in', '_the', '_*', '_set', '_are', '_copied', '_in', '_document', '_order', '_into', '_the', '_result', '_tree', ';', '_copying', '_*', '_an', '_element', '_node', '_copies', '_the', '_attribute', '_nodes', ',', '_namespace', '_nodes', '_and', '_*', '_children', '_of', '_the', '_element', '_node', '_as', '_well', '_as', '_the', '_element', '_node', '_itself', ';', '_*', '_a', '_root', '_node', '_is', '_copied', '_by', '_copying', '_its', '_children', '.', '_When', '_the', '_result', '_*', '_is', '_neither', '_a', '_node', '-', 'set', '_nor', '_a', '_result', '_tree', '_fragment', ',', '_the', '_result', '_is', '_*', '_converted', '_to', '_a', '_string', '_and', '_then', '_inserted', '_into', '_the', '_result', '_tree', ',', '_*', '_as', '_with', '_x', 'sl', ':', 'value', '-', 'of', '.', '_*/', '_#', 'if', 'def', '_WITH', '_', 'X', 'SL', 'T', '_', 'DEBUG', '_', 'PR', 'OC', 'ESS', '_X', 'SL', 'T', '_', 'TR', 'ACE', '(', 'ct', 'xt', ',', 'X', 'SL', 'T', '_', 'TR', 'ACE', '_', 'C', 'OP', 'Y', '_', 'OF', ',', 'xs', 'lt', 'Generic', 'Debug', '(', 'xs', 'lt', 'Generic', 'Debug', 'Context', ',', '_\"', 'xs', 'lt', 'Copy', 'Of', ':', '_select', '_%', 's', '\\\\', 'n', '\",', '_comp', '->', 'select', '));', '_#', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_ids: 0 43026 7984 48233 10643 1640 43026 7984 44820 48522 49835 740 46795 6 49377 48271 49835 37908 6 49377 48271 49835 9084 6 3023 29 7984 31774 22763 24699 49835 2471 196 24699 43 25522 849 1594 9232 1577 11160 565 1215 45935 13709 46818 3023 29 7984 31774 47599 48233 10643 49835 7753 5457 36 43026 7984 31774 47599 48233 10643 49835 43 2471 196 24699 131 849 44617 3023 29 7984 31774 22763 24699 49835 7753 5457 2471 196 24699 131 849 49741 49377 1000 42119 46674 49835 5032 5457 48955 131 49377 48271 28512 49835 889 5457 48955 131 6979 939 131 49377 42291 49835 793 29269 48522 42291 131 49377 40737 49835 1009 279 1000 21824 12336 43693 131 49377 48271 49835 793 29269 48522 48271 131 6979 793 29269 10653 1178 45853 46884 6 793 29269 48522 45698 6 793 1000 21824 29 487 338 131 49377 1000 42119 48522 49835 49288 3894 11483 131 114 41006 3894 11483 45994 48955 43 45056 36 46840 45994 48955 43 45056 36 16063 45994 48955 35122 671 131 114 41006 11828 45994 48955 43 45056 36 11828 46613 38450 45994 48955 43 45056 36 11828 46613 11828 45994 48955 35122 25522 3023 29 7984 44820 30192 1640 3894 11483 6 48955 6 9084 6 22 1178 9996 35 44273 12 1116 4832 32245 1447 37457 282 45751 671 131 35524 48565 1009 44921 1577 11160 565 112 4 288 35 1009 22 133 3023 9996 35 44273 12 1116 7510 64 28 341 7 27545 10 898 3907 1009 37903 88 5 898 3907 6 396 78 18841 24 7 1009 10 6755 25 3023 9996 35 19434 12 1116 473 36 7048 646 406 4 401 4 134 15745 1295 14159 19 1009 3023 9996 35 19434 12 1116 48610 20 1552 5163 21643 6308 41 1009 8151 4 520 5 898 9 15190 5 8151 16 10 1009 898 3907 37903 6 5 1498 37903 16 15443 88 5 1009 898 3907 4 520 5 898 16 10 37908 12 8738 6 70 5 32833 11 5 1009 278 32 15443 11 3780 645 88 5 898 3907 131 34236 1009 41 7510 37908 11288 5 21643 32833 6 49010 32833 8 1009 408 9 5 7510 37908 25 157 25 5 7510 37908 1495 131 1009 10 9749 37908 16 15443 30 34236 63 408 4 520 5 898 1009 16 5063 10 37908 12 8738 3486 10 898 3907 37903 6 5 898 16 1009 8417 7 10 6755 8 172 24557 88 5 898 3907 6 1009 25 19 3023 9996 35 19434 12 1116 4 48404 849 1594 9232 17345 1215 1000 11160 565 1215 49837 1215 4454 4571 12147 1577 11160 565 1215 6997 15949 1640 3894 11483 6 1000 11160 565 1215 6997 15949 1215 347 5733 975 1215 21600 6 43026 7984 49144 49714 1640 43026 7984 49144 49714 48522 6 22 43026 7984 48233 10643 35 5163 7606 29 37457 282 1297 7753 46613 38450 48749 849 2\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_tokens: ['<s>', 'm', 'ish', 'and', 'les', '_namespace', '_nodes', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_ids: 0 119 1173 463 1634 49010 32833 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   idx: 2\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_void', '_php', '_', 'zip', '_', 'get', '_', 'from', '(', 'IN', 'TERN', 'AL', '_', 'FUN', 'CT', 'ION', '_', 'PAR', 'AM', 'ET', 'ERS', ',', '_int', '_type', ')', '_/*', '_{{', '{', '_*/', '_{', '_struct', '_zip', '_*', 'intern', ';', '_z', 'val', '_*', 'self', '_=', '_get', 'This', '();', '_struct', '_zip', '_', 'stat', '_s', 'b', ';', '_struct', '_zip', '_', 'file', '_*', 'z', 'f', ';', '_z', 'end', '_', 'long', '_index', '_=', '_-', '1', ';', '_z', 'end', '_', 'long', '_flags', '_=', '_0', ';', '_z', 'end', '_', 'long', '_len', '_=', '_0', ';', '_z', 'end', '_', 'string', '_*', 'filename', ';', '_z', 'end', '_', 'string', '_*', 'buffer', ';', '_int', '_n', '_=', '_0', ';', '_if', '_(!', 'self', ')', '_{', '_RET', 'URN', '_', 'F', 'ALSE', ';', '_}', '_ZIP', '_', 'FR', 'OM', '_', 'OB', 'JECT', '(', 'intern', ',', '_self', ');', '_if', '_(', 'type', '_==', '_1', ')', '_{', '_if', '_(', 'z', 'end', '_', 'parse', '_', 'param', 'eters', '(', 'Z', 'END', '_', 'NUM', '_', 'AR', 'GS', '(),', '_\"', 'P', '|', 'll', '\",', '_&', 'filename', ',', '_&', 'len', ',', '_&', 'flags', ')', '_==', '_FA', 'IL', 'URE', ')', '_{', '_return', ';', '_}', '_PHP', '_', 'Z', 'IP', '_', 'STAT', '_', 'PATH', '(', 'intern', ',', '_Z', 'STR', '_', 'VAL', '(', 'filename', '),', '_Z', 'STR', '_', 'L', 'EN', '(', 'filename', '),', '_flags', ',', '_s', 'b', ');', '_}', '_else', '_{', '_if', '_(', 'z', 'end', '_', 'parse', '_', 'param', 'eters', '(', 'Z', 'END', '_', 'NUM', '_', 'AR', 'GS', '(),', '_\"', 'l', '|', 'll', '\",', '_&', 'index', ',', '_&', 'len', ',', '_&', 'flags', ')', '_==', '_FA', 'IL', 'URE', ')', '_{', '_return', ';', '_}', '_PHP', '_', 'Z', 'IP', '_', 'STAT', '_', 'IND', 'EX', '(', 'intern', ',', '_index', ',', '_0', ',', '_s', 'b', ');', '_}', '_if', '_(', 'sb', '.', 'size', '_<', '_1', ')', '_{', '_RET', 'URN', '_', 'EMP', 'TY', '_', 'STR', 'ING', '();', '_}', '_if', '_(', 'len', '_<', '_1', ')', '_{', '_len', '_=', '_s', 'b', '.', 'size', ';', '_}', '_if', '_(', 'index', '_>=', '_0', ')', '_{', '_z', 'f', '_=', '_zip', '_', 'f', 'open', '_', 'index', '(', 'intern', ',', '_index', ',', '_flags', ');', '_}', '_else', '_{', '_z', 'f', '_=', '_zip', '_', 'f', 'open', '(', 'intern', ',', '_Z', 'STR', '_', 'VAL', '(', 'filename', '),', '_flags', ');', '_}', '_if', '_(', 'z', 'f', '_==', '_NULL', ')', '_{', '_RET', 'URN', '_', 'F', 'ALSE', ';', '_}', '_buffer', '_=', '_z', 'end', '_', 'string', '_', 'alloc', '(', 'len', ',', '_0', ');', '_n', '_=', '_zip', '_', 'f', 'read', '(', 'z', 'f', ',', '_Z', 'STR', '_', 'VAL', '(', 'buffer', '),', '_Z', 'STR', '_', 'L', 'EN', '(', 'buffer', '));', '_if', '_(', 'n', '_<', '_1', ')', '_{', '_z', 'end', '_', 'string', '_', 'free', '(', 'buffer', ');', '_RET', 'URN', '_', 'EMP', 'TY', '_', 'STR', 'ING', '();', '_}', '_zip', '_', 'f', 'close', '(', 'z', 'f', ');', '_Z', 'STR', '_', 'VAL', '(', 'buffer', ')[', 'n', ']', '_=', \"_'\", '\\\\', '0', \"';\", '_Z', 'STR', '_', 'L', 'EN', '(', 'buffer', ')', '_=', '_n', ';', '_RET', 'URN', '_', 'NEW', '_', 'STR', '(', 'buffer', ');', '_}', '_/*', '_}', '}}', '_*/', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_ids: 0 42653 13842 46817 1215 39017 1215 6460 1215 7761 1640 2444 37683 2118 1215 45354 7164 7744 1215 14280 2620 3935 4322 6 6979 1907 43 48565 47517 45152 48404 25522 29916 23595 1009 44115 131 992 6486 1009 13367 5457 120 713 47006 29916 23595 1215 24344 579 428 131 29916 23595 1215 21710 1009 329 506 131 992 1397 1215 3479 1965 5457 111 134 131 992 1397 1215 3479 9287 5457 321 131 992 1397 1215 3479 25528 5457 321 131 992 1397 1215 20951 1009 49451 131 992 1397 1215 20951 1009 47438 131 6979 295 5457 321 131 114 48209 13367 43 25522 34017 28267 1215 597 49146 131 35524 41989 1215 5499 3765 1215 7912 33302 1640 44115 6 1403 4397 114 36 12528 45994 112 43 25522 114 36 329 1397 1215 48778 1215 46669 20413 1640 1301 9309 1215 46758 1215 2747 10729 49196 22 510 15483 890 1297 359 49451 6 359 8476 6 359 46760 43 45994 6236 3063 12435 43 25522 671 131 35524 42164 1215 1301 3808 1215 40106 1215 48468 1640 44115 6 525 30549 1215 39766 1640 49451 238 525 30549 1215 574 2796 1640 49451 238 9287 6 579 428 4397 35524 1493 25522 114 36 329 1397 1215 48778 1215 46669 20413 1640 1301 9309 1215 46758 1215 2747 10729 49196 22 462 15483 890 1297 359 18480 6 359 8476 6 359 46760 43 45994 6236 3063 12435 43 25522 671 131 35524 42164 1215 1301 3808 1215 40106 1215 13796 6725 1640 44115 6 1965 6 321 6 579 428 4397 35524 114 36 37844 4 10799 28696 112 43 25522 34017 28267 1215 42257 6175 1215 30549 1862 47006 35524 114 36 8476 28696 112 43 25522 25528 5457 579 428 4 10799 131 35524 114 36 18480 49095 321 43 25522 992 506 5457 23595 1215 506 12592 1215 18480 1640 44115 6 1965 6 9287 4397 35524 1493 25522 992 506 5457 23595 1215 506 12592 1640 44115 6 525 30549 1215 39766 1640 49451 238 9287 4397 35524 114 36 329 506 45994 48955 43 25522 34017 28267 1215 597 49146 131 35524 21944 5457 992 1397 1215 20951 1215 48429 1640 8476 6 321 4397 295 5457 23595 1215 506 12745 1640 329 506 6 525 30549 1215 39766 1640 47438 238 525 30549 1215 574 2796 1640 47438 48749 114 36 282 28696 112 43 25522 992 1397 1215 20951 1215 3743 1640 47438 4397 34017 28267 1215 42257 6175 1215 30549 1862 47006 35524 23595 1215 506 22641 1640 329 506 4397 525 30549 1215 39766 1640 47438 48462 282 742 5457 128 37457 288 23500 525 30549 1215 574 2796 1640 47438 43 5457 295 131 34017 28267 1215 5341 1215 30549 1640 47438 4397 35524 48565 35524 46961 48404 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_tokens: ['<s>', 'No', '_boundary', '_checking', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_ids: 0 3084 16358 8405 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   idx: 3\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_Image', '_*', 'Read', 'T', 'IFF', 'Image', '(', 'const', '_Image', 'Info', '_*', 'image', '_', 'info', ',', '_Exception', 'Info', '_*', 'ex', 'ception', ')', '_{', '_const', '_char', '_*', 'option', ';', '_float', '_*', 'chrom', 'atic', 'ity', ',', '_x', '_', 'position', ',', '_y', '_', 'position', ',', '_x', '_', 'resolution', ',', '_y', '_', 'resolution', ';', '_Image', '_*', 'image', ';', '_int', '_t', 'iff', '_', 'status', ';', '_Mag', 'ick', 'Boo', 'lean', 'Type', '_debug', ',', '_status', ';', '_Mag', 'ick', 'Size', 'Type', '_number', '_', 'p', 'ixels', ';', '_Quantum', 'Info', '_*', 'quant', 'um', '_', 'info', ';', '_Quantum', 'Type', '_quantum', '_', 'type', ';', '_register', '_s', 'size', '_', 't', '_i', ';', '_size', '_', 't', '_pad', ';', '_s', 'size', '_', 't', '_y', ';', '_T', 'IFF', '_*', 't', 'iff', ';', '_T', 'IFF', 'Error', 'Handler', '_error', '_', 'handler', ',', '_warning', '_', 'handler', ';', '_T', 'IFF', 'Method', 'Type', '_method', ';', '_uint', '16', '_compress', '_', 'tag', ',', '_bits', '_', 'per', '_', 'sample', ',', '_end', 'ian', ',', '_extra', '_', 's', 'amples', ',', '_inter', 'lace', ',', '_max', '_', 'sample', '_', 'value', ',', '_min', '_', 'sample', '_', 'value', ',', '_orientation', ',', '_pages', ',', '_phot', 'ometric', ',', '_*', 'sample', '_', 'info', ',', '_sample', '_', 'format', ',', '_samples', '_', 'per', '_', 'pixel', ',', '_units', ',', '_value', ';', '_uint', '32', '_height', ',', '_rows', '_', 'per', '_', 'strip', ',', '_width', ';', '_unsigned', '_char', '_*', 'p', 'ixels', ';', '_/*', '_Open', '_image', '.', '_*/', '_assert', '(', 'image', '_', 'info', '_!=', '_(', 'const', '_Image', 'Info', '_*)', '_NULL', ');', '_assert', '(', 'image', '_', 'info', '->', 'sign', 'ature', '_==', '_Mag', 'ick', 'Sign', 'ature', ');', '_if', '_(', 'image', '_', 'info', '->', 'debug', '_!=', '_Mag', 'ick', 'False', ')', '_(', 'void', ')', '_Log', 'Mag', 'ick', 'Event', '(', 'Tr', 'ace', 'Event', ',', 'Get', 'Mag', 'ick', 'Module', '()', ',\"', '%', 's', '\",', '_image', '_', 'info', '->', 'filename', ');', '_assert', '(', 'ex', 'ception', '_!=', '_(', 'Exception', 'Info', '_*)', '_NULL', ');', '_assert', '(', 'ex', 'ception', '->', 'sign', 'ature', '_==', '_Mag', 'ick', 'Sign', 'ature', ');', '_image', '=', 'Ac', 'quire', 'Image', '(', 'image', '_', 'info', ');', '_status', '=', 'Open', 'Bl', 'ob', '(', 'image', '_', 'info', ',', 'image', ',', 'Read', 'B', 'inary', 'Bl', 'ob', 'Mode', ',', 'ex', 'ception', ');', '_if', '_(', 'status', '_==', '_Mag', 'ick', 'False', ')', '_{', '_image', '=', 'Destroy', 'Image', 'List', '(', 'image', ');', '_return', '((', 'Image', '_*)', '_NULL', ');', '_}', '_(', 'void', ')', '_Mag', 'ick', 'Set', 'Thread', 'Value', '(', 't', 'iff', '_', 'ex', 'ception', ',', 'ex', 'ception', ');', '_error', '_', 'handler', '=', 'T', 'IFF', 'Set', 'Error', 'Handler', '(', 'T', 'IFF', 'Er', 'rors', ');', '_warning', '_', 'handler', '=', 'T', 'IFF', 'Set', 'Warning', 'Handler', '(', 'T', 'IF', 'FW', 'arn', 'ings', ');', '_t', 'iff', '=', 'T', 'IFF', 'Client', 'Open', '(', 'image', '->', 'filename', ',\"', 'rb', '\",', '(', 'th', 'and', 'le', '_', 't', ')', '_image', ',', 'T', 'IFF', 'Read', 'Bl', 'ob', ',', '_T', 'IFF', 'Write', 'Bl', 'ob', ',', 'T', 'IFF', 'Se', 'ek', 'Bl', 'ob', ',', 'T', 'IFF', 'Close', 'Bl', 'ob', ',', 'T', 'IFF', 'Get', 'Bl', 'ob', 'Size', ',', 'T', 'IFF', 'Map', 'Bl', 'ob', ',', '_T', 'IFF', 'Un', 'map', 'Bl', 'ob', ');', '_if', '_(', 't', 'iff', '_==', '_(', 'T', 'IFF', '_*)', '_NULL', ')', '_{', '_(', 'void', ')', '_T', 'IFF', 'Set', 'Warning', 'Handler', '(', 'warning', '_', 'handler', ');', '_(', 'void', ')', '_T', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_ids: 0 42653 2960 1009 25439 565 24377 8532 1640 20836 2960 39863 1009 20094 1215 23999 6 47617 39863 1009 3463 20900 43 25522 10759 16224 1009 27657 131 15754 1009 45872 5183 1571 6 3023 1215 14413 6 1423 1215 14413 6 3023 1215 29646 6 1423 1215 29646 131 2960 1009 20094 131 6979 326 4822 1215 29552 131 3771 1758 45599 21926 40118 47423 6 2194 131 3771 1758 45698 40118 346 1215 642 41699 131 30477 39863 1009 39064 783 1215 23999 131 30477 40118 17997 1215 12528 131 5124 579 10799 1215 90 939 131 1836 1215 90 11212 131 579 10799 1215 90 1423 131 255 24377 1009 90 4822 131 255 24377 30192 49191 5849 1215 45291 6 2892 1215 45291 131 255 24377 47967 40118 5448 131 49315 1549 37175 1215 10058 6 15239 1215 1741 1215 14029 6 253 811 6 1823 1215 29 45598 6 3222 44603 6 19220 1215 14029 1215 19434 6 5251 1215 14029 1215 19434 6 14497 6 6052 6 17190 22356 6 1009 14029 1215 23999 6 7728 1215 34609 6 7931 1215 1741 1215 44546 6 2833 6 923 131 49315 2881 6958 6 22162 1215 1741 1215 34216 6 22523 131 39023 16224 1009 642 41699 131 48565 2117 2274 4 48404 18088 1640 20094 1215 23999 49333 36 20836 2960 39863 49521 48955 4397 18088 1640 20094 1215 23999 46613 13033 18830 45994 3771 1758 25675 18830 4397 114 36 20094 1215 23999 46613 49208 49333 3771 1758 46659 43 36 47908 43 9359 25117 1758 44879 1640 12667 4450 44879 6 14181 25117 1758 48720 43048 60 207 29 1297 2274 1215 23999 46613 49451 4397 18088 1640 3463 20900 49333 36 48847 39863 49521 48955 4397 18088 1640 3463 20900 46613 13033 18830 45994 3771 1758 25675 18830 4397 2274 5214 26145 17446 8532 1640 20094 1215 23999 4397 2194 5214 25266 12654 2413 1640 20094 1215 23999 6 20094 6 25439 387 15548 12654 2413 47062 6 3463 20900 4397 114 36 29552 45994 3771 1758 46659 43 25522 2274 5214 47966 8532 36583 1640 20094 4397 671 48461 8532 49521 48955 4397 35524 36 47908 43 3771 1758 28512 47563 33977 1640 90 4822 1215 3463 20900 6 3463 20900 4397 5849 1215 45291 5214 565 24377 28512 30192 49191 1640 565 24377 28012 38505 4397 2892 1215 45291 5214 565 24377 28512 43370 49191 1640 565 7025 18514 4422 1033 4397 326 4822 5214 565 24377 47952 25266 1640 20094 46613 49451 60 20815 1297 1640 212 463 459 1215 90 43 2274 6 565 24377 25439 12654 2413 6 255 24377 45714 12654 2413 6 565 24377 14696 1951 12654 2413 6 565 24377 42841 12654 2413 6 565 24377 14181 12654 2413 45698 6 565 24377 41151 12654 2413 6 255 24377 9685 32557 12654 2413 4397 114 36 90 4822 45994 36 565 24377 49521 48955 43 25522 36 47908 43 255 24377 28512 43370 49191 1640 43395 1215 45291 4397 36 47908 43 255 2\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_tokens: ['<s>', 'susp', 'end', '_exception', '_processing', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_ids: 0 32658 1397 8219 5774 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   *** Example ***\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   idx: 4\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_tokens: ['<s>', 'static', '_void', '_diff', '_', 'bytes', '_', 'c', '(', 'uint', '8', '_', 't', '_*', 'd', 'st', ',', '_const', '_uint', '8', '_', 't', '_*', 'src', '1', ',', '_const', '_uint', '8', '_', 't', '_*', 'src', '2', ',', '_int', '_w', '){', '_long', '_i', ';', '_#', 'if', '_!', 'HA', 'VE', '_', 'F', 'AST', '_', 'UN', 'AL', 'IGN', 'ED', '_if', '((', 'long', ')', 'src', '2', '_&', '_(', 'size', 'of', '(', 'long', ')-', '1', '))', '{', '_for', '(', 'i', '=', '0', ';', '_i', '+', '7', '<', 'w', ';', '_i', '+=', '8', '){', '_dst', '[', 'i', '+', '0', ']', '_=', '_src', '1', '[', 'i', '+', '0', ']-', 'src', '2', '[', 'i', '+', '0', '];', '_dst', '[', 'i', '+', '1', ']', '_=', '_src', '1', '[', 'i', '+', '1', ']-', 'src', '2', '[', 'i', '+', '1', '];', '_dst', '[', 'i', '+', '2', ']', '_=', '_src', '1', '[', 'i', '+', '2', ']-', 'src', '2', '[', 'i', '+', '2', '];', '_dst', '[', 'i', '+', '3', ']', '_=', '_src', '1', '[', 'i', '+', '3', ']-', 'src', '2', '[', 'i', '+', '3', '];', '_dst', '[', 'i', '+', '4', ']', '_=', '_src', '1', '[', 'i', '+', '4', ']-', 'src', '2', '[', 'i', '+', '4', '];', '_dst', '[', 'i', '+', '5', ']', '_=', '_src', '1', '[', 'i', '+', '5', ']-', 'src', '2', '[', 'i', '+', '5', '];', '_dst', '[', 'i', '+', '6', ']', '_=', '_src', '1', '[', 'i', '+', '6', ']-', 'src', '2', '[', 'i', '+', '6', '];', '_dst', '[', 'i', '+', '7', ']', '_=', '_src', '1', '[', 'i', '+', '7', ']-', 'src', '2', '[', 'i', '+', '7', '];', '_}', '_}', 'else', '_#', 'endif', '_for', '(', 'i', '=', '0', ';', '_i', '<', '=', 'w', '-', 'size', 'of', '(', 'long', ');', '_i', '+=', 'size', 'of', '(', 'long', '))', '{', '_long', '_a', '_=', '_*', '(', 'long', '*', ')(', 'src', '1', '+', 'i', ');', '_long', '_b', '_=', '_*', '(', 'long', '*', ')(', 'src', '2', '+', 'i', ');', '_*', '(', 'long', '*', ')(', 'd', 'st', '+', 'i', ')', '_=', '_((', 'a', '|', 'pb', '_', '80', ')', '_-', '_(', 'b', '&', 'pb', '_', '7', 'f', '))', '_^', '_((', 'a', '^', 'b', '^', 'pb', '_', '80', ')', '&', 'pb', '_', '80', ');', '_}', '_for', '(', ';', '_i', '<', 'w', ';', '_i', '++)', '_dst', '[', 'i', '+', '0', ']', '_=', '_src', '1', '[', 'i', '+', '0', ']-', 'src', '2', '[', 'i', '+', '0', '];', '_}', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_ids: 0 42653 13842 25871 1215 46823 1215 438 1640 47157 398 1215 90 1009 417 620 6 10759 49315 398 1215 90 1009 45692 134 6 10759 49315 398 1215 90 1009 45692 176 6 6979 885 48512 251 939 131 849 1594 27785 6826 8856 1215 597 10388 1215 4154 2118 30596 1691 114 48461 3479 43 45692 176 359 36 10799 1116 1640 3479 19281 134 35122 45152 13 1640 118 5214 288 131 939 2744 406 41552 605 131 939 49419 398 48512 49339 10975 118 2744 288 742 5457 47215 134 10975 118 2744 288 48520 45692 176 10975 118 2744 288 44082 49339 10975 118 2744 134 742 5457 47215 134 10975 118 2744 134 48520 45692 176 10975 118 2744 134 44082 49339 10975 118 2744 176 742 5457 47215 134 10975 118 2744 176 48520 45692 176 10975 118 2744 176 44082 49339 10975 118 2744 246 742 5457 47215 134 10975 118 2744 246 48520 45692 176 10975 118 2744 246 44082 49339 10975 118 2744 306 742 5457 47215 134 10975 118 2744 306 48520 45692 176 10975 118 2744 306 44082 49339 10975 118 2744 245 742 5457 47215 134 10975 118 2744 245 48520 45692 176 10975 118 2744 245 44082 49339 10975 118 2744 401 742 5457 47215 134 10975 118 2744 401 48520 45692 176 10975 118 2744 401 44082 49339 10975 118 2744 406 742 5457 47215 134 10975 118 2744 406 48520 45692 176 10975 118 2744 406 44082 35524 35524 44617 849 49741 13 1640 118 5214 288 131 939 41552 5214 605 12 10799 1116 1640 3479 4397 939 49419 10799 1116 1640 3479 35122 45152 251 10 5457 1009 1640 3479 3226 21704 45692 134 2744 118 4397 251 741 5457 1009 1640 3479 3226 21704 45692 176 2744 118 4397 1009 1640 3479 3226 21704 417 620 2744 118 43 5457 41006 102 15483 45306 1215 2940 43 111 36 428 947 45306 1215 406 506 35122 37249 41006 102 35227 428 35227 45306 1215 2940 43 947 45306 1215 2940 4397 35524 13 1640 131 939 41552 605 131 939 49346 49339 10975 118 2744 288 742 5457 47215 134 10975 118 2744 288 48520 45692 176 10975 118 2744 288 44082 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_tokens: ['<s>', 'integer', '_overflow', '_and', '_out', '_of', '_array', '_access', 'es', '</s>']\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_ids: 0 49465 34391 8 66 9 8932 899 293 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "07/20/2023 02:34:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "07/20/2023 02:34:46 - INFO - __main__ -   ***** Running training *****\n",
      "07/20/2023 02:34:46 - INFO - __main__ -     Num examples = 3431\n",
      "07/20/2023 02:34:46 - INFO - __main__ -     Batch size = 50\n",
      "07/20/2023 02:34:46 - INFO - __main__ -     Num epoch = 100\n",
      "  0%|                                                    | 0/69 [00:00<?, ?it/s]/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 0 loss 12.2906:   1%|â–Ž                     | 1/69 [00:04<04:33,  4.02s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hqn650/vulexplain-internal-external-reason/CodeXGLUE/Code-Text/code-to-text/code/run.py\", line 519, in <module>\n",
      "    main()\n",
      "  File \"/home/hqn650/vulexplain-internal-external-reason/CodeXGLUE/Code-Text/code-to-text/code/run.py\", line 327, in main\n",
      "    loss,_,_ = model(source_ids=source_ids,source_mask=source_mask,target_ids=target_ids,target_mask=target_mask)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 171, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 181, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 89, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/_utils.py\", line 644, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hqn650/anaconda3/envs/vul-intext-reason/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hqn650/vulexplain-internal-external-reason/CodeXGLUE/Code-Text/code-to-text/code/model.py\", line 65, in forward\n",
      "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 730.00 MiB (GPU 0; 23.69 GiB total capacity; 21.69 GiB already allocated; 637.19 MiB free; 22.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 5e-5\n",
    "batch_size = 50 # change depending on the GPU Colab gives you\n",
    "beam_size = 10\n",
    "source_length = args.max_source_length\n",
    "target_length = args.max_target_length\n",
    "data_dir = 'tmp_data'\n",
    "output_dir = f'{args.save_dir}/{args.prefix}_{args.task}'\n",
    "train_file = f'{data_dir}/{args.task}/train.jsonl'\n",
    "dev_file = f'{data_dir}/{args.task}/valid.jsonl'\n",
    "epochs = args.epochs \n",
    "pretrained_model = args.model_name\n",
    "\n",
    "! python CodeXGLUE/Code-Text/code-to-text/code/run.py \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_lower_case \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path {pretrained_model} \\\n",
    "    --train_filename {train_file} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --train_batch_size {batch_size} \\\n",
    "    --eval_batch_size {batch_size} \\\n",
    "    --learning_rate {lr} \\\n",
    "    --num_train_epochs {epochs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/20/2023 01:44:15 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='tf_board/codebert_attack_vector', load_model_path='tf_board/codebert_attack_vector/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename='tmp_data/attack_vector/valid.jsonl', test_filename='tmp_data/attack_vector/test.jsonl', config_name='', tokenizer_name='', max_source_length=512, max_target_length=146, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n",
      "07/20/2023 01:44:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False\n",
      "07/20/2023 01:44:17 - INFO - __main__ -   reload model from tf_board/codebert_attack_vector/checkpoint-best-bleu/pytorch_model.bin\n",
      "07/20/2023 01:44:19 - INFO - __main__ -   Test file: tmp_data/attack_vector/valid.jsonl\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:32<00:00,  3.58s/it]\n",
      "Total: 540\n",
      "07/20/2023 01:44:52 - INFO - __main__ -     bleu-4 = 71.45 \n",
      "07/20/2023 01:44:52 - INFO - __main__ -     ********************\n",
      "07/20/2023 01:44:52 - INFO - __main__ -   Test file: tmp_data/attack_vector/test.jsonl\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [01:13<00:00,  3.32s/it]\n",
      "Total: 1350\n",
      "07/20/2023 01:46:08 - INFO - __main__ -     bleu-4 = 70.66 \n",
      "07/20/2023 01:46:08 - INFO - __main__ -     ********************\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "dev_file= f'{data_dir}/{args.task}/valid.jsonl'\n",
    "test_file=f\"{data_dir}/{args.task}/test.jsonl\"\n",
    "test_model=f\"{output_dir}/checkpoint-best-bleu/pytorch_model.bin\" #checkpoint for test\n",
    "\n",
    "! python code2nl/run.py \\\n",
    "    --do_test \\\n",
    "    --model_type roberta \\\n",
    "    --model_name_or_path microsoft/codebert-base \\\n",
    "    --load_model_path {test_model} \\\n",
    "    --dev_filename {dev_file} \\\n",
    "    --test_filename {test_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_source_length {source_length} \\\n",
    "    --max_target_length {target_length} \\\n",
    "    --beam_size {beam_size} \\\n",
    "    --eval_batch_size {batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name, do_lower_case=args.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "config = RobertaConfig.from_pretrained(pretrained_model)\n",
    "encoder = RobertaModel.from_pretrained(pretrained_model, config = config)    \n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(encoder = encoder,decoder = decoder,config=config,\n",
    "                beam_size=beam_size,max_length=target_length,\n",
    "                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n",
    "model.load_state_dict(torch.load(Path(output_dir)/\"checkpoint-best-bleu/pytorch_model.bin\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static int aes_gcm_ctrl(EVP_CIPHER_CTX *c, int type, int arg, void *ptr) {  EVP_AES_GCM_CTX *gctx = EVP_C_DATA(EVP_AES_GCM_CTX,c);  switch (type) {  case EVP_CTRL_INIT:  gctx->key_set = 0;  gctx->iv_set = 0;  gctx->ivlen = EVP_CIPHER_CTX_iv_length(c);  gctx->iv = EVP_CIPHER_CTX_iv_noconst(c);  gctx->taglen = -1;  gctx->iv_gen = 0;  gctx->tls_aad_len = -1;  return 1;   case EVP_CTRL_AEAD_SET_IVLEN:  if (arg <= 0)  return 0;  /* Allocate memory for IV if needed */  if ((arg > EVP_MAX_IV_LENGTH) && (arg > gctx->ivlen)) {  if (gctx->iv != EVP_CIPHER_CTX_iv_noconst(c))  OPENSSL_free(gctx->iv);  gctx->iv = OPENSSL_malloc(arg);  if (gctx->iv == NULL)  return 0;  }  gctx->ivlen = arg;  return 1;   case EVP_CTRL_AEAD_SET_TAG:  if (arg <= 0 || arg > 16 || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->taglen = arg;  return 1;   case EVP_CTRL_AEAD_GET_TAG:  if (arg <= 0 || arg > 16 || !EVP_CIPHER_CTX_encrypting(c)  || gctx->taglen < 0)  return 0;  memcpy(ptr, EVP_CIPHER_CTX_buf_noconst(c), arg);  return 1;   case EVP_CTRL_GCM_SET_IV_FIXED:  /* Special case: -1 length restores whole IV */  if (arg == -1) {  memcpy(gctx->iv, ptr, gctx->ivlen);  gctx->iv_gen = 1;  return 1;  }  /*  * Fixed field must be at least 4 bytes and invocation field at least  * 8.  */  if ((arg < 4) || (gctx->ivlen - arg) < 8)  return 0;  if (arg)  memcpy(gctx->iv, ptr, arg);  if (EVP_CIPHER_CTX_encrypting(c)  && RAND_bytes(gctx->iv + arg, gctx->ivlen - arg) <= 0)  return 0;  gctx->iv_gen = 1;  return 1;   case EVP_CTRL_GCM_IV_GEN:  if (gctx->iv_gen == 0 || gctx->key_set == 0)  return 0;  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  if (arg <= 0 || arg > gctx->ivlen)  arg = gctx->ivlen;  memcpy(ptr, gctx->iv + gctx->ivlen - arg, arg);  /*  * Invocation field will be at least 8 bytes in size and so no need  * to check wrap around or increment more than last 8 bytes.  */  ctr64_inc(gctx->iv + gctx->ivlen - 8);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_GCM_SET_IV_INV:  if (gctx->iv_gen == 0 || gctx->key_set == 0  || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(gctx->iv + gctx->ivlen - arg, ptr, arg);  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_AEAD_TLS1_AAD:  /* Save the AAD for later use */  if (arg != EVP_AEAD_TLS1_AAD_LEN)  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->tls_aad_len = arg;  {  unsigned int len =  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] << 8  | EVP_CIPHER_CTX_buf_noconst(c)[arg - 1];  /* Correct length for explicit IV */  len -= EVP_GCM_TLS_EXPLICIT_IV_LEN;  /* If decrypting correct for tag too */  if (!EVP_CIPHER_CTX_encrypting(c))  len -= EVP_GCM_TLS_TAG_LEN;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] = len >> 8;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 1] = len & 0xff;  }  /* Extra padding: tag appended to record */  return EVP_GCM_TLS_TAG_LEN;   case EVP_CTRL_COPY:  {  EVP_CIPHER_CTX *out = ptr;  EVP_AES_GCM_CTX *gctx_out = EVP_C_DATA(EVP_AES_GCM_CTX,out);  if (gctx->gcm.key) {  if (gctx->gcm.key != &gctx->ks)  return 0;  gctx_out->gcm.key = &gctx_out->ks;  }  if (gctx->iv == EVP_CIPHER_CTX_iv_noconst(c))  gctx_out->iv = EVP_CIPHER_CTX_iv_noconst(out);  else {  gctx_out->iv = OPENSSL_malloc(gctx->ivlen);  if (gctx_out->iv == NULL)  return 0;  memcpy(gctx_out->iv, gctx->iv, gctx->ivlen);  }  return 1;  }   default:  return -1;   } } \n",
      "Original Comment: sending specially-crafted data\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "TEXT_TO_SUMMARIZE = df_test.func_before.values[idx]\n",
    "print('Code:', TEXT_TO_SUMMARIZE)\n",
    "print('Original Comment:', df_val.explain.values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from code2nl.run import convert_examples_to_features, Example\n",
    "\n",
    "def get_preds(df: pd.DataFrame):\n",
    "    ps = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        examples = [\n",
    "            Example(idx, source = row.func_before, target = row.explain)\n",
    "        ]\n",
    "        eval_features = convert_examples_to_features(\n",
    "            examples, tokenizer, args, stage='test'\n",
    "        )\n",
    "        source_ids = torch.tensor(eval_features[0].source_ids, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "        source_mask = torch.tensor(eval_features[0].source_mask, dtype = torch.long).unsqueeze(0).to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(source_ids = source_ids, source_mask = source_mask)  \n",
    "            for pred in preds:\n",
    "                t = pred[0].cpu().numpy()\n",
    "                t = list(t)\n",
    "                if 0 in t:\n",
    "                    t = t[:t.index(0)]\n",
    "                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                ps.append(text)\n",
    "    \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009438514709472656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 39,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1350,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c039f53ed1204463be90b843a6fea73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/20/2023 02:20:19 - INFO - absl -   Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.7400530734869872,\n",
       " 'rouge2': 0.674424059172773,\n",
       " 'rougeL': 0.736809424464677,\n",
       " 'rougeLsum': 0.7375780847916675}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = df_test.reset_index()\n",
    "preds = get_preds(df_test)\n",
    "references = []\n",
    "for idx, row in df_test.iterrows():\n",
    "    # print('Code:', row.func_before)\n",
    "    # print('Original Comment:', row.explain)\n",
    "    # print('Generated Comment:', preds[idx])\n",
    "    # print('='*40)\n",
    "    references.append(row.explain)\n",
    "\n",
    "results = rouge.compute(predictions=preds, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: static int aes_gcm_ctrl(EVP_CIPHER_CTX *c, int type, int arg, void *ptr) {  EVP_AES_GCM_CTX *gctx = EVP_C_DATA(EVP_AES_GCM_CTX,c);  switch (type) {  case EVP_CTRL_INIT:  gctx->key_set = 0;  gctx->iv_set = 0;  gctx->ivlen = EVP_CIPHER_CTX_iv_length(c);  gctx->iv = EVP_CIPHER_CTX_iv_noconst(c);  gctx->taglen = -1;  gctx->iv_gen = 0;  gctx->tls_aad_len = -1;  return 1;   case EVP_CTRL_AEAD_SET_IVLEN:  if (arg <= 0)  return 0;  /* Allocate memory for IV if needed */  if ((arg > EVP_MAX_IV_LENGTH) && (arg > gctx->ivlen)) {  if (gctx->iv != EVP_CIPHER_CTX_iv_noconst(c))  OPENSSL_free(gctx->iv);  gctx->iv = OPENSSL_malloc(arg);  if (gctx->iv == NULL)  return 0;  }  gctx->ivlen = arg;  return 1;   case EVP_CTRL_AEAD_SET_TAG:  if (arg <= 0 || arg > 16 || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->taglen = arg;  return 1;   case EVP_CTRL_AEAD_GET_TAG:  if (arg <= 0 || arg > 16 || !EVP_CIPHER_CTX_encrypting(c)  || gctx->taglen < 0)  return 0;  memcpy(ptr, EVP_CIPHER_CTX_buf_noconst(c), arg);  return 1;   case EVP_CTRL_GCM_SET_IV_FIXED:  /* Special case: -1 length restores whole IV */  if (arg == -1) {  memcpy(gctx->iv, ptr, gctx->ivlen);  gctx->iv_gen = 1;  return 1;  }  /*  * Fixed field must be at least 4 bytes and invocation field at least  * 8.  */  if ((arg < 4) || (gctx->ivlen - arg) < 8)  return 0;  if (arg)  memcpy(gctx->iv, ptr, arg);  if (EVP_CIPHER_CTX_encrypting(c)  && RAND_bytes(gctx->iv + arg, gctx->ivlen - arg) <= 0)  return 0;  gctx->iv_gen = 1;  return 1;   case EVP_CTRL_GCM_IV_GEN:  if (gctx->iv_gen == 0 || gctx->key_set == 0)  return 0;  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  if (arg <= 0 || arg > gctx->ivlen)  arg = gctx->ivlen;  memcpy(ptr, gctx->iv + gctx->ivlen - arg, arg);  /*  * Invocation field will be at least 8 bytes in size and so no need  * to check wrap around or increment more than last 8 bytes.  */  ctr64_inc(gctx->iv + gctx->ivlen - 8);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_GCM_SET_IV_INV:  if (gctx->iv_gen == 0 || gctx->key_set == 0  || EVP_CIPHER_CTX_encrypting(c))  return 0;  memcpy(gctx->iv + gctx->ivlen - arg, ptr, arg);  CRYPTO_gcm128_setiv(&gctx->gcm, gctx->iv, gctx->ivlen);  gctx->iv_set = 1;  return 1;   case EVP_CTRL_AEAD_TLS1_AAD:  /* Save the AAD for later use */  if (arg != EVP_AEAD_TLS1_AAD_LEN)  return 0;  memcpy(EVP_CIPHER_CTX_buf_noconst(c), ptr, arg);  gctx->tls_aad_len = arg;  {  unsigned int len =  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] << 8  | EVP_CIPHER_CTX_buf_noconst(c)[arg - 1];  /* Correct length for explicit IV */  len -= EVP_GCM_TLS_EXPLICIT_IV_LEN;  /* If decrypting correct for tag too */  if (!EVP_CIPHER_CTX_encrypting(c))  len -= EVP_GCM_TLS_TAG_LEN;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 2] = len >> 8;  EVP_CIPHER_CTX_buf_noconst(c)[arg - 1] = len & 0xff;  }  /* Extra padding: tag appended to record */  return EVP_GCM_TLS_TAG_LEN;   case EVP_CTRL_COPY:  {  EVP_CIPHER_CTX *out = ptr;  EVP_AES_GCM_CTX *gctx_out = EVP_C_DATA(EVP_AES_GCM_CTX,out);  if (gctx->gcm.key) {  if (gctx->gcm.key != &gctx->ks)  return 0;  gctx_out->gcm.key = &gctx_out->ks;  }  if (gctx->iv == EVP_CIPHER_CTX_iv_noconst(c))  gctx_out->iv = EVP_CIPHER_CTX_iv_noconst(out);  else {  gctx_out->iv = OPENSSL_malloc(gctx->ivlen);  if (gctx_out->iv == NULL)  return 0;  memcpy(gctx_out->iv, gctx->iv, gctx->ivlen);  }  return 1;  }   default:  return -1;   } } \n",
      "Original Comment: sending specially crafted truncated packets\n",
      "Generated Comment: sending specially crafted truncated packets\n",
      "========================================\n",
      "Code: void BluetoothDeviceChromeOS::OnUnregisterAgentError(  const std::string& error_name,  const std::string& error_message) {  LOG(WARNING) << object_path_.value() << \": Failed to unregister agent: \"  << error_name << \": \" << error_message; } \n",
      "Original Comment: via a crafted web site .\n",
      "Generated Comment: via a crafted web site .\n",
      "========================================\n",
      "Code:  static void unregisterBlobURLTask(void* context)  {  OwnPtr<BlobRegistryContext> blobRegistryContext = adoptPtr(static_cast<BlobRegistryContext*>(context));  blobRegistry().unregisterBlobURL(blobRegistryContext->url);  } \n",
      "Original Comment: via unknown vectors .\n",
      "Generated Comment: via unknown vectors .\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_test.head(3).iterrows():\n",
    "    print('Code:', row.func_before)\n",
    "    print('Original Comment:', row.explain)\n",
    "    print('Generated Comment:', preds[idx])\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
